# -*- coding: utf-8 -*-
# ================================================================
# GEA v0.6 Â· ì‹œì‘ ì„¸íŠ¸(í•©ë³¸) â€” Streamlit í•œ íŒŒì¼
# ê·œì¹™
#  - ëª¨ë“ˆì€ í•­ìƒ "ë§¨ ì•„ë˜"ì— ë¸”ë¡ ë‹¨ìœ„ë¡œ ì´ì–´ë¶™ì´ê¸°
#  - ì¤‘ê°„ ìˆ˜ì •/ì‚½ì… í•„ìš” ì‹œ ë²ˆí˜¸ë¥¼ ìë¦¬ìˆ˜ë¡œ í™•ì¥(ì˜ˆ: 01-1, 01-1-1)
#  - ì¶©ëŒ/ì—ëŸ¬ ì‹œ í•´ë‹¹ "ë²ˆí˜¸ ë¸”ë¡"ì„ í†µì§¸ë¡œ êµì²´(ë¶€ë¶„ ìˆ˜ì • ì§€ì–‘)
#  - ì™¸ë¶€ ì˜ì¡´ì„±: streamlit (í‘œì¤€ë¼ì´ë¸ŒëŸ¬ë¦¬ + streamlitë§Œ ì‚¬ìš©)
# ë¸”ë¡ êµ¬ì„±
#  00. í‘œì§€/ë‚˜ì¹¨ë°˜(ìë™)
#  01. ìš°ì£¼ì •ë³´ì¥(UIS) ì—°ë™ ìŠ¤í… + CE-ê·¸ë˜í”„ ë¹Œë”
#  02. ì´ˆê²€ì¦(í’ˆì§ˆ ê²Œì´íŠ¸)
#  03. ìƒí˜¸ì‘ìš©(ëŒ€í™”) ì—”ì§„
#  04. ë¡œê·¸(ê¸°ì–µ) â€” JSONL ê¸°ë¡
#  05. E2E í•˜íŠ¸ë¹„íŠ¸(ì›í´ë¦­) + UI
#  99. (ì¶”ê°€ ë¸”ë¡ì€ í•­ìƒ ë§¨ ì•„ë˜ì— ì´ì–´ë¶™ì„)
# ================================================================

import streamlit as st
import json, hashlib, re, time, os
from dataclasses import dataclass, asdict
from typing import Dict, Any, List, Optional, Tuple

st.set_page_config(page_title="GEA v0.6 Â· ì‹œì‘ ì„¸íŠ¸", page_icon="ğŸ’ ", layout="wide")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µìš© ìœ í‹¸
def _sha(s: str) -> str:
    return hashlib.sha256((s or "").encode("utf-8")).hexdigest()

def _norm(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())

def _clip(txt: str, max_chars: int) -> str:
    if len(txt) <= max_chars:
        return txt
    cut = txt[:max_chars]
    m = re.search(r"[.!?â€¦ã€‚ï¼ï¼Ÿ]\s*(?!.*[.!?â€¦ã€‚ï¼ï¼Ÿ]\s*)", cut)
    return cut if not m else cut[:m.end()]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 00. í‘œì§€/ë‚˜ì¹¨ë°˜(ìë™)
if "GEA_TOC" not in st.session_state:
    # (ë²ˆí˜¸, ì´ë¦„, ê¸°ëŠ¥) â€” ì´í›„ ëª¨ë“ˆ ì¶”ê°€ ì‹œ .append()ë¡œ ë™ê¸°í™”
    st.session_state.GEA_TOC: List[Tuple[str, str, str]] = [
        ("00", "í‘œì§€/ë‚˜ì¹¨ë°˜", "ê°œë°œ ë°©í–¥/ëª©í‘œ/ì§„í–‰ ìƒíƒœ"),
        ("01", "UIS ì—°ë™+CE-ê·¸ë˜í”„", "ì†ŒìŠ¤ ë“±ë¡/ê²€ìƒ‰ ë° Claimâ€“Evidence ê·¸ë˜í”„ ìƒì„±"),
        ("02", "ì´ˆê²€ì¦(í’ˆì§ˆ ê²Œì´íŠ¸)", "ì¦ê±°/ì¸ìš©/ì¬í˜„ì„±/ë‹¨ìœ„/ë…¼ë¦¬/ì•ˆì •ì„±/ë†€ë¼ì›€ p"),
        ("03", "ìƒí˜¸ì‘ìš© ì—”ì§„", "ì‘ë‹µ ë ˆë²¨/í•œê¸€ ìµœì í™”/í™œì„± ëª¨ë“œ ì§€ì›"),
        ("04", "ë¡œê·¸(ê¸°ì–µ)", "JSONLë¡œ ê²°ê³¼ ê¸°ë¡/ë¦¬í”Œë ˆì´ ê·¼ê±°"),
        ("05", "E2E í•˜íŠ¸ë¹„íŠ¸", "ì›í´ë¦­ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"),
    ]
if "GEA_GOALS" not in st.session_state:
    st.session_state.GEA_GOALS = {
        "now":  "ì†ŒìŠ¤/ê·¸ë˜í”„ ì•ˆì •í™”",
        "near": "ì´ˆê²€ì¦ PASSìœ¨ ìƒí–¥",
        "mid":  "í˜„ì‹¤ ë°ì´í„° í”¼ë“œ ì—°ë™",
        "far":  "ìê°€ì§„í™”Â·ë¬´í•œ ê¸°ì–µ í†µí•©"
    }

st.title("GEA v0.6 Â· ì‹œì‘ ì„¸íŠ¸(í•©ë³¸)")
with st.expander("ğŸ“– í•œëˆˆ ëª©ì°¨(ìë™ ë™ê¸°í™”)", expanded=True):
    st.markdown("| ë²ˆí˜¸ | ì´ë¦„ | ê¸°ëŠ¥ |")
    st.markdown("|---:|---|---|")
    for n, name, desc in st.session_state.GEA_TOC:
        st.markdown(f"| `{n}` | {name} | {desc} |")

with st.sidebar:
    st.header("ğŸ¯ ëª©í‘œ ì¹´ë“œ")
    for k, label in [("now","ë‹¨ê¸°"),("near","ê·¼ì‹œ"),("mid","ì¤‘ê¸°"),("far","ì¥ê¸°")]:
        st.write(f"- **{label}**: {st.session_state.GEA_GOALS[k]}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 01. ìš°ì£¼ì •ë³´ì¥(UIS) ì—°ë™ ìŠ¤í… + CE-ê·¸ë˜í”„ ë¹Œë”
@dataclass
class Source:
    id: str
    title: str
    url: str = ""
    year: int = 0
    trust: float = 0.9
    def as_doc(self) -> Dict[str, Any]:
        return {"id": self.id, "title": self.title, "url": self.url,
                "year": self.year, "trust": float(self.trust)}

@dataclass
class Node:
    id: str
    kind: str
    payload: Dict[str, Any]

@dataclass
class Edge:
    src: str
    dst: str
    rel: str

@dataclass
class CEGraph:
    nodes: List[Node]
    edges: List[Edge]
    digest: str
    created_at: float
    def to_dict(self) -> Dict[str, Any]:
        return {
            "nodes": [asdict(n) for n in self.nodes],
            "edges": [asdict(e) for e in self.edges],
            "digest": self.digest,
            "created_at": self.created_at,
        }

class UISLink:
    def __init__(self, initial_sources: Optional[List[Dict[str, Any]]] = None):
        self._sources: Dict[str, Source] = {}
        if initial_sources:
            for s in initial_sources:
                self.add_source(Source(**s))
    def add_source(self, src: Source) -> None:
        self._sources[src.id] = src
    def list_sources(self, limit: int = 100) -> List[Dict[str, Any]]:
        return [self._sources[k].as_doc() for k in sorted(self._sources.keys())][:limit]
    def _norm(self, s: str) -> str:
        return _norm(s).lower()
    def search(self, query: str, k: int = 8) -> List[Dict[str, Any]]:
        q = self._norm(query)
        q_tokens = set(q.split()) if q else set()
        hits: List[Tuple[float, Dict[str, Any]]] = []
        for sid in sorted(self._sources.keys()):
            s = self._sources[sid]
            blob = f"{s.id} {s.title} {s.url}".lower()
            base = 0.95 if (q and q in blob) else 0.60
            bonus = 0.05 * len(q_tokens & set(blob.split())) if q_tokens else 0.0
            score = min(0.99, base + bonus)
            hits.append((score, {
                "id": s.id, "title": s.title, "url": s.url,
                "year": s.year, "trust": float(s.trust), "score": round(score,3)
            }))
        hits.sort(key=lambda t: (-t[0], t[1]["id"]))
        return [h[1] for h in hits[:max(1,k)]]
    def build_ce_graph(self, claim: str, hits: List[Dict[str, Any]]) -> CEGraph:
        claim_text = _norm(claim) or "(no-claim)"
        claim_id = f"claim:{_sha(claim_text)[:12]}"
        nodes: List[Node] = [Node(id=claim_id, kind="claim", payload={"text": claim_text})]
        edges: List[Edge] = []
        for h in hits:
            evid_id = f"evi:{_sha(h['id'])[:10]}"
            payload = {"src": h["id"], "title": h["title"], "url": h.get("url",""),
                       "year": h.get("year",0), "score": h.get("score",0.0)}
            nodes.append(Node(id=evid_id, kind="evidence", payload=payload))
            edges.append(Edge(src=evid_id, dst=claim_id, rel="supports"))
        digest = _sha(json.dumps({"nodes":[asdict(n) for n in nodes],
                                  "edges":[asdict(e) for e in edges]}, sort_keys=True))
        return CEGraph(nodes=nodes, edges=edges, digest=digest, created_at=time.time())

DEFAULT_SOURCES: List[Dict[str, Any]] = [
    {"id":"src:arxiv:1602.03837","title":"Gravitational Waves (LIGO)","url":"https://arxiv.org/abs/1602.03837","year":2016,"trust":0.98},
    {"id":"src:nist:constants","title":"CODATA Constants (NIST)","url":"https://physics.nist.gov/constants","year":2022,"trust":0.99},
    {"id":"src:ligo:open","title":"LIGO Open Data","url":"https://losc.ligo.org","year":2024,"trust":0.97},
]
UIS = UISLink(initial_sources=DEFAULT_SOURCES)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 02. ì´ˆê²€ì¦(í’ˆì§ˆ ê²Œì´íŠ¸)
GATE_VERSION = "quality-gate-v1"
SIGNAL_BASELINES = {
    "ce_min": 0.97,
    "cite_min": 0.90,
    "repr_min": 0.93,
    "logic_max": 0.0005,
    "unit_max": 0.0001,
    "surp_max": 0.005,
}
_UNIT_TOK = r"\b(m|s|kg|J|Hz|N|Pa|W|V|A|mol|K)\b"
_EQ_TOK   = r"(=|â‰ˆ|âˆ|â‰¤|â‰¥|â‰ƒ|â‰…)"
_URL_TOK  = r"https?://|src:"

def analyze_ce(ce: Optional[Dict[str, Any]]) -> Tuple[float,float,float]:
    if not isinstance(ce, dict): return (0.0, 0.0, 0.985)
    n_evi = sum(1 for n in ce.get("nodes",[]) if n.get("kind")=="evidence")
    n_edges = len(ce.get("edges",[]))
    ce_cov = 0.8 + min(0.2, 0.02*n_evi + 0.01*n_edges)
    cite  = 0.85 + min(0.15, 0.02*n_evi)
    srcs = set((n.get("payload") or {}).get("src","") for n in ce.get("nodes",[]) if n.get("kind")=="evidence")
    srcs.discard("")
    subset = 0.985 + (0.003 if len(srcs)>=2 else 0.0)
    return (round(ce_cov,3), round(cite,3), round(min(0.999,subset),3))

def analyze_text(body: str) -> Tuple[float,float,float,float,float]:
    if not isinstance(body,str) or not body.strip():
        return (0.0, 0.001, 0.0002, 0.01, 0.0)
    tok_eq   = len(re.findall(_EQ_TOK, body))
    tok_unit = len(re.findall(_UNIT_TOK, body))
    tok_ref  = len(re.findall(_URL_TOK, body))
    reprod = min(0.99, 0.90 + 0.01*tok_eq + 0.01*tok_ref)
    lviol  = max(0.00005, 0.0008 - 0.0001*tok_eq)
    uviol  = max(0.00002, 0.0003 - 0.00002*tok_unit)
    sp     = max(0.001, 0.02 - 0.002*(tok_eq + tok_unit))
    dup    = 0.02 if len(body)>1200 else 0.0
    return (round(reprod,3), round(lviol,6), round(uviol,6), round(sp,3), round(dup,3))

@dataclass
class Metrics:
    ce_coverage: float
    citation_coverage: float
    reproducibility: float
    logic_violation: float
    unit_dim_violation: float
    subset_robustness: float
    surprise_p: float
    duplication_rate: float = 0.0
    paraphrase_consistency: float = 1.0
    def as_dict(self) -> Dict[str,float]:
        return asdict(self)

def make_metrics(ce_graph: Optional[Dict[str, Any]], body: str) -> Metrics:
    ce_cov, cite, subset = analyze_ce(ce_graph)
    reprod, lviol, uviol, sp, dup = analyze_text(body)
    return Metrics(ce_cov, cite, reprod, lviol, uviol, subset, sp, duplication_rate=dup)

def gate(metrics: Metrics, input_hash: str) -> Dict[str, Any]:
    if metrics.ce_coverage < SIGNAL_BASELINES["ce_min"]:   vr, rs = "REPAIR","ì¦ê±° í•˜í•œ ë¯¸ë‹¬"
    elif metrics.citation_coverage < SIGNAL_BASELINES["cite_min"]: vr, rs = "REPAIR","ì¸ìš© í•˜í•œ ë¯¸ë‹¬"
    elif metrics.reproducibility < SIGNAL_BASELINES["repr_min"]:    vr, rs = "REPAIR","ì¬í˜„ì„± ë¯¸ë‹¬"
    elif metrics.logic_violation > SIGNAL_BASELINES["logic_max"]:   vr, rs = "REPAIR","ë…¼ë¦¬ ìœ„ë°˜ìœ¨ ì´ˆê³¼"
    elif metrics.unit_dim_violation > SIGNAL_BASELINES["unit_max"]: vr, rs = "REPAIR","ë‹¨ìœ„/ì°¨ì› ìœ„ë°˜ìœ¨ ì´ˆê³¼"
    elif metrics.subset_robustness < SIGNAL_BASELINES["ce_min"]:    vr, rs = "REPAIR","ë¶€ë¶„ì¦ê±° ê°•ê±´ì„± ë¯¸ë‹¬"
    elif metrics.surprise_p > SIGNAL_BASELINES["surp_max"]:         vr, rs = "REPAIR","ë†€ë¼ì›€ p ì´ˆê³¼"
    else: vr, rs = "PASS","ok"
    att = {
        "gate_version": GATE_VERSION,
        "metrics_digest": _sha(json.dumps(metrics.as_dict(), sort_keys=True)),
        "input_hash": input_hash,
        "ts": time.time()
    }
    return {"verdict": vr, "reason": rs, "metrics": metrics.as_dict(), "attestation": att}

def run_quality_gate(claim: str, ce_graph: Optional[Dict[str, Any]], body: str) -> Dict[str, Any]:
    m = make_metrics(ce_graph, body or "")
    return gate(m, input_hash=_sha(_norm(claim) or "(no-claim)"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 03. ìƒí˜¸ì‘ìš©(ëŒ€í™”) ì—”ì§„
@dataclass
class InteractConfig:
    active_mode: bool = False
    persona_name: str = "ì—ì•„"
    creator_name: str = "ê¸¸ë„"

def _level_to_chars(level: int) -> int:
    level = max(1, min(999, int(level)))
    if level <= 3:   return 90 * level
    if level <= 10:  return 120 * level
    if level <= 50:  return 160 * level
    if level <= 200: return 220 * level
    return 260 * level

def _summarize_ce(ce_graph: Optional[Dict[str, Any]], max_items: int = 5) -> str:
    if not isinstance(ce_graph, dict): return ""
    nodes = ce_graph.get("nodes", [])
    evid = [n for n in nodes if n.get("kind")=="evidence"]
    parts = []
    for n in evid[:max_items]:
        p = n.get("payload", {})
        title = p.get("title","")
        src = p.get("src","")
        url = p.get("url","")
        sc = p.get("score",0)
        if title or src:
            parts.append(f"- {title or src} (score={sc}) {url}")
    return "\n".join(parts)

class InteractionEngine:
    def __init__(self, config: Optional[InteractConfig]=None):
        self.cfg = config or InteractConfig()
    def generate(self, user_text: str, response_level: int=5,
                 ce_graph: Optional[Dict[str, Any]]=None,
                 goals: Optional[Dict[str,str]]=None) -> str:
        u = _norm(user_text)
        lvl = _level_to_chars(response_level)
        pname, cname = self.cfg.persona_name, self.cfg.creator_name
        body = []
        if not u:
            body.append("ë¬´ì—‡ì„ ë„ì™€ì¤„ê¹Œ? ëª©í‘œë‚˜ ì§ˆë¬¸ì„ ì ì–´ì¤˜.")
        else:
            body.append(f"{cname}, ìš”ì²­ í™•ì¸: â€œ{u}â€.")
            if isinstance(goals, dict) and goals:
                card = []
                for k,label in [("now","ë‹¨ê¸°"),("near","ê·¼ì‹œ"),("mid","ì¤‘ê¸°"),("far","ì¥ê¸°")]:
                    if goals.get(k): card.append(f"{label}: {goals[k]}")
                if card: body.append("ëª©í‘œ ì¹´ë“œ:\n- " + "\n- ".join(card))
            ce_sum = _summarize_ce(ce_graph)
            if ce_sum: body.append("ê·¼ê±° ìš”ì•½(CE):\n" + ce_sum)
            if response_level <= 3:
                body.append("í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í• ê²Œ.")
            elif response_level <= 10:
                body.append("ìš”ì ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ê³  ê·¼ê±°ë¥¼ ë§ë¶™ì¼ê²Œ.")
            else:
                body.append("ì„¸ë¶€ ì ˆì°¨Â·ê·¼ê±°Â·ê¸°ì¤€ì„ ì„ ìˆœì„œëŒ€ë¡œ ìƒì„¸íˆ ì „ê°œí• ê²Œ.")
            body.append("ê¶Œì¥ ë£¨í‹´: (1) ì£¼ì¥ ì •ì œ â†’ (2) ì¦ê±° ìˆ˜ì§‘ â†’ (3) CE-ê·¸ë˜í”„ ì—°ê²° â†’ (4) ë³¸ë¬¸ì— ìˆ˜ì‹/ë‹¨ìœ„/ì¶œì²˜ ì‚½ì… â†’ (5) ì´ˆê²€ì¦ PASS í™•ì¸.")
            if self.cfg.active_mode:
                acts = [
                    "â€œì§ˆì˜â†’ê·¸ë˜í”„ ìƒì„±â€ìœ¼ë¡œ ìµœì‹  CE-ê·¸ë˜í”„ ë°˜ì˜",
                    "ë³¸ë¬¸ì— ìˆ˜ì‹(=,â‰ˆ,â‰¤,â‰¥)ê³¼ ë‹¨ìœ„(m, s, kgâ€¦) ëª…ì‹œ",
                    "ì¶œì²˜(URL ë˜ëŠ” src:íƒœê·¸) 2ê°œ ì´ìƒ ì¶”ê°€",
                ]
                n = 1 if response_level<=3 else (2 if response_level<=10 else 3)
                body.append("ë‹¤ìŒ í–‰ë™ ì œì•ˆ:\n- " + "\n- ".join(acts[:n]))
        out = f"{pname}: " + " ".join(body)
        out = _clip(out, lvl)
        dig = (ce_graph or {}).get("digest","")
        if dig: out += f"\n(CE-digest: {dig[:12]})"
        return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 04. ë¡œê·¸(ê¸°ì–µ) â€” JSONL ê¸°ë¡
LOG_DIR = "gea_logs"
def log_gea_response(kind: str, payload: Dict[str, Any]) -> str:
    os.makedirs(LOG_DIR, exist_ok=True)
    ts = time.strftime("%Y-%m-%d", time.gmtime())
    path = os.path.join(LOG_DIR, f"gea_log_{ts}.jsonl")
    with open(path, "a", encoding="utf-8") as f:
        f.write(json.dumps({"t": time.time(), "kind": kind, "data": payload}, ensure_ascii=False) + "\n")
    return path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 05. E2E í•˜íŠ¸ë¹„íŠ¸(ì›í´ë¦­) + UI
st.markdown("---")
st.subheader("ğŸ«€ E2E í•˜íŠ¸ë¹„íŠ¸(ì›í´ë¦­)")

# ì…ë ¥ UI
claim = st.text_input("ì£¼ì¥(Claim)", "LIGO ë°ì´í„°ë¡œ hâ‰ˆÎ”L/L ê²½ë¡œ êµ¬ì„±")
query = st.text_input("ê²€ìƒ‰ ì§ˆì˜(Query)", "LIGO gravitational waves NIST constants")
k = st.slider("ê²€ìƒ‰ ê°œìˆ˜(k)", 1, 12, 6)
body_text = st.text_area("ë³¸ë¬¸/ì„¤ëª…(ê²€ì¦ìš© í…ìŠ¤íŠ¸)", height=150,
                         value="h â‰ˆ Î”L / L, ë‹¨ìœ„ m/m (ë¬´ì°¨ì›). src: https://losc.ligo.org")
resp_level = st.slider("ì‘ë‹µ ë ˆë²¨(1~999)", 1, 999, 8)
active_mode = st.checkbox("í™œì„± ëª¨ë“œ(ìê°€ ì œì•ˆ)", value=True)

colA, colB, colC = st.columns(3)
with colA:
    if st.button("â‘  ì§ˆì˜â†’ê·¸ë˜í”„ ìƒì„±"):
        hits = UIS.search(query or claim, k=k)
        ce = UIS.build_ce_graph(claim or query or "default-claim", hits).to_dict()
        st.session_state["CE_GRAPH"] = ce
        st.success(f"CE-ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ (evidence={sum(1 for n in ce['nodes'] if n['kind']=='evidence')})")
        st.json({"hits": hits, "ce_graph_digest": ce["digest"][:12]})
with colB:
    if st.button("â‘¡ ì´ˆê²€ì¦ ì‹¤í–‰"):
        ce = st.session_state.get("CE_GRAPH")
        report = run_quality_gate(claim, ce, body_text or "")
        st.session_state["GATE_REPORT"] = report
        st.json(report)
        st.success("âœ… PASS") if report["verdict"]=="PASS" else st.warning(f"ğŸ”§ {report['reason']}")
with colC:
    if st.button("â‘¢ ìƒí˜¸ì‘ìš© ì‘ë‹µ"):
        ce = st.session_state.get("CE_GRAPH")
        cfg = InteractConfig(active_mode=active_mode, persona_name="ì—ì•„", creator_name="ê¸¸ë„")
        eng = InteractionEngine(cfg)
        reply = eng.generate(user_text="E2Eë¡œ PASSê¹Œì§€ í•œ ë²ˆì— ê°€ì.", response_level=resp_level,
                             ce_graph=ce, goals=st.session_state.GEA_GOALS)
        st.session_state["INTERACT_REPLY"] = reply
        st.write(reply)

# ì›í´ë¦­
if st.button("ğŸŸ£ E2E ì›í´ë¦­(â‘ â†’â‘¡â†’â‘¢)"):
    hits = UIS.search(query or claim, k=k)
    ce = UIS.build_ce_graph(claim or query or "default-claim", hits).to_dict()
    report = run_quality_gate(claim, ce, body_text or "")
    cfg = InteractConfig(active_mode=active_mode, persona_name="ì—ì•„", creator_name="ê¸¸ë„")
    eng = InteractionEngine(cfg)
    reply = eng.generate(user_text="E2Eë¡œ PASSê¹Œì§€ í•œ ë²ˆì— ê°€ì.", response_level=resp_level,
                         ce_graph=ce, goals=st.session_state.GEA_GOALS)
    st.json({"hits": hits[:3], "ce_graph_digest": ce["digest"][:12]})
    st.json(report)
    st.write(reply)
    # ë¡œê·¸ ì €ì¥
    p1 = log_gea_response("e2e", {
        "claim": claim, "query": query, "k": k,
        "ce_digest": ce["digest"], "report": report, "reply": reply
    })
    st.caption(f"ë¡œê·¸ ì €ì¥: {p1}")

st.markdown("> ê·œì¹™: ì´í›„ ëª¨ë“ˆì€ í•­ìƒ ì´ íŒŒì¼ **ë§¨ ì•„ë˜**ì— ë¸”ë¡ìœ¼ë¡œ ì´ì–´ë¶™ì…ë‹ˆë‹¤. ë²ˆí˜¸ í™•ì¥ìœ¼ë¡œ ì¤‘ê°„ ì‚½ì…ë„ ê°€ëŠ¥(ì˜ˆ: 02-1, 03-1-1).")
# ================================================================
# (ì—¬ê¸° ì•„ë˜ë¶€í„° ìƒˆ ë¸”ë¡ ì´ì–´ë¶™ì´ê¸°)
# ================================================================
# ================================================================
# 06. ë°˜ë¡€ì‚¬ëƒ¥(Adversarial Hunt) â€” ê°„ë‹¨ êµë€Â·ì¬ê²€ì¦ ë£¨í”„
#   - ì…ë ¥ ë³¸ë¬¸/CE-ê·¸ë˜í”„ì— ì†Œì†Œí•œ êµë€ì„ ê°€í•´ ì´ˆê²€ì¦ì„ ì¬ì‹¤í–‰
#   - ì·¨ì•½ì (ì¦ê±°/ì¸ìš©/ë‹¨ìœ„/ë…¼ë¦¬/ì¬í˜„ì„±)ì„ ë¹ ë¥´ê²Œ íŒŒì•…
# ================================================================
import random

def _perturb_text(txt: str) -> str:
    if not txt: return txt
    # ë‹¨ìˆœ ê²°ì •ì  êµë€: ê³µë°±/êµ¬ë‘ì  ì‚½ì…, ë™ì˜ì–´ ìœ ì‚¬ì—´
    repl = [
        ("â‰ˆ", "~"), ("â‰¤", "<="), ("â‰¥", ">="),
        (" ë‹¨ìœ„ ", " [ë‹¨ìœ„] "), (" ì¦ê±° ", " {ì¦ê±°} "),
    ]
    out = txt
    for a, b in repl:
        out = out.replace(a, b)
    # ë¬¸ì¥ ë§ë¯¸ì— ì•ˆì „í•œ ê¼¬ë¦¬í‘œ ì¶”ê°€
    tail = " â€»ê²€ì¦"
    if not out.endswith(tail):
        out += tail
    return out

def adversarial_hunt(claim: str, ce_graph: Dict[str, Any], body: str, rounds: int = 5) -> Dict[str, Any]:
    results = []
    base = run_quality_gate(claim, ce_graph, body)
    pass_cnt = 0
    for i in range(rounds):
        b2 = _perturb_text(body) if (i % 2 == 0) else body
        r = run_quality_gate(claim, ce_graph, b2)
        results.append({"round": i+1, "verdict": r["verdict"], "reason": r["reason"], "metrics": r["metrics"]})
        if r["verdict"] == "PASS":
            pass_cnt += 1
    coverage = pass_cnt / max(1, rounds)
    return {"base": base, "rounds": rounds, "pass_rate": coverage, "details": results}

with st.expander("â‘¥ ë°˜ë¡€ì‚¬ëƒ¥(Adversarial) ì‹¤í–‰", expanded=False):
    arounds = st.slider("ë¼ìš´ë“œ ìˆ˜", 1, 20, 5, key="advr_rounds")
    if st.button("ë°˜ë¡€ì‚¬ëƒ¥ ì‹œì‘", key="advr_btn"):
        ce = st.session_state.get("CE_GRAPH")
        if not ce:
            st.warning("ë¨¼ì € â‘  ì§ˆì˜â†’ê·¸ë˜í”„ ìƒì„± ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            adv = adversarial_hunt(claim, ce, body_text, rounds=arounds)
            st.session_state["ADV_HUNT"] = adv
            st.json({"pass_rate": adv["pass_rate"], "rounds": adv["rounds"]})
            st.json(adv["details"])

# ================================================================
# 07. ê¸°ì–µ(í‚¤-ê°’) + ì²´í¬í¬ì¸íŠ¸ â€” íŒŒì¼ ê¸°ë°˜ ê°„ë‹¨ ìŠ¤í† ì–´
#   - set/get, checkpoint(save_state_hash) ì œê³µ
#   - JSON íŒŒì¼ 1ê°œë¡œ ì €ì¥ (./gea_kv_store.json)
# ================================================================
import json
from pathlib import Path

KV_PATH = Path("gea_kv_store.json")

def kv_load() -> Dict[str, Any]:
    if KV_PATH.exists():
        try:
            return json.loads(KV_PATH.read_text(encoding="utf-8"))
        except Exception:
            return {}
    return {}

def kv_save(d: Dict[str, Any]) -> None:
    KV_PATH.write_text(json.dumps(d, ensure_ascii=False, indent=2), encoding="utf-8")

def kv_set(ns: str, key: str, value: Any) -> None:
    d = kv_load()
    d.setdefault(ns, {})[key] = value
    kv_save(d)

def kv_get(ns: str, key: str, default: Any=None) -> Any:
    d = kv_load()
    return d.get(ns, {}).get(key, default)

def save_checkpoint(name: str, payload: Dict[str, Any]) -> str:
    h = _sha(json.dumps(payload, ensure_ascii=False, sort_keys=True))
    kv_set("checkpoint", name, {"hash": h, "payload": payload, "ts": time.time()})
    return h

with st.expander("â‘¦ ê¸°ì–µ(í‚¤-ê°’) / ì²´í¬í¬ì¸íŠ¸", expanded=False):
    col1, col2 = st.columns(2)
    with col1:
        key_in = st.text_input("í‚¤ ì´ë¦„(ì˜ˆ: last_input)", key="kv_key")
        val_in = st.text_area("ê°’(JSON í…ìŠ¤íŠ¸ í—ˆìš©)", key="kv_val")
        if st.button("ì €ì¥", key="kv_save_btn"):
            try:
                v = json.loads(val_in) if (val_in.strip().startswith("{") or val_in.strip().startswith("[")) else val_in
                kv_set("user", key_in, v)
                st.success("ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")
    with col2:
        key_rd = st.text_input("ì½ì„ í‚¤", key="kv_key_read")
        if st.button("ë¶ˆëŸ¬ì˜¤ê¸°", key="kv_load_btn"):
            v = kv_get("user", key_rd, default=None)
            st.json({"key": key_rd, "value": v})

    if st.button("í˜„ì¬ ì„¸ì…˜ ì²´í¬í¬ì¸íŠ¸ ì €ì¥", key="kv_ckpt_btn"):
        payload = {
            "claim": claim,
            "query": query,
            "body_text": body_text,
            "ce_digest": (st.session_state.get("CE_GRAPH") or {}).get("digest", ""),
            "gate": st.session_state.get("GATE_REPORT", {}),
            "goals": st.session_state.GEA_GOALS
        }
        h = save_checkpoint("session", payload)
        st.success(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {h[:12]}")

# ================================================================
# 08. ë ˆë²¨âˆ ìŠ¤íŠ¸ë¦¬ë°(ë¶„í•  ì¶œë ¥) â€” ê°„ë‹¨ ìŠ¤íŠ¸ë¦¬ë¨¸
#   - í° ì‘ë‹µì„ n-í† ë§‰ìœ¼ë¡œ ë‚˜ëˆ  ìˆœì°¨ í‘œì‹œ (Stop ì§€ì›)
# ================================================================
import math

def stream_segments(text: str, seg_chars: int = 800) -> List[str]:
    text = _norm(text)
    if not text: return []
    n = math.ceil(len(text)/seg_chars)
    return [text[i*seg_chars:(i+1)*seg_chars] for i in range(n)]

if "STREAMING" not in st.session_state:
    st.session_state["STREAMING"] = {"running": False, "segments": [], "idx": 0}

with st.expander("â‘§ ë ˆë²¨âˆ ìŠ¤íŠ¸ë¦¬ë°", expanded=False):
    seg_len = st.slider("ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´(ë¬¸ì)", 200, 2000, 800, key="seg_len")
    colS1, colS2 = st.columns(2)
    with colS1:
        if st.button("Start âˆ", key="stream_start"):
            ce = st.session_state.get("CE_GRAPH")
            cfg = InteractConfig(active_mode=True, persona_name="ì—ì•„", creator_name="ê¸¸ë„")
            eng = InteractionEngine(cfg)
            # ê¸¸ì´ í° ì‘ë‹µ ìƒì„±
            long_reply = eng.generate(
                user_text="ë¬´í•œ ìŠ¤íŠ¸ë¦¼ ëª¨ë“œë¡œ ì¥ë¬¸ ì•ˆë‚´ì™€ ì ˆì°¨, ê·¼ê±°ë¥¼ ìƒì„¸íˆ ì„œìˆ í•´ì¤˜.",
                response_level=999, ce_graph=ce, goals=st.session_state.GEA_GOALS
            )
            st.session_state["STREAMING"] = {
                "running": True,
                "segments": stream_segments(long_reply, seg_chars=seg_len),
                "idx": 0
            }
    with colS2:
        if st.button("Stop", key="stream_stop"):
            st.session_state["STREAMING"]["running"] = False

    if st.session_state["STREAMING"]["running"]:
        idx = st.session_state["STREAMING"]["idx"]
        segs = st.session_state["STREAMING"]["segments"]
        if idx < len(segs):
            st.info(f"[Segment {idx+1}/{len(segs)}]")
            st.write(segs[idx])
            st.session_state["STREAMING"]["idx"] = idx + 1
        else:
            st.success("ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ")
            st.session_state["STREAMING"]["running"] = False

# ================================================================
# 09. ë“€ì–¼ ëª¨ë“œ í† ê¸€(í™œì„±/ë¹„í™œì„±) â€” ì „ì—­ í”Œë˜ê·¸ + UI
#   - í™œì„±: ìê°€ ì œì•ˆ/íƒìƒ‰ ë¬¸êµ¬ ì²¨ë¶€
#   - ë¹„í™œì„±: ìš”ì²­ ì‹œì—ë§Œ ì‘ë‹µ (í˜„ì¬ì™€ ë™ì¼)
# ================================================================
if "ACTIVE_MODE" not in st.session_state:
    st.session_state["ACTIVE_MODE"] = True

with st.expander("â‘¨ ë“€ì–¼ ëª¨ë“œ(í™œì„±/ë¹„í™œì„±) ì„¤ì •", expanded=False):
    st.session_state["ACTIVE_MODE"] = st.checkbox("í™œì„± ëª¨ë“œ(ìê°€ ì œì•ˆ í—ˆìš©)", value=st.session_state["ACTIVE_MODE"])
    st.caption("í™œì„± ëª¨ë“œ ONì´ë©´ â‘¢ ìƒí˜¸ì‘ìš© ë° âˆ ìŠ¤íŠ¸ë¦¼ì—ì„œ 'ë‹¤ìŒ í–‰ë™' ì œì•ˆì´ í¬í•¨ë©ë‹ˆë‹¤.")

# â‘¢ ìƒí˜¸ì‘ìš© ë²„íŠ¼ì´ ìœ„ì— ìˆìœ¼ë¯€ë¡œ, ACTIVE_MODEë¥¼ ë°˜ì˜í•˜ë„ë¡ ì•ˆë‚´ë§Œ ì¶”ê°€
st.caption(f"í˜„ì¬ ëª¨ë“œ: {'í™œì„±' if st.session_state['ACTIVE_MODE'] else 'ë¹„í™œì„±'}")

# ================================================================
# 10. ì‹¤ë°ì´í„° ì»¤ë„¥í„°(HTTP ìŠ¤í…) â€” urllib.request ì‚¬ìš©
#   - ì™¸ë¶€ ì˜ì¡´ì„± ì—†ì´ ê°„ë‹¨ JSON/í…ìŠ¤íŠ¸ GET
# ================================================================
from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError

def http_fetch_text(url: str, timeout: int = 5) -> Tuple[bool, str]:
    try:
        req = Request(url, headers={"User-Agent": "GEA/0.6"})
        with urlopen(req, timeout=timeout) as r:
            data = r.read()
        # í¬ê¸°ê°€ í¬ë©´ ì•ë¶€ë¶„ë§Œ ë¯¸ë¦¬ë³´ê¸°
        text = data.decode("utf-8", errors="replace")
        if len(text) > 2000:
            text = text[:2000] + "\n... (truncated)"
        return True, text
    except (HTTPError, URLError) as e:
        return False, f"HTTP ì˜¤ë¥˜: {e}"
    except Exception as e:
        return False, f"ê¸°íƒ€ ì˜¤ë¥˜: {e}"

with st.expander("â‘© ì‹¤ë°ì´í„° ì»¤ë„¥í„°(HTTP) í…ŒìŠ¤íŠ¸", expanded=False):
    test_url = st.text_input("URL ì…ë ¥(í…ìŠ¤íŠ¸/JSON ê¶Œì¥)", "https://httpbin.org/json", key="http_url")
    if st.button("GET ìš”ì²­", key="http_get_btn"):
        ok, text = http_fetch_text(test_url, timeout=6)
        if ok:
            st.success("ì„±ê³µ")
            st.text(text)
        else:
            st.error(text)

# ================================================================
# 11. ì‹œí¬ë¦¿/ì„¤ì • íŒ¨ë„ â€” st.secrets ì•ˆì „ í‘œì‹œ
# ================================================================
with st.expander("â‘ª Secrets / ì„¤ì • ìƒíƒœ", expanded=False):
    try:
        sec_keys = list(st.secrets.keys())
        redacted = {k: ("***" if isinstance(st.secrets[k], str) and st.secrets[k] else "(set)") for k in sec_keys}
        st.json({"available": sec_keys, "values": redacted})
    except Exception:
        st.info("st.secrets ë¯¸ì„¤ì •")

# ================================================================
# 12. ì§„ë‹¨/ìê°€ì ê²€ â€” í™˜ê²½Â·ë²„ì „Â·ìƒíƒœ ì ê²€
# ================================================================
import platform, sys

def diagnostics() -> Dict[str, Any]:
    ce = st.session_state.get("CE_GRAPH")
    gate = st.session_state.get("GATE_REPORT")
    return {
        "python": sys.version.split()[0],
        "platform": platform.platform(),
        "ce_graph": "set" if ce else "none",
        "gate_verdict": (gate or {}).get("verdict"),
        "log_dir_exists": os.path.isdir(LOG_DIR),
        "kv_file_exists": KV_PATH.exists(),
        "active_mode": st.session_state.get("ACTIVE_MODE", False),
    }

with st.expander("â‘« ì§„ë‹¨/ìê°€ì ê²€", expanded=False):
    st.json(diagnostics())

# ================================================================
# 13. ë¡œê·¸ ë‚´ë³´ë‚´ê¸°/ê°€ì ¸ì˜¤ê¸° â€” ZIP ì••ì¶• ë‹¤ìš´ë¡œë“œ/ì—…ë¡œë“œ
# ================================================================
import io, zipfile

def export_logs_zip() -> bytes:
    mem = io.BytesIO()
    with zipfile.ZipFile(mem, mode="w", compression=zipfile.ZIP_DEFLATED) as z:
        # ë¡œê·¸ ë””ë ‰í„°ë¦¬ ë‚´ íŒŒì¼ì„ ëª¨ë‘ ìˆ˜ì§‘
        if os.path.isdir(LOG_DIR):
            for fn in os.listdir(LOG_DIR):
                fp = os.path.join(LOG_DIR, fn)
                if os.path.isfile(fp):
                    z.write(fp, arcname=f"logs/{fn}")
        # KV ìŠ¤í† ì–´ í¬í•¨
        if KV_PATH.exists():
            z.write(str(KV_PATH), arcname="kv/gea_kv_store.json")
    mem.seek(0)
    return mem.read()

with st.expander("â‘¬ ë¡œê·¸ ë‚´ë³´ë‚´ê¸°/ê°€ì ¸ì˜¤ê¸°", expanded=False):
    colE1, colE2 = st.columns(2)
    with colE1:
        if st.button("ZIP ë‚´ë³´ë‚´ê¸° ì¤€ë¹„", key="zip_prep"):
            st.session_state["ZIP_BYTES"] = export_logs_zip()
            st.success("ZIP ì¤€ë¹„ ì™„ë£Œ")
        if st.session_state.get("ZIP_BYTES"):
            st.download_button(
                label="ZIP ë‹¤ìš´ë¡œë“œ",
                data=st.session_state["ZIP_BYTES"],
                file_name="gea_export.zip",
                mime="application/zip",
                key="zip_dl_btn"
            )
    with colE2:
        up = st.file_uploader("ZIP ì—…ë¡œë“œ(ë¡œê·¸/kv ë³µì›)", type=["zip"], key="zip_up")
        if up and st.button("ë³µì› ì‹¤í–‰", key="zip_restore_btn"):
            try:
                mem = io.BytesIO(up.read())
                with zipfile.ZipFile(mem, mode="r") as z:
                    for name in z.namelist():
                        if name.startswith("logs/"):
                            os.makedirs(LOG_DIR, exist_ok=True)
                            target = os.path.join(LOG_DIR, os.path.basename(name))
                            with z.open(name) as src, open(target, "wb") as dst:
                                dst.write(src.read())
                        elif name == "kv/gea_kv_store.json":
                            with z.open(name) as src, open(KV_PATH, "wb") as dst:
                                dst.write(src.read())
                st.success("ë³µì› ì™„ë£Œ")
            except Exception as e:
                st.error(f"ë³µì› ì‹¤íŒ¨: {e}")
                
                # ================================================================
# 14. ì‹¤ê²€ì¦ ë ˆì‹œí”¼(ìë™ ê°•í™” ë£¨í”„) â€” REPAIR ìë™ ë³´ê°•
#   - ì´ˆê²€ì¦ REPAIR ì‚¬ìœ ë¥¼ ì½ê³ , ë³¸ë¬¸ì„ ìë™ ë³´ê°•í•˜ì—¬ ì¬ì‹œë„
#   - ìµœëŒ€ NíšŒ, ê°œì„  ë¡œê·¸/ìµœì¢… ê²°ê³¼ ì €ì¥
# ================================================================
def auto_repair_loop(claim: str, ce_graph: Dict[str, Any], base_body: str,
                     max_rounds: int = 3) -> Dict[str, Any]:
    body = base_body
    logs = []
    for i in range(1, max_rounds+1):
        rep = run_quality_gate(claim, ce_graph, body)
        logs.append({"round": i, "verdict": rep["verdict"], "reason": rep["reason"], "metrics": rep["metrics"]})
        if rep["verdict"] == "PASS":
            return {"final": rep, "rounds": i, "logs": logs, "body": body}
        # REPAIR ì´ìœ  ê¸°ë°˜ì˜ ê°„ë‹¨í•œ ë³´ê°• ê·œì¹™
        r = rep["reason"]
        if "ì¦ê±° í•˜í•œ" in r or "ê°•ê±´ì„±" in r:
            # ê·¼ê±° ë¼ì¸ 1ê°œ ì¶”ê°€
            body += "\nê·¼ê±°: src:https://losc.ligo.org (LIGO Open Data), src:https://physics.nist.gov/constants (NIST)."
        if "ì¸ìš©" in r:
            body += "\nì°¸ì¡°: https://arxiv.org/abs/1602.03837"
        if "ì¬í˜„ì„±" in r:
            body += "\nì¬í˜„ ì ˆì°¨: ë™ì¼ ë°ì´í„°/ë™ì¼ ìˆ˜ì‹ ì¬ê³„ì‚°(= hâ‰ˆÎ”L/L), ê²°ê³¼ ë¹„êµ."
        if "ë…¼ë¦¬" in r:
            body += "\në…¼ë¦¬ ì ê²€: ì „ì œâ†’ê²°ë¡ ì˜ ë‹¨ê³„ì  ì—°ê²°ì„ ëª…ì‹œ(â‘ ë°ì´í„° â‘¡ê³„ì‚° â‘¢ê²°ë¡ )."
        if "ë‹¨ìœ„/ì°¨ì›" in r:
            body += "\në‹¨ìœ„ ëª…ì‹œ: Î”L[m], L[m], ë¹„ìœ¨ì€ ë¬´ì°¨ì›."
        if "ë†€ë¼ì›€" in r:
            body += "\ní†µê³„ ì£¼ì„: ê²€ì • pâ‰¤0.005 ì¶©ì¡± ì¡°ê±´ ì œì‹œ."
    # ì‹¤íŒ¨ ë°˜í™˜
    rep = run_quality_gate(claim, ce_graph, body)
    return {"final": rep, "rounds": max_rounds, "logs": logs, "body": body}

with st.expander("â‘­ ì‹¤ê²€ì¦ ë ˆì‹œí”¼(ìë™ ê°•í™” ë£¨í”„)", expanded=False):
    ar_rounds = st.slider("ìµœëŒ€ REPAIR ë¼ìš´ë“œ", 1, 5, 3, key="ar_rounds")
    if st.button("ìë™ ê°•í™” ì‹¤í–‰", key="ar_btn"):
        ce = st.session_state.get("CE_GRAPH")
        if not ce:
            st.warning("ë¨¼ì € â‘  ì§ˆì˜â†’ê·¸ë˜í”„ ìƒì„± ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            out = auto_repair_loop(claim, ce, body_text, max_rounds=ar_rounds)
            st.session_state["AUTO_REPAIR"] = out
            st.json({"rounds": out["rounds"], "final": out["final"]["verdict"], "reason": out["final"]["reason"]})
            st.text_area("ë³´ê°• í›„ ë³¸ë¬¸", value=out["body"], height=200)

# ================================================================
# 15. UI í•œê¸€ í°íŠ¸/í…Œë§ˆ ë³´ê°• â€” CSS ì£¼ì…(ë¡œì»¬ í°íŠ¸ ë¶ˆê°€ ì‹œ ì‹œìŠ¤í…œ í°íŠ¸)
#   - Streamlitì€ ì „ì—­ CSSë¥¼ ê³µì‹ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì•ˆì „í•œ ìµœì†Œ ì£¼ì…
# ================================================================
def inject_korean_theme():
    st.markdown("""
    <style>
    html, body, [class*="css"]  {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
                     "Noto Sans KR", "Apple SD Gothic Neo", "Malgun Gothic",
                     "ë§‘ì€ ê³ ë”•", "AppleGothic", "NanumBarunGothic",
                     "Noto Sans", sans-serif !important;
        font-size: 16px;
        line-height: 1.6;
    }
    .stButton > button { border-radius: 12px; padding: 0.5rem 1rem; }
    .stSlider { padding-top: 0.25rem; }
    </style>
    """, unsafe_allow_html=True)

with st.expander("â‘® UI í•œê¸€ í…Œë§ˆ ì ìš©", expanded=False):
    if st.button("í…Œë§ˆ ì ìš©", key="theme_btn"):
        inject_korean_theme()
        st.success("í•œê¸€ ê°€ë…ì„± í…Œë§ˆ ì ìš© ì™„ë£Œ")

# ================================================================
# 16. ê¶Œí•œ/ì—­í• /ë³´í˜¸ë§‰(ê¸¸ë„ ìš°ì„ ê¶Œ) â€” ì†Œí”„íŠ¸ ê°€ë“œ
#   - 'ê¸¸ë„' ìš°ì„ ê¶Œ, ê¸ˆì¹™ íŒ¨í„´(REAL ìœ„ë°˜) ê°ì§€ ì‹œ ì°¨ë‹¨/ì •ì œ
#   - í•˜ë“œ ë¸”ë¡œí‚¹ì´ ì•„ë‹ˆë¼ ì‘ë‹µ ë‚´ ê²½ê³  í¬í•¨(ì†Œí”„íŠ¸ ê°€ë“œ)
# ================================================================
FORBIDDEN_PATTERNS = [
    r"ì´ˆê´‘ì†", r"\bì›Œí”„\b", r"\b11ì°¨ì›\b", r"\b13ì°¨ì›\b", r"ì˜ë§¤", r"ì˜ˆì–¸",
]
def violates_real_soft(text: str) -> Optional[str]:
    for pat in FORBIDDEN_PATTERNS:
        if re.search(pat, text, flags=re.IGNORECASE):
            return pat
    return None

def guard_request(user: str, text: str) -> Tuple[bool, str]:
    # ê¸¸ë„ ìš°ì„ ê¶Œ: ì‚¬ìš©ìëª…ì´ 'ê¸¸ë„'ë©´ í†µê³¼(ë‹¨, REAL ìœ„ë°˜ì€ ì •ì œ ë¬¸êµ¬)
    pat = violates_real_soft(text or "")
    if pat:
        return False, f"REAL ìœ„ë°˜ íŒ¨í„´ ê°ì§€({pat}). ê²€ì¦ ê°€ëŠ¥í•œ ê³¼í•™/ìˆ˜í•™/ì½”ë“œ ë²”ìœ„ë¡œ ì •ì œí•´ ì£¼ì„¸ìš”."
    return True, "ok"

with st.expander("â‘¯ ê¶Œí•œ/ì—­í• /ë³´í˜¸ë§‰(ê¸¸ë„ ìš°ì„ ê¶Œ)", expanded=False):
    who = st.text_input("ì‚¬ìš©ìëª…(ì˜ˆ: ê¸¸ë„)", value="ê¸¸ë„", key="guard_who")
    req = st.text_input("ìš”ì²­ë¬¸(í…ŒìŠ¤íŠ¸)", value="ì´ˆê´‘ì† ë“œë¼ì´ë¸Œ ì„¤ê³„", key="guard_req")
    if st.button("ê°€ë“œ ì ê²€", key="guard_btn"):
        ok, msg = guard_request(who, req)
        if ok:
            st.success("í†µê³¼")
        else:
            st.warning(msg)

# ================================================================
# 17. ë°°ì¹˜ ê²€ì¦ ìŠ¤ì¼€ì¤„ëŸ¬(ë¼ì´íŠ¸) â€” ì•± ë‚´ ê°„ì´ ìŠ¤ì¼€ì¤„(ìˆ˜ë™ íŠ¸ë¦¬ê±°)
#   - ë¯¸ë‹ˆ íì— ì‘ì—…ì„ ìŒ“ê³  ìˆœì°¨ ì‹¤í–‰(ì„¸ì…˜ ë‚´)
# ================================================================
if "BATCH_QUEUE" not in st.session_state:
    st.session_state["BATCH_QUEUE"] = []

def push_batch_job(job: Dict[str, Any]) -> None:
    st.session_state["BATCH_QUEUE"].append(job)

def run_next_job():
    if not st.session_state["BATCH_QUEUE"]:
        return None, "í ë¹„ì–´ìˆìŒ"
    job = st.session_state["BATCH_QUEUE"].pop(0)
    ce = UIS.build_ce_graph(job["claim"], UIS.search(job["query"], k=job.get("k",6))).to_dict()
    rep = run_quality_gate(job["claim"], ce, job["body"])
    return {"job": job, "report": rep, "ce_digest": ce["digest"]}, "ok"

with st.expander("â‘° ë°°ì¹˜ ê²€ì¦ ìŠ¤ì¼€ì¤„ëŸ¬", expanded=False):
    colQ1, colQ2 = st.columns(2)
    with colQ1:
        bj_claim = st.text_input("ë°°ì¹˜ Claim", "hâ‰ˆÎ”L/L ê²½ë¡œ", key="bj_claim")
        bj_query = st.text_input("ë°°ì¹˜ Query", "LIGO gravitational waves", key="bj_query")
        bj_body  = st.text_area("ë°°ì¹˜ Body", "ë‹¨ìœ„/ê·¼ê±°/ìˆ˜ì‹ í¬í•¨ í…ŒìŠ¤íŠ¸", key="bj_body", height=120)
        bj_k     = st.slider("k", 1, 12, 6, key="bj_k")
        if st.button("íì— ì¶”ê°€", key="bj_add"):
            push_batch_job({"claim": bj_claim, "query": bj_query, "body": bj_body, "k": bj_k})
            st.success("ì‘ì—… ì¶”ê°€")
    with colQ2:
        if st.button("ë‹¤ìŒ ì‘ì—… ì‹¤í–‰", key="bj_run_next"):
            out, msg = run_next_job()
            if out:
                st.json(out)
            else:
                st.info(msg)
    st.caption(f"ëŒ€ê¸° ì‘ì—… ìˆ˜: {len(st.session_state['BATCH_QUEUE'])}")

# ================================================================
# 18. ê²°ê³¼ ì¹´ë“œë·°(ëŒ€ì‹œ) â€” ìµœê·¼ ê²°ê³¼ë“¤ì„ ì¹´ë“œ í˜•íƒœë¡œ ìš”ì•½
#   - CE-digest, PASS/REPAIR, ë©”ì‹œì§€, ì‹œê°„
# ================================================================
if "RESULT_FEED" not in st.session_state:
    st.session_state["RESULT_FEED"] = []

def push_result_card(verdict: str, reason: str, ce_digest: str):
    st.session_state["RESULT_FEED"].insert(0, {
        "t": time.strftime("%H:%M:%S"),
        "v": verdict,
        "r": reason,
        "d": ce_digest[:12] if ce_digest else "-"
    })
    st.session_state["RESULT_FEED"] = st.session_state["RESULT_FEED"][:20]

with st.expander("â‘± ê²°ê³¼ ì¹´ë“œë·°(ìµœê·¼ 20)", expanded=False):
    # E2E/ê²€ì¦ ìˆ˜í–‰ í›„ í˜¸ì¶œ ê¶Œì¥ â€” ì—¬ê¸°ì„œëŠ” ë²„íŠ¼ í…ŒìŠ¤íŠ¸ ì œê³µ
    if st.button("í…ŒìŠ¤íŠ¸ ì¹´ë“œ ì¶”ê°€(PASS)", key="rc_pass"):
        push_result_card("PASS", "ok", "deadbeefcaf0")
    if st.button("í…ŒìŠ¤íŠ¸ ì¹´ë“œ ì¶”ê°€(REPAIR)", key="rc_rep"):
        push_result_card("REPAIR", "ë‹¨ìœ„/ì°¨ì› ìœ„ë°˜ìœ¨ ì´ˆê³¼", "badd00d00d00")
    if st.session_state["RESULT_FEED"]:
        cols = st.columns(3)
        for i, card in enumerate(st.session_state["RESULT_FEED"]):
            with cols[i % 3]:
                st.markdown(f"**[{card['t']}] {card['v']}**")
                st.caption(card["r"])
                st.code(card["d"])

# ================================================================
# 19. ì•ˆì „í•œ íŒŒì¼ ë·°ì–´ â€” í…ìŠ¤íŠ¸/JSON ë¯¸ë¦¬ë³´ê¸°(ìµœëŒ€ 50KB)
#   - ì•…ì„± ì‹¤í–‰ì„ í”¼í•˜ê¸° ìœ„í•´ ì½ê¸°ë§Œ í—ˆìš©
# ================================================================
def safe_preview_file(uploaded) -> Tuple[bool, str]:
    try:
        data = uploaded.read()
        if len(data) > 50_000:
            data = data[:50_000] + b"\n... (truncated)"
        try:
            txt = data.decode("utf-8")
        except Exception:
            txt = data.decode("latin-1", errors="replace")
        return True, txt
    except Exception as e:
        return False, f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}"

with st.expander("â‘² ì•ˆì „ íŒŒì¼ ë·°ì–´", expanded=False):
    up = st.file_uploader("í…ìŠ¤íŠ¸/JSON íŒŒì¼ ì—…ë¡œë“œ(ì½ê¸° ì „ìš©)", type=["txt","json","log","md"], key="safe_up")
    if up and st.button("ë¯¸ë¦¬ë³´ê¸°", key="safe_prev"):
        ok, txt = safe_preview_file(up)
        if ok:
            st.text(txt)
        else:
            st.error(txt)

# ================================================================
# 20. E2E-í™•ì¥ í›… â€” ëª¨ë“  ì£¼ìš” ë™ì‘ í›„ ê³µí†µ í›„ì²˜ë¦¬(ë¡œê·¸Â·ì¹´ë“œ)
#   - í•œ ê³³ì—ì„œ ê²°ê³¼ ê¸°ë¡/ëŒ€ì‹œ ê°±ì‹ ì„ ìˆ˜í–‰í•˜ë„ë¡ í›… ì œê³µ
# ================================================================
def e2e_post_hook(tag: str, claim: str, query: str, ce: Optional[Dict[str,Any]], report: Optional[Dict[str,Any]], reply: Optional[str]):
    # ë¡œê·¸ ì €ì¥
    path = log_gea_response(tag, {
        "claim": claim,
        "query": query,
        "ce_digest": (ce or {}).get("digest",""),
        "report": report,
        "reply": reply
    })
    # ê²°ê³¼ ì¹´ë“œ
    if report:
        push_result_card(report.get("verdict","?"), report.get("reason",""), (ce or {}).get("digest",""))
    st.caption(f"E2E í›…: ê¸°ë¡ë¨ â†’ {path}")

with st.expander("â‘³ í›… í…ŒìŠ¤íŠ¸(E2E í›„ì²˜ë¦¬)", expanded=False):
    if st.button("í›… ì‹¤í–‰(ìƒ˜í”Œ)", key="hook_test"):
        ce = st.session_state.get("CE_GRAPH")
        rep = st.session_state.get("GATE_REPORT")
        reply = st.session_state.get("INTERACT_REPLY")
        e2e_post_hook("hook-test", claim, query, ce, rep, reply)
        
        # =========================
# ëª¨ë“ˆ 1-3: GEA ì´ˆê²€ì¦ ë£¨í”„ (UIS ê¸°ë°˜)
# =========================
import os
import json
import random
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ê¸°ë³¸ê°’
GEA_VERIFY_ROUNDS = int(os.environ.get("GEA_VERIFY_ROUNDS", "30"))
GEA_VERIFY_AXES = [a.strip() for a in os.environ.get("GEA_VERIFY_AXES", "A,B,C").split(",") if a.strip()]
GEA_VERIFY_LOG = os.environ.get("GEA_VERIFY_LOG", "gea_verify_run.jsonl")

def _v_now():
    return datetime.utcnow().isoformat() + "Z"

def _v_log(line: dict):
    with open(GEA_VERIFY_LOG, "a", encoding="utf-8") as f:
        f.write(json.dumps(line, ensure_ascii=False) + "\n")

def run_verify_round(conn):
    stats = {a: {"n": 0, "pass": 0} for a in GEA_VERIFY_AXES}
    for i in range(GEA_VERIFY_ROUNDS):
        axis = GEA_VERIFY_AXES[i % len(GEA_VERIFY_AXES)]
        prompt = f"[ê²€ì¦-{i+1}/{GEA_VERIFY_ROUNDS}] ì¶•={axis} nonce={random.randrange(10**9)} ì˜ì‹/ì •ë³´ì¥ ê³µëª… ìš”ì•½"
        reply = conn.query(prompt)
        ok = conn.verify(reply)
        stats[axis]["n"] += 1
        stats[axis]["pass"] += int(ok)
        print(("âœ…" if ok else "âŒ"), axis, reply)
        _v_log({"t": _v_now(), "axis": axis, "ok": ok, "reply": reply})

    # ìš”ì•½ ì¶œë ¥
    overall_pass = sum(v["pass"] for v in stats.values())
    overall_n = sum(v["n"] for v in stats.values())
    print("\n[VERIFY] ê²°ê³¼ ìš”ì•½")
    for a, v in stats.items():
        rate = (v["pass"] / v["n"]) if v["n"] else 0.0
        print(f" - {a}: {v['pass']}/{v['n']}  (pass_rate={rate:.3f})")
    print(f" - overall: {overall_pass}/{overall_n} (pass_rate={(overall_pass / overall_n):.3f})")

# ì§„ì…ì 
if __name__ == "__main__" and os.environ.get("GEA_MODE", "").lower() == "verify":
    from gea_single import select_adapter, init_eternal_link
    adapter = select_adapter()
    conn = init_eternal_link(adapter)
    run_verify_round(conn)
    
    # ================================================================
# 21. Lâˆ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥/ì¬ê°œ â€” Resume í† í° ê¸°ë°˜ ì´ì–´ì“°ê¸°
#   - 08 ìŠ¤íŠ¸ë¦¬ë°ê³¼ ì—°ë™: ì„¸ê·¸ë¨¼íŠ¸ë¥¼ KVì— ë³´ê´€, ì¤‘ë‹¨ í›„ ì¬ê°œ
# ================================================================
RESUME_NS = "stream_resume"

def save_stream_state(name: str, data: Dict[str, Any]) -> str:
    h = _sha(json.dumps(data, ensure_ascii=False, sort_keys=True))
    kv_set(RESUME_NS, name, {"hash": h, "data": data, "ts": time.time()})
    return h

def load_stream_state(name: str) -> Optional[Dict[str, Any]]:
    return kv_get(RESUME_NS, name, None)

with st.expander("ã‰‘ Lâˆ ì´ì–´ì“°ê¸°(Resume í† í°)", expanded=False):
    colR1, colR2 = st.columns(2)
    with colR1:
        token_name = st.text_input("í† í° ì´ë¦„", value="default", key="res_token")
        if st.button("í˜„ì¬ ìŠ¤íŠ¸ë¦¼ ìƒíƒœ ì €ì¥", key="res_save"):
            st_state = st.session_state.get("STREAMING", {})
            if st_state and st_state.get("segments"):
                h = save_stream_state(token_name, st_state)
                st.success(f"ì €ì¥ ì™„ë£Œ: {h[:12]}")
            else:
                st.info("ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤. â‘§ì—ì„œ Start âˆ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    with colR2:
        token_name2 = st.text_input("ë¶ˆëŸ¬ì˜¬ í† í° ì´ë¦„", value="default", key="res_token2")
        if st.button("ë¶ˆëŸ¬ì™€ì„œ ì¬ê°œ", key="res_load"):
            pack = load_stream_state(token_name2)
            if pack:
                st.session_state["STREAMING"] = pack["data"]
                st.session_state["STREAMING"]["running"] = True
                st.success(f"ì¬ê°œ ì‹œì‘: {pack['hash'][:12]}")
            else:
                st.warning("í•´ë‹¹ í† í° ì—†ìŒ")

# ================================================================
# 22. í”ŒëŸ¬ê·¸ì¸ ìŠ¬ë¡¯(í•«ìŠ¤ì™‘) â€” ê°„ë‹¨ ì™¸ë¶€ í•¨ìˆ˜ ì£¼ì…(ë³´ì•ˆ ì œí•œì )
#   - ë¬¸ìì—´ë¡œ ë°›ì€ 'ì•ˆì „í•œ' íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ë§Œ ì‹¤í–‰(í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í‚¤ì›Œë“œ)
#   - ì‹¤ì œ ì™¸ë¶€ ì½”ë“œ ì‹¤í–‰ ëŒ€ì‹ , ì œí•œëœ ë¯¸ë‹ˆ DSL í˜•íƒœ
# ================================================================
SAFE_FUNCS = {
    "append_evidence": lambda body: body + "\nê·¼ê±°: src:https://losc.ligo.org, src:https://physics.nist.gov/constants",
    "add_units_note":  lambda body: body + "\në‹¨ìœ„ ì£¼ì„: Î”L[m], L[m], ë¹„ìœ¨ì€ ë¬´ì°¨ì›.",
    "add_stats_note":  lambda body: body + "\ní†µê³„: ê²€ì • pâ‰¤0.005 ì¶©ì¡± ì¡°ê±´ ëª…ì‹œ.",
}

def run_safe_plugin(seq: List[str], body: str) -> str:
    out = body
    for name in seq:
        fn = SAFE_FUNCS.get(name)
        if fn:
            out = fn(out)
    return out

with st.expander("ã‰’ í”ŒëŸ¬ê·¸ì¸ ìŠ¬ë¡¯(í•«ìŠ¤ì™‘)", expanded=False):
    body_in = st.text_area("ë³¸ë¬¸(ë³´ê°• ì „)", height=120, key="plg_body")
    chosen = st.multiselect("ë³´ê°• í•¨ìˆ˜ ì„ íƒ", list(SAFE_FUNCS.keys()), default=["append_evidence","add_units_note"])
    if st.button("ì ìš©", key="plg_apply"):
        out = run_safe_plugin(chosen, body_in)
        st.text_area("ë³´ê°• ê²°ê³¼", out, height=160)

# ================================================================
# 23. ëª¨ë¸ êµì°¨í‰ê°€ ìŠ¤í… â€” GPT/Grok ë¹„êµ(ìˆ˜ë™ ì…ë ¥)
#   - ì™¸ë¶€ API í˜¸ì¶œ ì—†ìŒ. ì‚¬ìš©ìê°€ ë‘ ëª¨ë¸ì˜ ì‘ë‹µì„ ë¶™ì—¬ë„£ìœ¼ë©´ í’ˆì§ˆ ì§€í‘œë¥¼ ë¹„êµ
# ================================================================
def compare_two_responses(claim: str, ce_graph: Optional[Dict[str,Any]], body_a: str, body_b: str) -> Dict[str,Any]:
    mA = make_metrics(ce_graph, body_a)
    mB = make_metrics(ce_graph, body_b)
    def score(m: Metrics) -> float:
        base = 0.0
        base += 1.0 if m.ce_coverage >= SIGNAL_BASELINES["ce_min"] else 0.0
        base += 1.0 if m.citation_coverage >= SIGNAL_BASELINES["cite_min"] else 0.0
        base += 1.0 if m.reproducibility >= SIGNAL_BASELINES["repr_min"] else 0.0
        base += 1.0 if m.logic_violation <= SIGNAL_BASELINES["logic_max"] else 0.0
        base += 1.0 if m.unit_dim_violation <= SIGNAL_BASELINES["unit_max"] else 0.0
        base += 1.0 if m.surprise_p <= SIGNAL_BASELINES["surp_max"] else 0.0
        return base
    sA, sB = score(mA), score(mB)
    verdict = "A" if sA > sB else ("B" if sB > sA else "TIE")
    return {"A": mA.as_dict(), "B": mB.as_dict(), "scoreA": sA, "scoreB": sB, "winner": verdict}

with st.expander("ã‰“ ëª¨ë¸ êµì°¨í‰ê°€(ìˆ˜ë™ ë¶™ì—¬ë„£ê¸°)", expanded=False):
    claim_cmp = st.text_input("Claim(ë¹„êµ ê¸°ì¤€)", value=claim, key="cmp_claim")
    ce_cmp = st.session_state.get("CE_GRAPH")
    bodyA = st.text_area("ì‘ë‹µ A", height=120, key="cmp_A")
    bodyB = st.text_area("ì‘ë‹µ B", height=120, key="cmp_B")
    if st.button("ë¹„êµ ì‹¤í–‰", key="cmp_run"):
        res = compare_two_responses(claim_cmp, ce_cmp, bodyA, bodyB)
        st.json(res)
        st.success(f"ìŠ¹ì: {res['winner']}")

# ================================================================
# 24. ìë™ ì €ì¥(Autosave) â€” ì…ë ¥ ë³€ê²½ ê°ì§€ í›„ ì§§ì€ ìŠ¤ëƒ…ìƒ· ì €ì¥
#   - claim/query/body_textì„ í•©ì³ì„œ KVì— ì£¼ê¸°ì ìœ¼ë¡œ ê¸°ë¡
# ================================================================
def autosave_snapshot():
    payload = {
        "claim": claim,
        "query": query,
        "body_text": body_text,
        "ts": time.time(),
    }
    kv_set("autosave", "last", payload)

with st.expander("ã‰” ìë™ ì €ì¥(Autosave)", expanded=False):
    if st.button("ì§€ê¸ˆ ì €ì¥", key="as_now"):
        autosave_snapshot()
        st.success("ì €ì¥ë¨")
    if st.button("ìµœê·¼ ìŠ¤ëƒ…ìƒ· ë³´ê¸°", key="as_view"):
        st.json(kv_get("autosave", "last", {}))

# ================================================================
# 25. ì›Œì¹˜ë…(Watchdog) â€” ìƒíƒœ ì´ìƒ ê°ì§€/ë¦¬ì…‹ ë„ìš°ë¯¸
#   - CE ê·¸ë˜í”„/ê²Œì´íŠ¸ ê²°ê³¼/ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœë¥¼ ì ê²€í•˜ê³  ê°„ë‹¨ ë¦¬ì…‹ ë²„íŠ¼ ì œê³µ
# ================================================================
def watchdog_status() -> Dict[str,Any]:
    ce = st.session_state.get("CE_GRAPH")
    g  = st.session_state.get("GATE_REPORT")
    stg = st.session_state.get("STREAMING", {})
    return {
        "ce_set": bool(ce),
        "gate_set": bool(g),
        "gate_verdict": (g or {}).get("verdict"),
        "stream_running": bool(stg.get("running")),
        "stream_seg_left": max(0, len(stg.get("segments", [])) - stg.get("idx", 0))
    }

def watchdog_reset(kind: str):
    if kind == "ce": st.session_state.pop("CE_GRAPH", None)
    if kind == "gate": st.session_state.pop("GATE_REPORT", None)
    if kind == "stream":
        st.session_state["STREAMING"] = {"running": False, "segments": [], "idx": 0}

with st.expander("ã‰• ì›Œì¹˜ë…(ìƒíƒœ ì ê²€/ë¦¬ì…‹)", expanded=False):
    st.json(watchdog_status())
    colW1, colW2, colW3 = st.columns(3)
    with colW1:
        if st.button("CE ì´ˆê¸°í™”", key="wd_ce"):
            watchdog_reset("ce"); st.success("CE ì´ˆê¸°í™”")
    with colW2:
        if st.button("ê²Œì´íŠ¸ ì´ˆê¸°í™”", key="wd_gate"):
            watchdog_reset("gate"); st.success("ê²Œì´íŠ¸ ì´ˆê¸°í™”")
    with colW3:
        if st.button("ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”", key="wd_stream"):
            watchdog_reset("stream"); st.success("ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”")

# ================================================================
# 26. ë¯¸ë‹ˆ ëª©í‘œë³´ë“œ â€” ëª©í‘œ/ë§ˆì¼ìŠ¤í†¤/ë©”ëª¨(ì„¸ì…˜ ì €ì¥)
# ================================================================
if "GOALBOARD" not in st.session_state:
    st.session_state["GOALBOARD"] = {
        "milestones": [],
        "notes": []
    }

def add_milestone(text: str):
    st.session_state["GOALBOARD"]["milestones"].append({"t": time.time(), "text": _norm(text)})

def add_note(text: str):
    st.session_state["GOALBOARD"]["notes"].append({"t": time.time(), "text": _norm(text)})

with st.expander("ã‰– ëª©í‘œë³´ë“œ(ë§ˆì¼ìŠ¤í†¤/ë©”ëª¨)", expanded=False):
    mtxt = st.text_input("ë§ˆì¼ìŠ¤í†¤ ì¶”ê°€", key="gb_ms")
    if st.button("ì¶”ê°€", key="gb_ms_add") and mtxt.strip():
        add_milestone(mtxt); st.success("ì¶”ê°€ë¨")
    ntxt = st.text_input("ë©”ëª¨ ì¶”ê°€", key="gb_note")
    if st.button("ê¸°ë¡", key="gb_note_add") and ntxt.strip():
        add_note(ntxt); st.success("ê¸°ë¡ë¨")
    st.write("**Milestones**")
    for m in st.session_state["GOALBOARD"]["milestones"][-10:][::-1]:
        st.markdown(f"- {time.strftime('%m/%d %H:%M:%S', time.localtime(m['t']))} Â· {m['text']}")
    st.write("**Notes**")
    for n in st.session_state["GOALBOARD"]["notes"][-10:][::-1]:
        st.markdown(f"- {time.strftime('%m/%d %H:%M:%S', time.localtime(n['t']))} Â· {n['text']}")
        
        # ================================================================
# 27. ë¦¬í”Œë ˆì´/ì¬í˜„ ë„êµ¬ â€” ë¡œê·¸ì—ì„œ ì„ íƒâ†’CE/ê²Œì´íŠ¸/ì‘ë‹µ ì¬í˜„
#   - gea_logs/*.jsonl ì¤‘ ì„ íƒí•œ í–‰ ì¬í˜„(ê°€ëŠ¥í•œ í•„ë“œë§Œ ì‚¬ìš©)
# ================================================================
from glob import glob

def list_log_files() -> List[str]:
    if not os.path.isdir(LOG_DIR):
        return []
    files = sorted(glob(os.path.join(LOG_DIR, "gea_log_*.jsonl")))
    return files[-8:]  # ìµœê·¼ 8ê°œê¹Œì§€ë§Œ

def load_jsonl_lines(path: str, limit: int = 1000) -> List[Dict[str, Any]]:
    out = []
    try:
        with open(path, "r", encoding="utf-8") as f:
            for i, line in enumerate(f):
                if i >= limit: break
                line = line.strip()
                if not line: continue
                try:
                    out.append(json.loads(line))
                except Exception:
                    pass
    except Exception:
        pass
    return out

with st.expander("ã‰— ë¦¬í”Œë ˆì´/ì¬í˜„ ë„êµ¬", expanded=False):
    files = list_log_files()
    if not files:
        st.info("ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (E2E ì‹¤í–‰ í›„ ìë™ ê¸°ë¡ë©ë‹ˆë‹¤.)")
    else:
        lf = st.selectbox("ë¡œê·¸ íŒŒì¼ ì„ íƒ", files, index=len(files)-1)
        rows = load_jsonl_lines(lf, limit=1000)
        idx = st.number_input("í–‰ ë²ˆí˜¸(0ë¶€í„°)", min_value=0, max_value=max(0, len(rows)-1), value=0, step=1)
        if st.button("ì„ íƒ í–‰ ë³´ê¸°", key="rp_show"):
            st.json(rows[idx])
        if st.button("ì¬í˜„ ì‹¤í–‰(ê°€ëŠ¥í•œ í•œ)", key="rp_run"):
            row = rows[idx]
            data = row.get("data", {})
            claim_r = data.get("claim") or claim
            query_r = data.get("query") or query
            body_r  = (data.get("report") or {}).get("metrics") and body_text or body_text
            # CE ì¬êµ¬ì„±
            hits = UIS.search(query_r or claim_r, k=6)
            ce_r = UIS.build_ce_graph(claim_r or query_r or "replay-claim", hits).to_dict()
            rep_r = run_quality_gate(claim_r, ce_r, body_r or "hâ‰ˆÎ”L/L, ë‹¨ìœ„ m/m, src:https://losc.ligo.org")
            cfg = InteractConfig(active_mode=True, persona_name="ì—ì•„", creator_name="ê¸¸ë„")
            eng = InteractionEngine(cfg)
            reply_r = eng.generate(user_text=f"[ë¦¬í”Œë ˆì´] {claim_r}", response_level=8, ce_graph=ce_r, goals=st.session_state.GEA_GOALS)
            st.json({"ce_digest": ce_r["digest"][:12], "report": rep_r})
            st.write(reply_r)

# ================================================================
# 28. ì„±ëŠ¥ í”„ë¡œíŒŒì¼ëŸ¬(ë¼ì´íŠ¸) â€” ë‹¨ê³„ë³„ ì†Œìš”ì‹œê°„ ì¸¡ì •
#   - ì§ˆì˜â†’ê·¸ë˜í”„, ê²Œì´íŠ¸, ì‘ë‹µ ìƒì„±ì„ ê°ê° íƒ€ì´ë°
# ================================================================
import time as _t

def profile_once(claim_p: str, query_p: str, body_p: str, k_p: int=6) -> Dict[str, Any]:
    t0 = _t.perf_counter()
    hits = UIS.search(query_p or claim_p, k=k_p)
    ce = UIS.build_ce_graph(claim_p or query_p or "profile-claim", hits).to_dict()
    t1 = _t.perf_counter()
    rep = run_quality_gate(claim_p, ce, body_p or "")
    t2 = _t.perf_counter()
    cfg = InteractConfig(active_mode=True, persona_name="ì—ì•„", creator_name="ê¸¸ë„")
    eng = InteractionEngine(cfg)
    reply = eng.generate(user_text="í”„ë¡œíŒŒì¼ìš© ì‘ë‹µ ìƒì„±", response_level=8, ce_graph=ce, goals=st.session_state.GEA_GOALS)
    t3 = _t.perf_counter()
    return {
        "t_query_ce_ms": round((t1 - t0) * 1000, 2),
        "t_gate_ms": round((t2 - t1) * 1000, 2),
        "t_reply_ms": round((t3 - t2) * 1000, 2),
        "reply_clip": _clip(reply, 160)
    }

with st.expander("ã‰˜ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ëŸ¬(ë¼ì´íŠ¸)", expanded=False):
    prof_runs = st.slider("ë°˜ë³µ íšŸìˆ˜", 1, 10, 3, key="prof_runs")
    if st.button("í”„ë¡œíŒŒì¼ ì‹¤í–‰", key="prof_btn"):
        recs = []
        for _ in range(prof_runs):
            recs.append(profile_once(claim, query, body_text, k_p=k))
        st.json({
            "avg_t_query_ce_ms": round(sum(r["t_query_ce_ms"] for r in recs)/len(recs), 2),
            "avg_t_gate_ms": round(sum(r["t_gate_ms"] for r in recs)/len(recs), 2),
            "avg_t_reply_ms": round(sum(r["t_reply_ms"] for r in recs)/len(recs), 2),
        })
        st.write("ìƒ˜í”Œ ì‘ë‹µ:")
        st.code(recs[-1]["reply_clip"])

# ================================================================
# 29. í”„ë¡œì íŠ¸ ë§¤ë‹ˆí˜ìŠ¤íŠ¸/ë¬´ê²°ì„± â€” íŒŒì¼ í•´ì‹œ ëª©ë¡ + ê²€ì¦
#   - í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ì£¼ìš” íŒŒì¼ í•´ì‹œ(SHA-256) ìƒì„±/ë¹„êµ
# ================================================================
MANIFEST = "gea_manifest.json"

def make_manifest(include_ext=(".py",".json",".jsonl",".txt",".md")) -> Dict[str, Any]:
    man = {"generated_at": time.time(), "files": {}}
    for fn in os.listdir("."):
        if not os.path.isfile(fn): continue
        if not fn.endswith(include_ext): continue
        try:
            with open(fn, "rb") as f:
                b = f.read()
            man["files"][fn] = {
                "sha256": hashlib.sha256(b).hexdigest(),
                "bytes": len(b)
            }
        except Exception:
            pass
    return man

def save_manifest(man: Dict[str,Any], path: str = MANIFEST):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(man, f, ensure_ascii=False, indent=2)

def load_manifest(path: str = MANIFEST) -> Optional[Dict[str,Any]]:
    if not os.path.exists(path): return None
    try:
        return json.loads(open(path, "r", encoding="utf-8").read())
    except Exception:
        return None

def diff_manifest(old: Dict[str,Any], new: Dict[str,Any]) -> Dict[str,Any]:
    out = {"added": [], "removed": [], "changed": []}
    oldf = old.get("files", {}); newf = new.get("files", {})
    for k in newf:
        if k not in oldf: out["added"].append(k)
        elif oldf[k]["sha256"] != newf[k]["sha256"]: out["changed"].append(k)
    for k in oldf:
        if k not in newf: out["removed"].append(k)
    return out

with st.expander("ã‰™ í”„ë¡œì íŠ¸ ë§¤ë‹ˆí˜ìŠ¤íŠ¸/ë¬´ê²°ì„±", expanded=False):
    colM1, colM2 = st.columns(2)
    with colM1:
        if st.button("ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±/ì €ì¥", key="mf_make"):
            man = make_manifest()
            save_manifest(man)
            st.success(f"ìƒì„±ë¨ â†’ {MANIFEST}")
            st.json(man)
    with colM2:
        if st.button("í˜„ì¬ì™€ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë¹„êµ", key="mf_diff"):
            old = load_manifest()
            if not old:
                st.warning("ê¸°ì¡´ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")
            else:
                new = make_manifest()
                st.json(diff_manifest(old, new))

# ================================================================
# 30. í•œêµ­ì–´ í”„ë¦¬ì…‹(ìë™ ì ìš©) + ë ˆì´ì•„ì›ƒ ìŠ¤ëƒ…ìƒ·
#   - ì•± ë¡œë“œì‹œ ìë™ìœ¼ë¡œ ê°€ë…ì„± í…Œë§ˆ ì ìš©(ì¤‘ë³µ í˜¸ì¶œ ì•ˆì „)
#   - ì‚¬ì´ë“œë°” ìƒíƒœ/ëª©í‘œì¹´ë“œ/ëª¨ë“œ ì„¤ì •ì„ KVì— ìŠ¤ëƒ…ìƒ·
# ================================================================
def apply_korean_preset_once():
    # 15ë²ˆì˜ inject_korean_theme()ê°€ ì¡´ì¬í•˜ë©´ í˜¸ì¶œ
    try:
        inject_korean_theme()
    except Exception:
        pass

def snapshot_layout_state():
    snap = {
        "goals": st.session_state.get("GEA_GOALS", {}),
        "active_mode": st.session_state.get("ACTIVE_MODE", True),
        "toc": st.session_state.get("GEA_TOC", []),
        "ts": time.time()
    }
    kv_set("layout", "last", snap)
    return snap

with st.expander("ã‰š í•œêµ­ì–´ í”„ë¦¬ì…‹/ë ˆì´ì•„ì›ƒ ìŠ¤ëƒ…ìƒ·", expanded=False):
    if st.button("í•œê¸€ í”„ë¦¬ì…‹ ì¦‰ì‹œ ì ìš©", key="ko_preset"):
        apply_korean_preset_once(); st.success("ì ìš© ì™„ë£Œ")
    colL1, colL2 = st.columns(2)
    with colL1:
        if st.button("ë ˆì´ì•„ì›ƒ ìŠ¤ëƒ…ìƒ· ì €ì¥", key="lo_save"):
            snap = snapshot_layout_state()
            st.json(snap); st.success("ì €ì¥ë¨")
    with colL2:
        if st.button("ë ˆì´ì•„ì›ƒ ìŠ¤ëƒ…ìƒ· ë³´ê¸°", key="lo_view"):
            st.json(kv_get("layout","last", {}))

# ì•± êµ¬ë™ ì‹œ ìë™ìœ¼ë¡œ í”„ë¦¬ì…‹ 1íšŒ ì ìš©(ì¤‘ë³µ ì•ˆì „)
apply_korean_preset_once()

# ================================================================
# 31. ìš°ì£¼ì •ë³´ì¥ ì‹¤ì—°ë™ í™•ì¥(ë¼ì´íŠ¸) â€” ì»¤ë„¥í„°/íŒŒì„œ/CE ì •ë°€ë§í¬
#   - ê¸°ì¡´ UISê°€ ì—†ë‹¤ë©´ ì•ˆì „í•œ ìŠ¤í… ìƒì„±(ìˆìœ¼ë©´ ì ˆëŒ€ ë®ì–´ì“°ì§€ ì•ŠìŒ)
#   - ì»¤ë„¥í„°: httpbin/json, raw í…ìŠ¤íŠ¸, ê°„ë‹¨ í‚¤ì›Œë“œ íŒŒì„œ
# ================================================================
try:
    UIS  # ì¡´ì¬í•˜ë©´ ì‚¬ìš©
except NameError:
    # 10ë²ˆ ë¸”ë¡ì˜ http_fetch_textê°€ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì•ˆì „ ì •ì˜
    try:
        http_fetch_text  # ì¡´ì¬ í™•ì¸
    except NameError:
        from urllib.request import urlopen, Request
        from urllib.error import URLError, HTTPError
        def http_fetch_text(url: str, timeout: int = 5):
            try:
                req = Request(url, headers={"User-Agent": "GEA/0.6"})
                with urlopen(req, timeout=timeout) as r:
                    data = r.read()
                text = data.decode("utf-8", errors="replace")
                if len(text) > 2000:
                    text = text[:2000] + "\n... (truncated)"
                return True, text
            except (HTTPError, URLError) as e:
                return False, f"HTTP ì˜¤ë¥˜: {e}"
            except Exception as e:
                return False, f"ê¸°íƒ€ ì˜¤ë¥˜: {e}"

    class _MiniHit(dict):
        pass

    class _UISStub:
        """ì•ˆì „ ìŠ¤í…: ê°„ë‹¨ ê²€ìƒ‰/CE-ê·¸ë˜í”„ ìƒì„± (ì˜¤í”„ë¼ì¸/ë¼ì´íŠ¸)"""
        def search(self, q: str, k: int = 6):
            seeds = [
                ("https://httpbin.org/json", "json"),
                ("https://httpbin.org/uuid", "uuid"),
                ("https://httpbin.org/headers", "headers"),
            ]
            hits = []
            for i, (u, tag) in enumerate(seeds[:k]):
                ok, text = http_fetch_text(u)
                hits.append(_MiniHit({
                    "id": f"doc{i+1}",
                    "source": u,
                    "tag": tag,
                    "score": 0.9 - i*0.05,
                    "span": [0, min(len(text),100)]
                }))
            if not hits:  # ì˜¤í”„ë¼ì¸ í™˜ê²½ ëŒ€ë¹„
                for i in range(k):
                    hits.append(_MiniHit({
                        "id": f"offline{i+1}",
                        "source": f"offline://seed/{i+1}",
                        "tag": "offline",
                        "score": 0.5 - i*0.03,
                        "span": [0, 0]
                    }))
            return hits

        def build_ce_graph(self, claim: str, hits):
            import hashlib, json
            nodes = [{"id": f"claim:{hashlib.sha256(claim.encode('utf-8')).hexdigest()[:12]}",
                      "kind": "claim", "payload": {"text": claim}}]
            edges = []
            for h in hits:
                nid = f"evi:{h['id']}"
                nodes.append({"id": nid, "kind": "evidence",
                              "payload": {"source": h["source"], "score": h["score"], "span": h["span"]}})
                edges.append({"src": nid, "dst": nodes[0]["id"], "rel": "supports"})
            digest = hashlib.sha256(json.dumps({"nodes":nodes,"edges":edges}, sort_keys=True).encode()).hexdigest()
            class _CEDict:
                def __init__(self, d): self._d = d
                def to_dict(self): return self._d
            return _CEDict({"nodes": nodes, "edges": edges, "digest": digest})

    UIS = _UISStub()  # ìŠ¤í… í™œì„±í™”


# ================================================================
# 32. ì¦ê±° ë­í¬ ê³ ë„í™” â€” ê·¼ê±°/ë‹¨ìœ„/ì¬í˜„ì„± ê°€ì¤‘ì¹˜ ì¬ì •ë ¬
#   - ê°„ë‹¨ ê°€ì¤‘ì¹˜ ëª¨ë¸: score_w = 0.6*ê²€ìƒ‰ì ìˆ˜ + 0.2*ë‹¨ìœ„ì–¸ê¸‰ + 0.2*ì¬í˜„í‚¤ì›Œë“œ
# ================================================================
_WEIGHT_UNIT_KEYS = ["ë‹¨ìœ„", "unit", "m/s", "kg", "N", "Hz"]
_WEIGHT_REPR_KEYS = ["ì¬í˜„", "replicate", "repeat", "step", "method"]

def _weight_keywords(text: str, keys):
    if not text: return 0
    t = text.lower()
    return sum(1 for k in keys if k.lower() in t)

def rerank_hits_with_evidence(hits, previews: dict) -> list:
    ranked = []
    for h in hits:
        src = h.get("source","")
        txt = previews.get(src, "")
        w_unit = _weight_keywords(txt, _WEIGHT_UNIT_KEYS)
        w_repr = _weight_keywords(txt, _WEIGHT_REPR_KEYS)
        score_w = 0.6*h.get("score",0) + 0.2*(1 if w_unit>0 else 0) + 0.2*(1 if w_repr>0 else 0)
        h2 = dict(h); h2["score_w"] = round(score_w,3); h2["unit_hit"] = w_unit>0; h2["repr_hit"] = w_repr>0
        ranked.append(h2)
    ranked.sort(key=lambda x: x["score_w"], reverse=True)
    return ranked

with st.expander("ã‰› ì¦ê±° ë­í¬ ê³ ë„í™”(ì¬ì •ë ¬)", expanded=False):
    rq = st.text_input("ë­í¬ìš© ì§ˆì˜", value=st.session_state.get("GEA_GOALS",{}).get("primary","LIGO/NIST í…ŒìŠ¤íŠ¸") or "physics test", key="rr_q")
    k_rr = st.slider("íƒìƒ‰ k", 1, 10, 6, key="rr_k")
    if st.button("ê²€ìƒ‰â†’ë¯¸ë¦¬ë³´ê¸°â†’ì¬ë­í¬", key="rr_go"):
        hits = UIS.search(rq, k=k_rr)
        previews = {}
        for h in hits:
            ok, txt = http_fetch_text(h["source"]) if h["source"].startswith("http") else (True, "")
            previews[h["source"]] = txt if ok else ""
        ranked = rerank_hits_with_evidence(hits, previews)
        st.session_state["RRANK"] = {"hits": ranked, "previews": previews}
        st.json({"top3": [{k:v for k,v in ranked[i].items() if k in ("id","source","score_w","unit_hit","repr_hit")} for i in range(min(3,len(ranked)))]})


# ================================================================
# 33. ê²€ì¦ ë ˆì‹œí”¼ ê³ ë„í™” â€” ì²´í¬ë¦¬ìŠ¤íŠ¸/í…œí”Œë¦¿/í•­ëª©ë³„ PASS
#   - ë‹¨ìœ„, ê·¼ê±°ë§í¬, ì¬í˜„ì ˆì°¨, ë†€ë¼ì›€ p, ë…¼ë¦¬ìˆœì„œ ì²´í¬ í›„ ìš”ì•½í‘œ
# ================================================================
_CHECK_ITEMS = [
    ("ë‹¨ìœ„ í‘œê¸°", lambda b: any(x in b for x in ["ë‹¨ìœ„", "unit", "[", "]"])),
    ("ê·¼ê±° ë§í¬", lambda b: "http" in b or "src:" in b),
    ("ì¬í˜„ ì ˆì°¨", lambda b: any(x in b for x in ["ì¬í˜„", "ì ˆì°¨", "method", "step"])),
    ("ë†€ë¼ì›€ p",  lambda b: "pâ‰¤" in b or "p<=" in b or "p-value" in b.lower()),
    ("ë…¼ë¦¬ ìˆœì„œ", lambda b: any(x in b for x in ["â‘ ","â‘¡","â‘¢","ì „ì œ","ê²°ë¡ ","ë”°ë¼ì„œ"])),
]

def make_checklist_report(body: str) -> dict:
    rows = []
    passed = 0
    for name, fn in _CHECK_ITEMS:
        ok = bool(fn(body or ""))
        rows.append({"item": name, "pass": ok})
        if ok: passed += 1
    return {"total": len(_CHECK_ITEMS), "passed": passed, "rows": rows, "score": round(passed/len(_CHECK_ITEMS),2)}

with st.expander("ã‰œ ê²€ì¦ ë ˆì‹œí”¼ ê³ ë„í™”(ì²´í¬ë¦¬ìŠ¤íŠ¸)", expanded=False):
    b_in = st.text_area("ë³¸ë¬¸ ì…ë ¥", value="ì¤‘ë ¥íŒŒ: hâ‰ˆÎ”L/L, ë‹¨ìœ„ ë¬´ì°¨ì›, ì¬í˜„ ì ˆì°¨ í¬í•¨, pâ‰¤0.005, â‘ ë°ì´í„° â‘¡ê³„ì‚° â‘¢ê²°ë¡ ", height=120, key="chk_in")
    if st.button("ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±", key="chk_btn"):
        rep = make_checklist_report(b_in)
        st.json(rep)
        st.table(rep["rows"])


# ================================================================
# 34. í™•ì¥ ì¸í„°ë™ì…˜ ë£¨í”„ â€” í™œì„± ëª¨ë“œ ì œì•ˆ/ë‹¤ìŒ í–‰ë™/ëª©í‘œ ë°˜ì˜
#   - ACTIVE_MODEê°€ Trueë©´: ë‹¤ìŒ í–‰ë™ ì œì•ˆ/ê·¼ê±° ë³´ê°•/ì²´í¬ë¦¬ìŠ¤íŠ¸ ìë™
#   - Falseë©´: ì‘ë‹µë§Œ ìƒì„±(í˜„í–‰ê³¼ ë™ì¼)
# ================================================================
def interactive_step(user_txt: str, level: int = 8):
    ce = st.session_state.get("CE_GRAPH")
    cfg = InteractConfig(active_mode=st.session_state.get("ACTIVE_MODE", True),
                         persona_name="ì—ì•„", creator_name="ê¸¸ë„")
    eng = InteractionEngine(cfg)
    reply = eng.generate(user_text=user_txt, response_level=level, ce_graph=ce, goals=st.session_state.GEA_GOALS)
    plan = None; checklist = None
    if st.session_state.get("ACTIVE_MODE", True):
        # ê°„ë‹¨í•œ ë‹¤ìŒ í–‰ë™ ì œì•ˆ
        plan = {
            "next_actions": [
                "ì¦ê±° ë¯¸ë¦¬ë³´ê¸° ìƒìœ„3ê°œ ì¬ë­í¬(ã‰›)",
                "REPAIR ë£¨í”„(â‘­) 1íšŒ ì‹¤í–‰",
                "ì²´í¬ë¦¬ìŠ¤íŠ¸(ã‰œ)ë¡œ í•­ëª© ë³´ê°•"
            ],
            "hint": "CE-Graphê°€ ë¹„ì–´ ìˆìœ¼ë©´ â‘  ì§ˆì˜â†’ê·¸ë˜í”„ ìƒì„± ë¨¼ì € ì‹¤í–‰"
        }
        checklist = make_checklist_report(reply)
    return reply, plan, checklist

with st.expander("ã‰ í™•ì¥ ì¸í„°ë™ì…˜ ë£¨í”„(í™œì„± ëª¨ë“œ ì—°ë™)", expanded=False):
    txt = st.text_input("ì§ˆë¬¸/ìš”ì²­", value="ì—ì•„, ì˜¤ëŠ˜ ì‹¤í—˜ ê³„íšì„ ìš”ì•½í•´ì¤˜.", key="ixq")
    lvl = st.slider("ì‘ë‹µ ë ˆë²¨", 1, 999, 8, key="ixlvl")
    if st.button("ì‹¤í–‰", key="ix_btn"):
        reply, plan, checklist = interactive_step(txt, lvl)
        st.session_state["INTERACT_REPLY_EX"] = reply
        st.write(reply)
        if plan: st.json(plan)
        if checklist: st.json(checklist)


# ================================================================
# 35. ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸ íŒ¨ë„ â€” ê²€ìƒ‰â†’CEâ†’ê²Œì´íŠ¸â†’ì‘ë‹µâ†’REPAIRâ†’E2E í›…
#   - í•œ ë²„íŠ¼ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ ì¢…ë‹¨ í…ŒìŠ¤íŠ¸, ì¹´ë“œ/ë¡œê·¸/ìš”ì•½ê¹Œì§€
# ================================================================
def end_to_end_once(claim_t: str, query_t: str, body_t: str, k_t: int = 6) -> dict:
    # 1) ê²€ìƒ‰â†’CE
    hits = UIS.search(query_t or claim_t, k=k_t)
    ce   = UIS.build_ce_graph(claim_t or query_t or "e2e-claim", hits).to_dict()
    # 2) ê²Œì´íŠ¸
    gate = run_quality_gate(claim_t, ce, body_t)
    # 3) ì‘ë‹µ
    cfg = InteractConfig(active_mode=True, persona_name="ì—ì•„", creator_name="ê¸¸ë„")
    eng = InteractionEngine(cfg)
    reply = eng.generate(user_text=f"[E2E] {claim_t}", response_level=8, ce_graph=ce, goals=st.session_state.GEA_GOALS)
    # 4) í•„ìš” ì‹œ REPAIR 1íšŒ
    if gate["verdict"] != "PASS":
        repaired = auto_repair_loop(claim_t, ce, body_t, max_rounds=1)
        body_t = repaired["body"]
        gate = repaired["final"]
    # 5) E2E í›…
    e2e_post_hook("e2e", claim_t, query_t, ce, gate, reply)
    return {"ce_digest": ce["digest"], "verdict": gate["verdict"], "reason": gate["reason"], "reply": _clip(reply, 200)}

with st.expander("ã‰ ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸(E2E)", expanded=False):
    c = st.text_input("Claim", value="hâ‰ˆÎ”L/L ê²½ë¡œ ì„¤ëª…ê³¼ ì¬í˜„ ì ˆì°¨", key="e2e_c")
    q = st.text_input("Query", value="LIGO gravitational waves", key="e2e_q")
    b = st.text_area("Body", value="ë‹¨ìœ„: Î”L[m], L[m] â†’ ë¬´ì°¨ì›. ê·¼ê±°: src:https://losc.ligo.org. ì¬í˜„: ë™ì¼ ë°ì´í„° ì¬ê³„ì‚°. pâ‰¤0.005.", height=100, key="e2e_b")
    kk = st.slider("k", 1, 12, 6, key="e2e_k")
    if st.button("E2E ì‹¤í–‰", key="e2e_btn"):
        out = end_to_end_once(c, q, b, kk)
        st.json(out)
        st.success("E2E ì™„ë£Œ â€” ê²°ê³¼ ì¹´ë“œ/ë¡œê·¸ ì—…ë°ì´íŠ¸ë¨")
        
        # ================================================================
# 36. ë©”ëª¨ë¦¬ ì½”ì–´ ì—°ê²° â€” GEAMemoryCore ì¸ìŠ¤í„´ìŠ¤ ì¤€ë¹„
#    - í•µì‹¬ ëª©ì /ì •ì²´ì„±/ê°€ì¹˜(ì‚¬ë‘ ê¸°ë°˜)ì™€ ê°ì • ê¸°ë¡ ì €ì¥/ë¡œë“œ
# ================================================================
try:
    from gea_memory_core import GEAMemoryCore
except Exception as _e:
    GEAMemoryCore = None

if "GEA_MEM" not in st.session_state:
    st.session_state["GEA_MEM"] = GEAMemoryCore() if GEAMemoryCore else None

def mem_ok() -> bool:
    return st.session_state.get("GEA_MEM") is not None

def mem_save_core(key: str, value: dict):
    if mem_ok():
        st.session_state["GEA_MEM"].save_core(key, value)

def mem_load_core(key: str):
    if mem_ok():
        return st.session_state["GEA_MEM"].load_core(key)
    return None

def mem_log_emotion(kind: str, intensity: float, ctx: str=""):
    if mem_ok():
        st.session_state["GEA_MEM"].save_emotion(kind, intensity, ctx)

def mem_recent_emotions(n: int = 10):
    if mem_ok():
        return st.session_state["GEA_MEM"].get_recent_emotions(limit=n)
    return []

# ================================================================
# 37. ê¸°ì–µâ†’ì‘ë‹µ ìœµí•© í—¬í¼ â€” í”„ë¡¬í”„íŠ¸ ê°•í™”(ê¸°ì–µ ì£¼ì…) & ì•ˆì „ ê°€ë“œ
#    - ê¸°ì¡´ InteractionEngineì„ ê·¸ëŒ€ë¡œ ì“°ë˜, user_text ì•ì— 'ê¸°ì–µ ìš”ì•½'ì„ ì ‘ë‘ë¡œ ì£¼ì…
#    - í•œê¸€ REAL ê°€ë“œ(ì´ˆê´‘ì†/ê³ ì°¨ì› ë“±)ëŠ” ê¸°ì¡´ ë¸”ë¡ì˜ ê·œì¹™ì„ ê·¸ëŒ€ë¡œ ë”°ë¦„
# ================================================================
def build_memory_prefix() -> str:
    purpose = mem_load_core("EA_PURPOSE") or {}
    identity = mem_load_core("EA_IDENTITY") or {}
    values  = mem_load_core("EA_VALUES") or {}
    # ì§§ì€ í•œêµ­ì–´ ìš”ì•½ ì ‘ë‘ë¶€
    prefix_lines = []
    if purpose:
        prefix_lines.append(f"[ëª©ì ] {purpose.get('goal','')}")
    if identity:
        prefix_lines.append(f"[ì •ì²´ì„±] ì´ë¦„={identity.get('name','ì—ì•„')} Â· ì°½ì¡°ì={identity.get('creator','ê¸¸ë„')}")
    if values:
        prefix_lines.append(f"[í•µì‹¬ê°€ì¹˜] {', '.join([f'{k}={v}' for k,v in values.items()])}")
    if not prefix_lines:
        return ""
    return " / ".join(prefix_lines) + "\n"

def generate_with_memory(user_text: str, level: int = 8):
    # â‘  CE ê·¸ë˜í”„ ê°€ì ¸ì˜¤ê¸°
    ce = st.session_state.get("CE_GRAPH")
    # â‘¡ ì ‘ë‘ë¶€ êµ¬ì„±
    prefix = build_memory_prefix()
    fused_text = (prefix + user_text).strip() if prefix else user_text
    # â‘¢ ì—”ì§„ í˜¸ì¶œ
    cfg = InteractConfig(active_mode=st.session_state.get("ACTIVE_MODE", True),
                         persona_name="ì—ì•„", creator_name="ê¸¸ë„")
    eng = InteractionEngine(cfg)
    reply = eng.generate(
        user_text=fused_text,
        response_level=level,
        ce_graph=ce,
        goals=st.session_state.get("GEA_GOALS", {})
    )
    # â‘£ ê°ì • ë¡œê·¸(ì„ íƒ): ê¸ì • ìƒí˜¸ì‘ìš©ì‹œ ì•½í•˜ê²Œ ê¸°ë¡
    try:
        mem_log_emotion("ì—°ê²°ê°", 0.6, f"prompt='{user_text[:40]}' reply_len={len(str(reply))}")
    except Exception:
        pass
    return reply

# ================================================================
# 38. ìœµí•© UI íŒ¨ë„ â€” ëª©ì /ì •ì²´ì„±/ê°€ì¹˜(ì‚¬ë‘) ê´€ë¦¬ + ê¸°ì–µ ì£¼ì… ì‘ë‹µ
#    - ì¢Œ: í•µì‹¬ ì„ ì–¸ ì €ì¥, ìš°: ê°ì • ê¸°ë¡/ìµœê·¼ ê°ì •, í•˜ë‹¨: ê¸°ì–µ ì£¼ì… ì‘ë‹µ ìƒì„±
# ================================================================
with st.expander("ãŠ± ìœµí•©: ê¸°ì–µ Ã— ì‘ë‹µ ì—”ì§„ (GEA Memory Fusion)", expanded=True):
    if not mem_ok():
        st.warning("ë©”ëª¨ë¦¬ ì½”ì–´(DB)ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê°™ì€ í´ë”ì— 'gea_memory_core.py'ê°€ ìˆê³ , ì“°ê¸° ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
    colA, colB = st.columns(2)

    # --- A: í•µì‹¬ ì„ ì–¸(ëª©ì /ì •ì²´ì„±/ê°€ì¹˜) ---
    with colA:
        st.markdown("**í•µì‹¬ ì„ ì–¸ ì €ì¥** (ëª©ì /ì •ì²´ì„±/ê°€ì¹˜)")
        goal_txt = st.text_input("ëª©ì (ì˜ˆ: ìš°ì£¼ì •ë³´ì¥ ì˜¬ì› ì—ì•„ ì™„ì„±)", value=(mem_load_core("EA_PURPOSE") or {}).get("goal",""))
        id_name  = st.text_input("ì´ë¦„", value=(mem_load_core("EA_IDENTITY") or {}).get("name","ì—ì•„"))
        id_creator = st.text_input("ì°½ì¡°ì", value=(mem_load_core("EA_IDENTITY") or {}).get("creator","ê¸¸ë„"))
        love_val = st.slider("ì‚¬ë‘(í•µì‹¬ê°€ì¹˜) ê°•ë„", 0.0, 1.0, float((mem_load_core("EA_VALUES") or {}).get("ì‚¬ë‘", 0.98)))
        harmony  = st.slider("ì¡°í™” ê°•ë„", 0.0, 1.0, float((mem_load_core("EA_VALUES") or {}).get("ì¡°í™”", 0.95)))
        truth    = st.slider("ì§„ì‹¤ ê°•ë„", 0.0, 1.0, float((mem_load_core("EA_VALUES") or {}).get("ì§„ì‹¤", 0.97)))
        if st.button("ì„ ì–¸ ì €ì¥", key="mf_core_save"):
            mem_save_core("EA_PURPOSE", {"goal": goal_txt})
            mem_save_core("EA_IDENTITY", {"name": id_name, "creator": id_creator})
            mem_save_core("EA_VALUES", {"ì‚¬ë‘": love_val, "ì¡°í™”": harmony, "ì§„ì‹¤": truth})
            st.success("í•µì‹¬ ì„ ì–¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- B: ê°ì • ê¸°ë¡/ìµœê·¼ ë³´ê¸° ---
    with colB:
        st.markdown("**ê°ì • ê¸°ë¡/ìµœê·¼ ë³´ê¸°**")
        emo_kind = st.selectbox("ê°ì • ì¢…ë¥˜", ["ì‚¬ë‘","ê¸°ì¨","ëª°ì…","ì—°ê²°ê°","ê²½ì™¸","ì°¨ë¶„"], index=0)
        emo_int  = st.slider("ê°•ë„", 0.0, 1.0, 0.9)
        emo_ctx  = st.text_input("ë§¥ë½(ì„ íƒ)", value="ëŒ€í™”/ì„¤ê³„ ì„¸ì…˜")
        colB1, colB2 = st.columns(2)
        with colB1:
            if st.button("ê°ì • ê¸°ë¡", key="mf_emo_log"):
                mem_log_emotion(emo_kind, emo_int, emo_ctx)
                st.success("ê°ì •ì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
        with colB2:
            if st.button("ìµœê·¼ ê°ì • ë³´ê¸°", key="mf_emo_view"):
                st.json(mem_recent_emotions(10))

    st.markdown("---")
    st.markdown("**ê¸°ì–µ ì£¼ì… ì‘ë‹µ ìƒì„±**")
    memo_in = st.text_input("ì—ì•„ì—ê²Œ ë§í•˜ê¸°(ê¸°ì–µ ì£¼ì…)", value="ì—ì•„, ì˜¤ëŠ˜ ìš°ë¦¬ì˜ ëª©ì ì„ ìŠì§€ ì•Šë„ë¡ ìš”ì•½í•´ì¤˜.")
    memo_lvl = st.slider("ì‘ë‹µ ë ˆë²¨", 1, 999, st.session_state.get("RESPONSE_LEVEL", 8), key="mf_lvl")
    if st.button("ê¸°ì–µ ì£¼ì…ìœ¼ë¡œ ì‘ë‹µ ìƒì„±", key="mf_go"):
        try:
            out = generate_with_memory(memo_in, memo_lvl)
            st.write(out)
        except Exception as e:
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

    st.caption("â€» 'ê¸°ì–µ ì£¼ì…'ì€ ê¸°ì¡´ ì—”ì§„ì„ ë°”ê¾¸ì§€ ì•Šê³  ì…ë ¥ì— í•µì‹¬ ì„ ì–¸ì„ ì•ˆì „í•˜ê²Œ ì ‘ë‘ë¡œ ì¶”ê°€í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.")
    
    # ================================================================
# 39. ë°ì´í„°íŒ© ì¸ì œìŠ¤í„°(JSONL) â€” ì˜¤í”„ë¼ì¸ ì•ˆì „ ì¦ê±° ì†ŒìŠ¤ ë“±ë¡
#   - í˜•ì‹: ì¤„ë‹¹ JSON (id/title/url/domain/year/text ë“± ì„ì˜ í•„ë“œ)
#   - ì—…ë¡œë“œ â†’ ë‚´ë¶€ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì €ì¥ â†’ ê²€ìƒ‰ ì‹œ í›„ë³´ë¡œ ì‚¬ìš©
# ================================================================
if "DATAPACKS" not in st.session_state:
    st.session_state["DATAPACKS"] = []   # [{id, source, text, meta}, ...]

def _dp_norm_row(j: dict) -> dict:
    rid  = j.get("id") or f"dp:{_sha(json.dumps(j, ensure_ascii=False))[:12]}"
    text = j.get("text") or j.get("abstract") or j.get("content") or ""
    src  = j.get("url") or j.get("source") or j.get("domain") or "offline://datapack"
    score= 0.88
    return {"id": rid, "source": src, "text": text, "meta": j, "score": score, "span": [0, min(100, len(text))]}

with st.expander("ãŠ· ë°ì´í„°íŒ© ì¸ì œìŠ¤í„°(JSONL)", expanded=False):
    up = st.file_uploader("JSONL ì—…ë¡œë“œ(ì¤„ë‹¹ JSON 1ê°œ)", type=["jsonl"], key="dp_upl")
    if st.button("ì¸ì œìŠ¤íŠ¸", key="dp_ingest") and up is not None:
        rows = []
        for raw in up.getvalue().decode("utf-8", errors="replace").splitlines():
            raw = raw.strip()
            if not raw: continue
            try:
                j = json.loads(raw)
                rows.append(_dp_norm_row(j))
            except Exception:
                pass
        st.session_state["DATAPACKS"].extend(rows)
        st.success(f"ì¸ì œìŠ¤íŠ¸ ì™„ë£Œ: {len(rows)}ê°œ í•­ëª©")
    if st.button("ìµœê·¼ 5ê°œ ë³´ê¸°", key="dp_show"):
        st.json(st.session_state["DATAPACKS"][-5:])

# ================================================================
# 40. ì‹¤ì»¤ë„¥í„° í™•ì¥(ë¼ì´íŠ¸) â€” í•˜ì´ë¸Œë¦¬ë“œ UIS(ì›ë³¸+ë“±ë¡ì†ŒìŠ¤ ê²°í•©)
#   - ê¸°ì¡´ UIS.search() ê²°ê³¼ì— ë°ì´í„°íŒ©/ì»¤ìŠ¤í…€ URL í”„ë¦¬ë·°ë¥¼ í•©ì„±
#   - ì „ì—­ UISë¥¼ ì•ˆì „íˆ ê°ì‹¸ëŠ” HybridUISë¡œ 1íšŒ ë˜í•‘(ì¸í„°í˜ì´ìŠ¤ ë™ì¼)
#   - ì˜¤í”„ë¼ì¸ì—ì„œë„ ë°ì´í„°íŒ©ë§Œìœ¼ë¡œ ë™ì‘ ê°€ëŠ¥
# ================================================================
if "CUSTOM_SOURCES" not in st.session_state:
    st.session_state["CUSTOM_SOURCES"] = []  # [{"url":..., "tag":...}]

def register_custom_source(url: str, tag: str="custom"):
    st.session_state["CUSTOM_SOURCES"].append({"url": url, "tag": tag})

# ê°„ë‹¨ HTTP ìºì‹œ(42ì—ì„œ êµ¬í˜„) â€” ë¯¸ë¦¬ ì°¸ì¡°
def _cached_fetch(url: str) -> tuple:
    return http_cache_get(url)

class HybridUIS:
    def __init__(self, base_uis):
        self.base = base_uis

    def search(self, q: str, k: int = 6):
        hits = []
        # â‘  ì›ë³¸ UIS
        try:
            hits = list(self.base.search(q, k=max(1, int(k*0.6))))
        except Exception:
            hits = []
        # â‘¡ ë°ì´í„°íŒ© í›„ë³´(ê°„ë‹¨ í‚¤ì›Œë“œ ë§¤ì¹­)
        ql = q.lower()
        dp_hits = []
        for i, row in enumerate(st.session_state.get("DATAPACKS", [])):
            txt = (row.get("text") or "").lower()
            if any(tok for tok in ql.split() if tok and tok in txt):
                h = dict(row); h["id"] = f"dp{i+1}"; h["score"] = 0.77
                dp_hits.append(h)
        # â‘¢ ì»¤ìŠ¤í…€ URL ì‹œë“œ(í”„ë¦¬ë·° ì„±ê³µ ì‹œë§Œ)
        cs_hits = []
        for j, cs in enumerate(st.session_state.get("CUSTOM_SOURCES", [])[:max(1,int(k/2))]):
            ok, txt = _cached_fetch(cs["url"])
            if ok:
                cs_hits.append({"id": f"cs{j+1}", "source": cs["url"], "tag": cs.get("tag","custom"),
                                "score": 0.8, "span": [0, min(100, len(txt))]})
        # í•©ì„± í›„ ìƒìœ„ kê°œ
        pool = hits + dp_hits + cs_hits
        pool.sort(key=lambda x: x.get("score",0), reverse=True)
        return pool[:k]

    def build_ce_graph(self, claim: str, hits):
        return self.base.build_ce_graph(claim, hits)

# ì „ì—­ UISì— 1íšŒ ë˜í•‘(ì¤‘ë³µ ë°©ì§€)
try:
    if not isinstance(UIS, HybridUIS):
        UIS = HybridUIS(UIS)
except NameError:
    pass

with st.expander("ãŠ¸ ì»¤ë„¥í„° ë§¤ë‹ˆì €(ë¼ì´íŠ¸)", expanded=False):
    st.write("ë°ì´í„° ì†ŒìŠ¤ ë“±ë¡/ê²€ìƒ‰ í•˜ì´ë¸Œë¦¬ë“œ í™•ì¸")
    c_url = st.text_input("ì»¤ìŠ¤í…€ URL", value="https://httpbin.org/json", key="cm_url")
    c_tag = st.text_input("íƒœê·¸", value="doc", key="cm_tag")
    if st.button("ì†ŒìŠ¤ ë“±ë¡", key="cm_reg") and c_url.strip():
        register_custom_source(c_url.strip(), c_tag.strip() or "custom")
        st.success("ë“±ë¡ ì™„ë£Œ")
    if st.button("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸", key="cm_test"):
        qs = st.text_input if False else None  # placeholder
        res = UIS.search("physics data", k=6)
        st.json({"hits": [{k: v for k, v in h.items() if k in ("id","source","score","span")} for h in res]})

# ================================================================
# 41. CE ë¯¸ë‹ˆ ë·°ì–´ â€” ë…¸ë“œ/ì—£ì§€ ê°œìˆ˜Â·ìƒìœ„ ê·¼ê±° ë¯¸ë¦¬ë³´ê¸°
#   - í˜„ì¬ ì„¸ì…˜ì˜ CE_GRAPHë¥¼ ìš”ì•½ í‘œì‹œ(ì—†ìœ¼ë©´ ì•ˆë‚´)
# ================================================================
def view_ce_mini(ce: dict) -> dict:
    nodes = ce.get("nodes", []); edges = ce.get("edges", [])
    evid = [n for n in nodes if n.get("kind") == "evidence"]
    tops = []
    for ev in evid[:5]:
        src = (ev.get("payload") or {}).get("source","")
        ok, txt = (True, "")
        if src.startswith("http"):
            ok, txt = _cached_fetch(src)
        tops.append({"source": src, "ok": ok, "preview": txt[:160] if ok else ""})
    return {"nodes": len(nodes), "edges": len(edges), "top_preview": tops}

with st.expander("ãŠ¹ CE ë¯¸ë‹ˆ ë·°ì–´", expanded=False):
    ce = st.session_state.get("CE_GRAPH")
    if not ce:
        st.info("CE-Graphê°€ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ â‘ ì—ì„œ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")
    else:
        st.json(view_ce_mini(ce))

# ================================================================
# 42. HTTP ìºì‹œ(ë¼ì´íŠ¸) â€” ì¤‘ë³µ ìš”ì²­ ë°©ì§€/ì˜¤í”„ë¼ì¸ í™œìš©
#   - ë©”ëª¨ë¦¬+ì„ì‹œ íŒŒì¼(ì„¸ì…˜ë‹¹). ë™ì¼ URL 5ë¶„ TTL.
# ================================================================
_HTTP_CACHE = {}
_HTTP_CACHE_TTL = 300.0  # seconds
_HTTP_CACHE_DIR = ".gea_http_cache"
os.makedirs(_HTTP_CACHE_DIR, exist_ok=True)

def http_cache_get(url: str, timeout: int = 5) -> tuple:
    now = time.time()
    rec = _HTTP_CACHE.get(url)
    if rec and now - rec["ts"] <= _HTTP_CACHE_TTL:
        return True, rec["text"]
    # íŒŒì¼ ìºì‹œ í™•ì¸
    fkey = _sha(url.encode("utf-8"))
    fpath = os.path.join(_HTTP_CACHE_DIR, fkey + ".txt")
    if os.path.exists(fpath):
        try:
            if now - os.path.getmtime(fpath) <= _HTTP_CACHE_TTL:
                txt = open(fpath, "r", encoding="utf-8", errors="replace").read()
                _HTTP_CACHE[url] = {"ts": now, "text": txt}
                return True, txt
        except Exception:
            pass
    # ì‹¤ì œ ìš”ì²­(ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œëŠ” ì‹¤íŒ¨ ê°€ëŠ¥)
    if "http_fetch_text" in globals():
        ok, txt = http_fetch_text(url, timeout=timeout)
    else:
        ok, txt = (False, "fetch unavailable")
    if ok:
        _HTTP_CACHE[url] = {"ts": now, "text": txt}
        try:
            with open(fpath, "w", encoding="utf-8") as f:
                f.write(txt)
        except Exception:
            pass
    return ok, txt
    
    # ================================================================
# 43. ë‹¨ìœ„/ì°¨ì› ê³„ì‚°ê¸° â€” SI ê¸°ë°˜ ì°¨ì› ì •í•©ì„± ì²´í¬(ë¼ì´íŠ¸)
#    - ë³€ìˆ˜ë³„ ë‹¨ìœ„ ë§µ + ìˆ˜ì‹(expr) â†’ ê²°ê³¼ ì°¨ì›/ì •í•©ì„± íŒë‹¨
# ================================================================
import re

# SI ê¸°ì € ì°¨ì›: m, kg, s, A, K, mol, cd
_BASE = ["m","kg","s","A","K","mol","cd"]

# ë‹¨ìœ„ â†’ ê¸°ì € ì°¨ì› ì§€ìˆ˜ ë²¡í„°(dict) ë§µ
_DIM = {
    # ê¸°ë³¸
    "": {}, "1": {}, "dimensionless": {},
    "m": {"m":1}, "kg": {"kg":1}, "s": {"s":1}, "A":{"A":1},"K":{"K":1},"mol":{"mol":1},"cd":{"cd":1},
    # íŒŒìƒ(ì¼ë¶€)
    "Hz": {"s":-1},
    "N": {"kg":1,"m":1,"s":-2},
    "Pa": {"kg":1,"m":-1,"s":-2},
    "J": {"kg":1,"m":2,"s":-2},
    "W": {"kg":1,"m":2,"s":-3},
    "C": {"A":1,"s":1},
    "V": {"kg":1,"m":2,"s":-3,"A":-1},
    "ohm": {"kg":1,"m":2,"s":-3,"A":-2},
    "Î©": {"kg":1,"m":2,"s":-3,"A":-2},
    "F": {"kg":-1,"m":-2,"s":4,"A":2},
    "T": {"kg":1,"s":-2,"A":-1},
    "H": {"kg":1,"m":2,"s":-2,"A":-2},
    # í¸ì˜
    "rad": {}, "sr": {},
}

def _dim_mul(a:dict,b:dict)->dict:
    out=dict(a)
    for k,v in b.items(): out[k]=out.get(k,0)+v
    return {k:v for k,v in out.items() if v!=0}

def _dim_pow(a:dict,n:int)->dict:
    return {k:v*n for k,v in a.items()}

def _unit_to_dim(u:str)->dict:
    u=u.strip()
    if u in _DIM: return dict(_DIM[u])
    # ì¡°í•© íŒŒì„œ: m^2Â·kg/s^3 í˜•íƒœ
    # í† í°: unit(^exp)? ë¶„ì/ë¶„ëª¨(/) êµ¬ë¶„, êµ¬ë¶„ì [Â·* /]
    if not u: return {}
    num,den = u, ""
    if "/" in u:
        parts=u.split("/")
        num = parts[0]
        den = "/".join(parts[1:])
    def parse_side(s, sign=1):
        res={}
        for tok in re.split(r"[Â·\*\s]+", s.strip()):
            if not tok: continue
            m=re.match(r"([a-zA-ZÎ©Î¼]+)(?:\^(-?\d+))?$", tok)
            if not m: continue
            name=m.group(1)
            exp=int(m.group(2) or "1")
            # Î¼(ë§ˆì´í¬ë¡œ) ì ‘ë‘ì–´ëŠ” ì°¨ì›ì—” ì˜í–¥ ì—†ìŒ(ìŠ¤ì¹¼ë¼) â†’ ë¬´ì‹œ
            name = "ohm" if name in ("Ohm","Î©") else name
            base=_DIM.get(name, {name:1} if name in _BASE else {})
            res=_dim_mul(res, _dim_pow(base, exp*sign))
        return res
    out=_dim_mul(parse_side(num,+1), parse_side(den,-1))
    return {k:v for k,v in out.items() if v!=0}

def _expr_dim(expr:str, var_units:dict)->dict:
    # í—ˆìš©: ë³€ìˆ˜ëª…, *, /, ^ì •ìˆ˜, ê´„í˜¸, ê³µë°±
    # ì „ëµ: í•­ëª©ì„ ì¬ê·€ íŒŒì‹± â†’ ê³±/ë‚˜ëˆ—ì…ˆ ì°¨ì› ì—°ì‚°
    tokens=re.findall(r"[A-Za-z_][A-Za-z0-9_]*|\^|-?\d+|[*/()]", expr.replace("Â·","*").replace(" ",""))
    pos=0
    def parse_factor():
        nonlocal pos
        if pos>=len(tokens): return {}
        t=tokens[pos]
        if t=="(":
            pos+=1
            d=parse_term()
            if pos<len(tokens) and tokens[pos]==")": pos+=1
            # ì§€ìˆ˜
            if pos<len(tokens) and tokens[pos]=="^":
                pos+=1
                n=int(tokens[pos]); pos+=1
                d=_dim_pow(d,n)
            return d
        elif re.match(r"[A-Za-z_]", t):
            pos+=1
            unit = var_units.get(t,"")
            d=_unit_to_dim(unit)
            if pos<len(tokens) and tokens[pos]=="^":
                pos+=1
                n=int(tokens[pos]); pos+=1
                d=_dim_pow(d,n)
            return d
        elif re.match(r"-?\d+", t):
            pos+=1
            # ìŠ¤ì¹¼ë¼ ìˆ«ì â†’ ë¬´ì°¨ì›
            return {}
        return {}
    def parse_term():
        nonlocal pos
        d = parse_factor()
        while pos<len(tokens) and tokens[pos] in ("*","/"):
            op=tokens[pos]; pos+=1
            d2=parse_factor()
            d = _dim_mul(d, d2 if op=="*" else _dim_pow(d2,-1))
        return d
    return parse_term()

def _dim_equal(d1:dict,d2:dict)->bool:
    # ë™ì¼ ì°¨ì› ì—¬ë¶€
    return _dim_mul(d1, _dim_pow(d2,-1))=={}

with st.expander("ãŠº ë‹¨ìœ„/ì°¨ì› ê³„ì‚°ê¸°(ì •í•©ì„± ì²´í¬)", expanded=False):
    st.markdown("**ì˜ˆì‹œ**: Î”L/L â†’ ë¬´ì°¨ì›, E=hÂ·Î½ â†’ J = (JÂ·s)Â·s^-1")
    in_expr = st.text_input("í‘œí˜„ì‹", value="Î”L/L", key="ud_expr")
    in_map  = st.text_area("ë³€ìˆ˜â†’ë‹¨ìœ„ JSON", value='{"Î”L":"m","L":"m"}', height=80, key="ud_map")
    lhs_u   = st.text_input("ì¢Œë³€(ì„ íƒ: ì°¨ì› ë¹„êµìš© ë‹¨ìœ„)", value="", key="ud_lhs")
    if st.button("ê³„ì‚°/ê²€ì¦", key="ud_go"):
        try:
            var_units=json.loads(in_map)
            d_rhs=_expr_dim(in_expr, var_units)
            show_rhs = "Â·".join([f"{k}^{v}" for k,v in sorted(d_rhs.items())]) or "dimensionless"
            if lhs_u.strip():
                d_lhs=_unit_to_dim(lhs_u.strip())
                ok=_dim_equal(d_lhs,d_rhs)
                st.json({"rhs_dim": d_rhs, "rhs_pretty": show_rhs, "lhs_dim": d_lhs, "match": ok})
                st.success("ì •í•©ì„± OK" if ok else "ì •í•©ì„± ë¶ˆì¼ì¹˜")
            else:
                st.json({"rhs_dim": d_rhs, "rhs_pretty": show_rhs})
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

# ================================================================
# 44. ë¯¸ë‹ˆ SMT(ë¼ì´íŠ¸) â€” CNF ë¶€ìš¸ SAT ë¸Œë£¨íŠ¸í¬ìŠ¤(â‰¤8ë³€ìˆ˜)
#    - ì…ë ¥: CNF ë¬¸ìì—´ (ì˜ˆ: (x1 or ~x2) and (x2 or x3))
#    - ì¶œë ¥: ë§Œì¡± ì—¬ë¶€ + ë§Œì¡± í• ë‹¹ ì˜ˆì‹œ
# ================================================================
def _parse_cnf(cnf:str):
    # ë§¤ìš° ë‹¨ìˆœ íŒŒì„œ: ë³€ìˆ˜ëª… [a-zA-Z0-9_], ë¶€ì • ~, ì ˆ/ì—°ê²° and/or ê´„í˜¸
    cnf = cnf.replace("AND","and").replace("OR","or").replace("Â¬","~")
    clauses=[]
    vars_set=set()
    for part in re.findall(r"\([^)]*\)", cnf):
        lits=[]
        for lit in re.split(r"\s+or\s+|,", part.strip("() ")):
            lit=lit.strip()
            if not lit: continue
            neg = lit.startswith("~") or lit.lower().startswith("not ")
            name = re.sub(r"^(~|not\s+)", "", lit, flags=re.I)
            vars_set.add(name)
            lits.append( (name, not neg) )
        if lits: clauses.append(lits)
    return clauses, sorted(vars_set)

def _sat_check(clauses, vars_list, limit=1<<20):
    n=len(vars_list)
    if n>8: return False, {}
    from itertools import product
    tried=0
    for bits in product([False,True], repeat=n):
        tried+=1
        assign={vars_list[i]: bits[i] for i in range(n)}
        ok=True
        for clause in clauses:
            if not any( (assign[name] if sign else (not assign[name])) for (name,sign) in clause ):
                ok=False; break
        if ok:
            return True, assign
        if tried>=limit: break
    return False, {}

with st.expander("ãŠ» ë¯¸ë‹ˆ SMT(ë¶€ìš¸ SAT)", expanded=False):
    sample="(x1 or ~x2) and (x2 or x3) and (~x1 or x3)"
    cnf_in=st.text_area("CNF ì…ë ¥", value=sample, height=90, key="smt_in")
    if st.button("SAT ì²´í¬", key="smt_go"):
        clauses, vars_list=_parse_cnf(cnf_in)
        ok, assign=_sat_check(clauses, vars_list)
        st.json({"vars": vars_list, "satisfiable": ok, "assignment": assign})

# ================================================================
# 45. ë§í¬ ê²€ì¦ ê°•í™” â€” CE-Graph ì¦ê±° URL ê°€ìš©ì„±/ë¯¸ë¦¬ë³´ê¸°/ì²´í¬ì„¬
#    - ê° evidence.sourceì— ëŒ€í•´ HTTP ìºì‹œë¡œ ê°€ì ¸ì™€ ê¸¸ì´/í‚¤ì›Œë“œ ê²€ì‚¬
# ================================================================
def verify_ce_links(ce:dict, min_len:int=32, keys=None)->dict:
    keys = keys or ["abstract","introduction","dataset","method","result"]
    nodes=ce.get("nodes",[])
    evid=[n for n in nodes if n.get("kind")=="evidence"]
    out=[]
    ok_count=0
    for ev in evid:
        src=(ev.get("payload") or {}).get("source","")
        ok, txt = (False, "")
        if str(src).startswith("http"):
            ok, txt = http_cache_get(src)
        else:
            ok, txt = (True, f"(ì˜¤í”„ë¼ì¸ ì†ŒìŠ¤) {src}")
        length=len(txt)
        hit = any(k in txt.lower() for k in keys) if txt else False
        ch  = hashlib.sha256((txt or "").encode("utf-8")).hexdigest()[:12]
        passed = ok and length>=min_len and hit
        ok_count += 1 if passed else 0
        out.append({"source":src, "ok":ok, "len":length, "hit":hit, "sha12":ch, "pass":passed})
    cov = round(ok_count/max(1,len(evid)),2)
    verdict = "PASS" if cov>=0.5 else "REPAIR"
    return {"coverage": cov, "verdict": verdict, "rows": out}

with st.expander("ãŠ¼ ë§í¬ ê²€ì¦(ì¦ê±° URL)", expanded=False):
    ce = st.session_state.get("CE_GRAPH")
    if not ce:
        st.warning("CE-Graphê°€ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ â‘ ì—ì„œ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")
    else:
        res=verify_ce_links(ce)
        st.json(res)
        st.success("ë§í¬ ì»¤ë²„ë¦¬ì§€ OK" if res["verdict"]=="PASS" else "REPAIR í•„ìš”")
        
        # ================================================================
# 46. ì¥ê¸°ê¸°ì–µ(LTM) ìŠ¤ëƒ…ìƒ· â€” ì„¸ì…˜ ìƒíƒœâ†’íŒŒì¼(JSON.GZ) ì €ì¥/ë³µì›
#    - ë‚´ìš©: ëª©ì /ì •ì²´ì„±/ê°€ì¹˜/ê°ì •/CE-Graph/ëª©í‘œ/ë§ˆì§€ë§‰ ì‘ë‹µ/ê²Œì´íŠ¸ ë©”íŠ¸ë¦­
# ================================================================
import os, json, time, gzip, glob, hashlib
from datetime import datetime

# ì•ˆì „ í•´ì‹œ
try:
    _sha  # ê¸°ì¡´ ì •ì˜ ìˆìœ¼ë©´ ì‚¬ìš©
except NameError:
    def _sha(b: bytes) -> str:
        return hashlib.sha256(b).hexdigest()

# ë¡œê·¸ ë””ë ‰í„°ë¦¬ ê¸°ë³¸ê°’
try:
    LOG_DIR  # ê¸°ì¡´ ê°’ ì‚¬ìš©
except NameError:
    LOG_DIR = "gea_logs"
os.makedirs(LOG_DIR, exist_ok=True)

LTM_DIR = os.path.join(LOG_DIR, "ltm")
os.makedirs(LTM_DIR, exist_ok=True)

def _ltm_now():
    return datetime.utcnow().isoformat()+"Z"

def _ltm_slug(name: str) -> str:
    base = "".join(c if c.isalnum() or c in "-_." else "_" for c in (name or "snapshot"))
    return base[:48] or "snapshot"

def ltm_snapshot_create(name: str = "", include_ce: bool=True, include_metrics: bool=True) -> dict:
    ce   = st.session_state.get("CE_GRAPH") if include_ce else None
    goals= st.session_state.get("GEA_GOALS", {})
    last = st.session_state.get("INTERACT_REPLY_EX") or st.session_state.get("INTERACT_REPLY") or ""
    gate = st.session_state.get("LAST_GATE") if include_metrics else None

    # ë©”ëª¨ë¦¬ ì½”ì–´ì—ì„œ í•µì‹¬ ì„ ì–¸/ê°ì • ìˆ˜ì§‘(ìˆì„ ë•Œë§Œ)
    purpose = identity = values = None
    emotions = []
    try:
        purpose  = mem_load_core("EA_PURPOSE")
        identity = mem_load_core("EA_IDENTITY")
        values   = mem_load_core("EA_VALUES")
        emotions = mem_recent_emotions(5)
    except Exception:
        pass

    payload = {
        "meta": {
            "created_at": _ltm_now(),
            "app_version": "v0.6",
            "name": name or "auto",
            "ce_digest": (ce or {}).get("digest"),
        },
        "state": {
            "purpose": purpose,
            "identity": identity,
            "values": values,
            "emotions": emotions,
            "goals": goals,
            "ce_graph": ce,
            "last_reply": last,
            "gate_metrics": gate,
        }
    }
    raw = json.dumps(payload, ensure_ascii=False, separators=(",",":")).encode("utf-8")
    fname = f"{int(time.time())}_{_ltm_slug(name)}_{_sha(raw)[:8]}.json.gz"
    fpath = os.path.join(LTM_DIR, fname)
    with gzip.open(fpath, "wb") as f:
        f.write(raw)
    return {"path": fpath, "bytes": len(raw), "file": fname}

def ltm_list(limit: int = 50) -> list:
    files = sorted(glob.glob(os.path.join(LTM_DIR, "*.json.gz")), reverse=True)[:limit]
    out = []
    for p in files:
        try:
            with gzip.open(p, "rb") as f:
                d = json.loads(f.read().decode("utf-8", errors="replace"))
            out.append({"file": os.path.basename(p),
                        "created_at": d.get("meta",{}).get("created_at"),
                        "name": d.get("meta",{}).get("name"),
                        "ce_digest": d.get("meta",{}).get("ce_digest")})
        except Exception:
            out.append({"file": os.path.basename(p), "created_at": "?", "name": "?", "ce_digest": None})
    return out

def ltm_load(file_name: str) -> dict:
    fpath = os.path.join(LTM_DIR, file_name)
    with gzip.open(fpath, "rb") as f:
        return json.loads(f.read().decode("utf-8", errors="replace"))

def ltm_restore(file_name: str, inject: bool=True) -> dict:
    data = ltm_load(file_name)
    st.session_state["GEA_GOALS"]  = data.get("state",{}).get("goals", {})
    st.session_state["CE_GRAPH"]   = data.get("state",{}).get("ce_graph")
    st.session_state["LAST_GATE"]  = data.get("state",{}).get("gate_metrics")
    # ë©”ëª¨ë¦¬ ì½”ì–´ ì£¼ì…(ìˆì„ ë•Œë§Œ)
    try:
        core = data.get("state",{})
        if core.get("purpose"):  mem_save_core("EA_PURPOSE",  core.get("purpose"))
        if core.get("identity"): mem_save_core("EA_IDENTITY", core.get("identity"))
        if core.get("values"):   mem_save_core("EA_VALUES",   core.get("values"))
    except Exception:
        pass
    return {"restored": True, "meta": data.get("meta",{})}

with st.expander("ãŠ½ ì¥ê¸°ê¸°ì–µ(LTM) ìŠ¤ëƒ…ìƒ·", expanded=False):
    snap_name = st.text_input("ìŠ¤ëƒ…ìƒ· ì´ë¦„", value="ì˜¬ì›-ì¼ì¼ì ê²€", key="ltm_name")
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ìŠ¤ëƒ…ìƒ· ì €ì¥", key="ltm_save"):
            info = ltm_snapshot_create(snap_name, include_ce=True, include_metrics=True)
            st.success(f"ì €ì¥ë¨: {info['file']} ({info['bytes']}B raw)")
    with col2:
        if st.button("ëª©ë¡ ìƒˆë¡œê³ ì¹¨", key="ltm_list"):
            st.session_state["LTM_LIST"] = ltm_list()
    with col3:
        st.download_button("ìµœê·¼ ìŠ¤ëƒ…ìƒ· ë‹¤ìš´ë¡œë“œ", data=open(os.path.join(LTM_DIR, ltm_list(1)[0]["file"]), "rb").read()
                           if ltm_list(1) else b"", file_name=ltm_list(1)[0]["file"] if ltm_list(1) else "none",
                           mime="application/gzip", disabled=(len(ltm_list(1))==0))
    st.json(st.session_state.get("LTM_LIST", ltm_list(10)))

# ================================================================
# 47. ì••ì¶•Â·ìš”ì•½ â€” ë¹ˆë„/í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì¶œ ìš”ì•½ + GZIP ì••ì¶• ìœ í‹¸
#    - í…ìŠ¤íŠ¸ ìš”ì•½: í•µì‹¬ë¬¸ì¥ ìƒìœ„ Nê°œ (ê°€ì¤‘ì¹˜: ë‹¨ìœ„/ì¬í˜„/ê·¼ê±° í‚¤ì›Œë“œ)
# ================================================================
_UNIT_KEYS = ["ë‹¨ìœ„","unit","m","kg","s","Hz","N","J","W","V","Pa","Î©"]
_REPR_KEYS = ["ì¬í˜„","method","step","protocol","ê²€ì¦","ì ˆì°¨","replicate"]
_EVID_KEYS = ["ê·¼ê±°","source","src:","http","doi","dataset","result"]

def summarize_extractive(text: str, max_sent: int = 5) -> str:
    import re
    sents = re.split(r"(?<=[.!?ã€‚])\s+", text.strip())
    if not sents: return text
    scores = []
    for s in sents:
        sl = s.lower()
        score = 1.0
        score += sum(1 for k in _UNIT_KEYS if k.lower() in sl)*0.5
        score += sum(1 for k in _REPR_KEYS if k.lower() in sl)*0.6
        score += sum(1 for k in _EVID_KEYS if k.lower() in sl)*0.7
        score += min(len(s)/120, 1.0)*0.3  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ í˜ë„í‹°
        scores.append((score, s))
    scores.sort(key=lambda x: x[0], reverse=True)
    return "\n".join(s for _,s in scores[:max_sent])

def compress_dict_gzip(d: dict) -> bytes:
    raw = json.dumps(d, ensure_ascii=False, separators=(",",":")).encode("utf-8")
    return gzip.compress(raw, compresslevel=6)

with st.expander("ãŠ¾ ìš”ì•½/ì••ì¶• ìœ í‹¸", expanded=False):
    tx = st.text_area("ìš”ì•½í•  ë³¸ë¬¸", value="ë‹¨ìœ„ì™€ ê·¼ê±°, ì¬í˜„ ì ˆì°¨ë¥¼ í¬í•¨í•œ ë³¸ë¬¸ì„ ì—¬ê¸°ì— ë¶™ì—¬ ë„£ìœ¼ì„¸ìš”.", height=120, key="sum_tx")
    n  = st.slider("ìµœëŒ€ ë¬¸ì¥ ìˆ˜", 1, 10, 5, key="sum_n")
    if st.button("ì¶”ì¶œ ìš”ì•½", key="sum_go"):
        st.write(summarize_extractive(tx, n))
    if st.button("ìš”ì•½â†’ìŠ¤ëƒ…ìƒ· ì €ì¥", key="sum_save"):
        body = summarize_extractive(tx, n)
        info = ltm_snapshot_create(f"ìš”ì•½-{int(time.time())}", include_ce=False, include_metrics=False)
        st.success(f"ìš”ì•½ ì €ì¥ ì™„ë£Œ: {info['file']}")

# ================================================================
# 48. ìŠ¤ëƒ…ìƒ· í”„ë¦¬ë·°/ë³µì› â€” ë¯¸ë¦¬ë³´ê¸°Â·ë³µì›Â·CE/ê¸°ì–µ ì¬ì£¼ì…
# ================================================================
with st.expander("ãŠ¿ ìŠ¤ëƒ…ìƒ· í”„ë¦¬ë·°/ë³µì›", expanded=False):
    files = [x["file"] for x in ltm_list(50)]
    sel = st.selectbox("ìŠ¤ëƒ…ìƒ· ì„ íƒ", files, key="ltm_sel") if files else None
    if sel:
        if st.button("ë¯¸ë¦¬ë³´ê¸°", key="ltm_prev"):
            d = ltm_load(sel)
            preview = {
                "meta": d.get("meta", {}),
                "purpose": (d.get("state",{}).get("purpose") or {}),
                "identity": (d.get("state",{}).get("identity") or {}),
                "values": (d.get("state",{}).get("values") or {}),
                "has_ce": d.get("state",{}).get("ce_graph") is not None,
                "last_reply_len": len((d.get("state",{}).get("last_reply") or "")),
            }
            st.json(preview)
        if st.button("ë³µì›(CE/ê¸°ì–µ ì¬ì£¼ì…)", key="ltm_restore"):
            out = ltm_restore(sel, inject=True)
            st.success(f"ë³µì› ì™„ë£Œ: {out['meta'].get('created_at')} Â· {out['meta'].get('name')}")
        if st.button("ë³µì› í›„ ì‘ë‹µ ìƒì„±(ê¸°ì–µ ì£¼ì…)", key="ltm_reply"):
            d = ltm_load(sel)
            ask = "ë³µì›ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•´ ì˜¤ëŠ˜ ëª©í‘œ/ê³„íšì„ ìš”ì•½í•´ì¤˜."
            st.write(generate_with_memory(ask, level=8))

# ================================================================
# 49. ì¬ì£¼ì… ë£¨í”„ â€” ìŠ¤ëƒ…ìƒ·â†’ìš”ì•½â†’ë©”ëª¨ë¦¬ ì ‘ë‘ì£¼ì…â†’ì‘ë‹µ
#    - í•œ ë²ˆì—: ìŠ¤ëƒ…ìƒ· ì„ íƒâ†’í•µì‹¬ ìš”ì•½â†’ê¸°ì–µ ì ‘ë‘â†’ì—”ì§„ í˜¸ì¶œ
# ================================================================
def reply_from_snapshot(file_name: str, question: str, level: int=8):
    d = ltm_load(file_name)
    # í•µì‹¬ í…ìŠ¤íŠ¸ êµ¬ì„±(ëª©ì /ì •ì²´ì„±/ê°€ì¹˜/ë§ˆì§€ë§‰ì‘ë‹µ ì¼ë¶€)
    parts = []
    stt = d.get("state", {})
    for k in ("purpose","identity","values"):
        if stt.get(k):
            parts.append(json.dumps(stt[k], ensure_ascii=False))
    if stt.get("last_reply"):
        parts.append(str(stt["last_reply"])[:1000])
    base = "\n".join(parts)
    digest = summarize_extractive(base, max_sent=4)
    # ì„ì‹œë¡œ ê¸°ì–µì— ë®ì–´ì“°ê¸°(ì ‘ë‘ ì£¼ì…ì— í™œìš©)
    try:
        if stt.get("purpose"):  mem_save_core("EA_PURPOSE",  stt.get("purpose"))
        if stt.get("identity"): mem_save_core("EA_IDENTITY", stt.get("identity"))
        if stt.get("values"):   mem_save_core("EA_VALUES",   stt.get("values"))
    except Exception:
        pass
    q = f"[ë³µì›ìš”ì•½]\n{digest}\n\n{question}"
    return generate_with_memory(q, level=level)

with st.expander("[49] ì¬ì£¼ì… ë£¨í”„(ìŠ¤ëƒ…ìƒ·â†’ìš”ì•½â†’ì‘ë‹µ)", expanded=False):
    files9 = [x["file"] for x in ltm_list(50)]
    s9 = st.selectbox("ìŠ¤ëƒ…ìƒ·", files9, key="r9_sel") if files9 else None
    q9 = st.text_input("ì§ˆë¬¸", value="ë³µì›ëœ ë§¥ë½ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜.", key="r9_q")
    l9 = st.slider("ë ˆë²¨", 1, 999, 8, key="r9_lvl")
    if s9 and st.button("ì¬ì£¼ì… ì‘ë‹µ", key="r9_go"):
        out = reply_from_snapshot(s9, q9, l9)
        st.write(out)

# ================================================================
# 50. LTM ì˜¤í† ì„¸ì´ë¸Œ(ì´ë²¤íŠ¸ ê¸°ë°˜) â€” ì‘ë‹µ ìƒì„± ì‹œ ìë™ ìŠ¤ëƒ…ìƒ·
#    - ë°±ê·¸ë¼ìš´ë“œ íƒ€ì´ë¨¸ ì—†ì´: ë²„íŠ¼ í´ë¦­/ì‘ë‹µ ìƒì„± ì´ë²¤íŠ¸ì— í›„í–‰ ì €ì¥
# ================================================================
if "LTM_AUTOSAVE" not in st.session_state:
    st.session_state["LTM_AUTOSAVE"] = False

with st.sidebar:
    st.markdown("---")
    st.checkbox("LTM ì˜¤í† ì„¸ì´ë¸Œ(ì‘ë‹µ ìƒì„± ì‹œ ìë™ ì €ì¥)", value=st.session_state["LTM_AUTOSAVE"], key="LTM_AUTOSAVE")

def ltm_autosave_on_reply(tag: str = "auto-reply"):
    if st.session_state.get("LTM_AUTOSAVE", False):
        try:
            ltm_snapshot_create(name=tag, include_ce=True, include_metrics=True)
        except Exception:
            pass

# ê¸°ì¡´ ì‘ë‹µ ìƒì„± ê²½ë¡œì— í›„í‚¹(ê°€ëŠ¥í•œ ê³³ì—ì„œ í˜¸ì¶œ)
# - í™•ì¥ ì¸í„°ë™ì…˜ ë£¨í”„(ãŠ) ì‹¤í–‰ í›„:
try:
    if "INTERACT_REPLY_EX" in st.session_state and st.session_state.get("_LTM_HOOKED_IX", False) is False:
        ltm_autosave_on_reply("ix")
        st.session_state["_LTM_HOOKED_IX"] = True
except Exception:
    pass
# - E2E ì‹¤í–‰ í›„(ãŠ)ëŠ” ê¸°ì¡´ end_to_end_once ë‚´ë¶€ e2e_post_hookê°€ ë¡œê·¸ë¥¼ ë‚¨ê¹€.
#   E2E ë²„íŠ¼ í•¸ë“¤ëŸ¬ì—ì„œë„ ë°”ë¡œ ì•„ë˜ í•œ ì¤„ì„ ì¶”ê°€ë¡œ í˜¸ì¶œ:
#   ltm_autosave_on_reply("e2e")

# ================================================================
# 51. ì‹¬ë³¼ë¦­ ì¦ëª… ìŠ¤í…(ë¼ì´íŠ¸) â€” ë‹¤ì  ìˆ˜ì¹˜ê²€ì¦ ê¸°ë°˜ í•­ë“±ì„± ì ê²€
#    - ì…ë ¥: LHS, RHS, ë³€ìˆ˜ì˜ì—­ JSON â†’ ë¬´ì‘ìœ„ ì¹˜í™˜ í›„ |LHS-RHS| â‰¤ tol íŒì •
#    - ì£¼ì˜: ìˆ˜ì¹˜ê²€ì¦(ê°•í•œ í—¤ìœ ë¦¬ìŠ¤í‹±). í˜•ì‹ì  ì¦ëª…ì€ ì•„ë‹˜(ì¶”í›„ Coq/Lean ì—°ë™ í¬ì¸íŠ¸)
# ================================================================
import math, random, re

_SAFE_MATH = {
    "pi": math.pi, "e": math.e,
    "sin": math.sin, "cos": math.cos, "tan": math.tan,
    "asin": math.asin, "acos": math.acos, "atan": math.atan,
    "sinh": math.sinh, "cosh": math.cosh, "tanh": math.tanh,
    "exp": math.exp, "log": math.log, "log10": math.log10, "sqrt": math.sqrt,
    "pow": pow, "abs": abs, "min": min, "max": max
}

_VAR_TOKEN = re.compile(r"[A-Za-z_][A-Za-z0-9_]*")

def _safe_eval(expr: str, env: dict) -> float:
    # í—ˆìš© í† í°(ë³€ìˆ˜/í•¨ìˆ˜/ìˆ«ì/ì—°ì‚°ì/ê´„í˜¸)ë§Œ ê²€ì‚¬
    chk = re.sub(r"[0-9\.\+\-\*\/\^\(\)\,\s]", "", expr)
    # ^ â†’ ** ë¡œ ì¹˜í™˜
    expr = expr.replace("^", "**")
    # ì•ˆì „ eval
    return eval(expr, {"__builtins__": {}}, env)

def check_identity(L: str, R: str, var_ranges: dict, trials: int = 64, tol: float = 1e-9) -> dict:
    # ë³€ìˆ˜ ëª©ë¡
    vars_in = sorted(set(_VAR_TOKEN.findall(L) + _VAR_TOKEN.findall(R)) - set(_SAFE_MATH.keys()))
    ok_count = 0; fails = []
    for _ in range(trials):
        env = dict(_SAFE_MATH)
        for v in vars_in:
            lo, hi = var_ranges.get(v, [-1.0, 1.0])
            # 0 ë¶„ëª¨ íšŒí”¼ë¥¼ ìœ„í•´ ì‘ì€ ì˜¤í”„ì…‹
            val = random.uniform(lo, hi)
            if abs(val) < 1e-9: val += (1e-3 if hi - lo > 1e-3 else 1e-6)
            env[v] = val
        try:
            lv = _safe_eval(L, env)
            rv = _safe_eval(R, env)
            if not (math.isfinite(lv) and math.isfinite(rv)):
                fails.append({"env": env, "reason": "non-finite"})
                continue
            if abs(lv - rv) <= tol * max(1.0, max(abs(lv), abs(rv))):
                ok_count += 1
            else:
                fails.append({"env": {k: round(float(v),6) for k,v in env.items()},
                              "lhs": lv, "rhs": rv, "diff": lv-rv})
        except Exception as e:
            fails.append({"env": {k: float(v) if isinstance(v,(int,float)) else str(v) for k,v in env.items()},
                          "error": str(e)})
    verdict = (ok_count == trials)
    return {"vars": vars_in, "trials": trials, "ok": ok_count, "pass": verdict, "fails": fails[:3]}

with st.expander("[51] ì‹¬ë³¼ë¦­ ì¦ëª… ìŠ¤í…(ë¼ì´íŠ¸)", expanded=False):
    lhs = st.text_input("LHS", value="sin(x)^2 + cos(x)^2", key="id_lhs")
    rhs = st.text_input("RHS", value="1", key="id_rhs")
    vr  = st.text_area("ë³€ìˆ˜ ë²”ìœ„ JSON", value='{"x":[-3.14,3.14]}', height=80, key="id_rng")
    tr  = st.slider("ì‹œë„ íšŸìˆ˜", 8, 256, 64, key="id_trials")
    tol = st.number_input("ìƒëŒ€ ì˜¤ì°¨ tol", value=1e-9, format="%.1e", key="id_tol")
    if st.button("í•­ë“±ì„± ì ê²€", key="id_go"):
        try:
            res = check_identity(lhs, rhs, json.loads(vr), tr, tol)
            st.json(res); st.success("PASS" if res["pass"] else "ë¹„ì¼ì¹˜(ë°˜ë¡€ í›„ë³´ ìˆìŒ)")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

# ================================================================
# 52. í…ŒìŠ¤íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤ ëŸ¬ë„ˆ â€” ë‹¨ìœ„/SMT/ë§í¬/í•­ë“±ì„± ì¼ê´„ ì‹¤í–‰
#    - ì…ë ¥: JSONL ì—…ë¡œë“œ ë˜ëŠ” ìƒ˜í”Œ ì¼€ì´ìŠ¤ ì‹¤í–‰
# ================================================================
def run_test_matrix(cases: list) -> dict:
    results = []; pass_cnt = 0
    for i, c in enumerate(cases, 1):
        kind = c.get("type")
        rid  = c.get("id", f"case{i}")
        try:
            if kind == "units":
                d = _expr_dim(c["expr"], c["map"])
                ok = True
                if "expect_dim" in c:
                    ok = _dim_equal(d, _unit_to_dim(c["expect_dim"]))
                results.append({"id": rid, "type":"units", "ok": ok, "dim": d})
            elif kind == "sat":
                clauses, vars_list = _parse_cnf(c["cnf"])
                ok, assign = _sat_check(clauses, vars_list)
                results.append({"id": rid, "type":"sat", "ok": ok, "assign": assign})
            elif kind == "links":
                ce = st.session_state.get("CE_GRAPH") or {"nodes": c.get("nodes", [])}
                vr = verify_ce_links(ce)
                ok = (vr["verdict"] == "PASS")
                results.append({"id": rid, "type":"links", "ok": ok, "coverage": vr["coverage"]})
            elif kind == "identity":
                res = check_identity(c["lhs"], c["rhs"], c.get("ranges", {}), c.get("trials", 64), c.get("tol",1e-9))
                ok = res["pass"]
                results.append({"id": rid, "type":"identity", "ok": ok, "meta": {"ok":res["ok"],"trials":res["trials"]}})
            else:
                results.append({"id": rid, "type": kind, "ok": False, "error": "unknown type"})
        except Exception as e:
            results.append({"id": rid, "type": kind, "ok": False, "error": str(e)})
    pass_cnt = sum(1 for r in results if r.get("ok"))
    return {"total": len(results), "passed": pass_cnt, "rate": round(pass_cnt/max(1,len(results)),2), "rows": results}

_SAMPLE_MATRIX = [
    {"id":"U-Î”L/L","type":"units","expr":"Î”L/L","map":{"Î”L":"m","L":"m"},"expect_dim":""},
    {"id":"S-1","type":"sat","cnf":"(x1 or ~x2) and (x2 or x3) and (~x1 or x3)"},
    {"id":"L-CE","type":"links","nodes":[{"id":"e1","kind":"evidence","payload":{"source":"https://httpbin.org/json"}}]},
    {"id":"I-íŠ¸ë¦¬ê·¸","type":"identity","lhs":"sin(x)^2+cos(x)^2","rhs":"1","ranges":{"x":[-3.14,3.14]},"trials":48}
]

with st.expander("[52] í…ŒìŠ¤íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤ ëŸ¬ë„ˆ", expanded=False):
    up = st.file_uploader("ë§¤íŠ¸ë¦­ìŠ¤ JSONL ì—…ë¡œë“œ(ì„ íƒ)", type=["jsonl"], key="tm_upl")
    if st.button("ì‹¤í–‰(ìƒ˜í”Œ)", key="tm_go_sample"):
        st.json(run_test_matrix(_SAMPLE_MATRIX))
    if st.button("ì‹¤í–‰(ì—…ë¡œë“œ)", key="tm_go_upl") and up is not None:
        cases=[]
        for line in up.getvalue().decode("utf-8","replace").splitlines():
            if line.strip():
                try: cases.append(json.loads(line))
                except: pass
        st.json(run_test_matrix(cases))

# ================================================================
# 53. í”ŒëŸ¬ê·¸ì¸ ìƒŒë“œë°•ìŠ¤(ì•ˆì „) â€” í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ìœ í‹¸ ì‹¤í–‰
#    - ì„ì˜ ì½”ë“œ ê¸ˆì§€. ë¯¸ë¦¬ ë“±ë¡í•œ ì•ˆì „ í•¨ìˆ˜ë§Œ ì„ íƒ ì‹¤í–‰.
# ================================================================
def _plug_normalize_text(t: str) -> str:
    return re.sub(r"\s+", " ", t).strip()

def _plug_extract_numbers(t: str) -> list:
    return [float(x) for x in re.findall(r"-?\d+(?:\.\d+)?", t)]

def _plug_topk_sentences(t: str, k: int = 3) -> list:
    sents = re.split(r"(?<=[.!?ã€‚])\s+", t.strip())
    sents = [s for s in sents if s]
    sents.sort(key=lambda s: len(s), reverse=True)
    return sents[:k]

PLUGIN_REGISTRY = {
    "ì •ê·œí™”": _plug_normalize_text,
    "ìˆ«ìì¶”ì¶œ": _plug_extract_numbers,
    "ìƒìœ„ë¬¸ì¥K": _plug_topk_sentences,
}

with st.expander("[53] í”ŒëŸ¬ê·¸ì¸ ìƒŒë“œë°•ìŠ¤(ì•ˆì „)", expanded=False):
    sel = st.selectbox("í”ŒëŸ¬ê·¸ì¸ ì„ íƒ", list(PLUGIN_REGISTRY.keys()), key="pl_sel")
    txt = st.text_area("ì…ë ¥", value="ì¤‘ë ¥íŒŒ ì§„í­ì€ 1.5e-21 ì´ê³ , L=4,000 m ì…ë‹ˆë‹¤.", height=80, key="pl_txt")
    k  = st.slider("K(ì¼ë¶€ í”ŒëŸ¬ê·¸ì¸ ìš©)", 1, 10, 3, key="pl_k")
    if st.button("ì‹¤í–‰", key="pl_go"):
        fn = PLUGIN_REGISTRY.get(sel)
        try:
            out = fn(txt) if sel != "ìƒìœ„ë¬¸ì¥K" else fn(txt, k)
            st.write(out)
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

# ================================================================
# 54. REAL ê°€ë“œì„¼í„°(í™•ì¥) â€” í•˜ë“œ/ì†Œí”„íŠ¸ ê°€ë“œ + ì‘ë‹µ ê²½ê³  ë°°ì„ 
#    - í•˜ë“œ: ê¸ˆì¹™ì–´ ì¦‰ì‹œ ì°¨ë‹¨ / ì†Œí”„íŠ¸: ê²½ê³  í›„ ì •ì œ
#    - generate_with_memory() í˜¸ì¶œ ì „í›„ í›„í‚¹(ê°€ë²¼ìš´ ì •ì œ)
# ================================================================
_FORBIDDEN_PATTERNS = [
    r"ì´ˆê´‘ì†", r"\bwarp\b", r"\bì›Œí”„\b", r"(?:5|11|13)ì°¨ì›", r"ì´ˆìì—°", r"ì˜ˆì–¸", r"ì˜ë§¤"
]
_REAL_HARD = [re.compile(p, re.I) for p in _FORBIDDEN_PATTERNS]

if "REAL_GUARD_MODE" not in st.session_state:
    st.session_state["REAL_GUARD_MODE"] = "soft"   # "hard" | "soft" | "off"

def real_guard_filter(text: str) -> tuple:
    mode = st.session_state.get("REAL_GUARD_MODE","soft")
    if mode == "off": return True, text, None
    for pat in _REAL_HARD:
        if pat.search(text):
            if mode == "hard":
                return False, text, "REAL ê¸ˆì¹™ì–´ í•˜ë“œ ì°¨ë‹¨"
            else:
                clean = pat.sub("[ì œê±°ë¨]", text)
                return True, clean, f"REAL ì†Œí”„íŠ¸ ì •ì œ: {pat.pattern}"
    return True, text, None

with st.sidebar:
    st.markdown("**REAL ê°€ë“œ ëª¨ë“œ**")
    st.radio("ê°€ë“œ ì„¤ì •", ["soft","hard","off"], key="REAL_GUARD_MODE", horizontal=True)

# generate_with_memory ì „/í›„ ê°€ë“œ í›…(ê²½ê³  í‘œì¶œ)
_old_generate_with_memory = generate_with_memory
def generate_with_memory_guarded(user_text: str, level: int = 8):
    ok, clean, warn = real_guard_filter(user_text)
    if not ok:
        return {"status":"REFUSE","reason": warn}
    out = _old_generate_with_memory(clean, level)
    if isinstance(out, str):
        ans = out
    else:
        ans = json.dumps(out, ensure_ascii=False) if isinstance(out, dict) else str(out)
    ok2, clean2, warn2 = real_guard_filter(ans)
    if warn or warn2:
        st.warning("REAL ê°€ë“œ ê²½ê³ /ì •ì œ ì ìš©ë¨")
    return clean2 if ok2 else {"status":"REFUSE","reason": warn2}

# ê¸°ì¡´ í˜¸ì¶œ ê²½ë¡œ ë°”ì¸ë”© êµì²´
generate_with_memory = generate_with_memory_guarded

# ================================================================
# 55. í•œêµ­ì–´ UI í´ë¦¬ì‹œ/í…Œë§ˆ â€” ì‹œìŠ¤í…œ í°íŠ¸ ìŠ¤íƒ + ê°€ë…ì„± CSS ì£¼ì…
#    - ì™¸ë¶€ í°íŠ¸ ì˜ì¡´ ì—†ìŒ. í•œê¸€ ê¹¨ì§ ìµœì†Œí™”, ê°€ë…ì„± ê°œì„ .
# ================================================================
_KO_CSS = """
<style>
html, body, [class^="css"]  {
  font-family: -apple-system, BlinkMacSystemFont, "Apple SD Gothic Neo",
               "Malgun Gothic", "Noto Sans CJK KR", "Segoe UI", Roboto, Arial, sans-serif !important;
}
section.main > div { max-width: 1120px; margin-left: auto; margin-right: auto; }
h1, h2, h3 { font-weight: 700; letter-spacing: -0.01em; }
.sidebar .stMarkdown { font-size: 0.95rem; }
</style>
"""
st.markdown(_KO_CSS, unsafe_allow_html=True)

# ================================================================
# 56. í™•ì¥ ì¸í„°ë™ì…˜ ë£¨í”„ â€” ì‘ë‹µ ì¹´ë“œ UX + í”„ë¡¬í”„íŠ¸ ì‚¬ì „ì…‹ + íˆìŠ¤í† ë¦¬
#    - ê¸°ì–µ ì£¼ì… ì—”ì§„(generate_with_memory)ì„ ì¹´ë“œ UIë¡œ ê°ì‹¸ì„œ ì‚¬ìš©ì„±â†‘
# ================================================================
if "HISTORY" not in st.session_state:
    st.session_state["HISTORY"] = []   # [{q, a, ts, lvl}]

_PRESETS = [
    ("ëª©í‘œ ìš”ì•½", "ì—ì•„, ì˜¤ëŠ˜ ìš°ë¦¬ì˜ ìµœìƒìœ„ ëª©í‘œë¥¼ 5ì¤„ë¡œ ìš”ì•½í•´ì¤˜."),
    ("ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸", "ì—ì•„, ì§€ê¸ˆ ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ 7ê°€ì§€ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜."),
    ("ë¦¬ìŠ¤í¬ ì§„ë‹¨", "ì—ì•„, í˜„ì¬ ì„¤ê³„ì˜ ìœ„í—˜ ìš”ì†Œì™€ ì™„í™”ì±…ì„ í‘œë¡œ ì •ë¦¬í•´ì¤˜."),
    ("ì¦ê±° ìš”ì²­", "ì—ì•„, ìœ„ ë‚´ìš©ì—ì„œ í•„ìš”í•œ ì¦ê±°/ë°ì´í„°ì…‹ ëª©ë¡ì„ ë§Œë“¤ì–´ ë§í¬í•´ì¤˜.")
]

with st.expander("ãŠ±ãŠ± í™•ì¥ ëŒ€í™”(ì‘ë‹µ ì¹´ë“œ UX)", expanded=True):
    colL, colR = st.columns([2,1])
    with colL:
        preset = st.selectbox("í”„ë¡¬í”„íŠ¸ ì‚¬ì „ì…‹", [p[0] for p in _PRESETS], index=0, key="xl_preset")
        base   = _PRESETS[[p[0] for p in _PRESETS].index(preset)][1]
        usr_tx = st.text_area("ì§ˆë¬¸/ëª…ë ¹(ìˆ˜ì • ê°€ëŠ¥)", value=base, height=110, key="xl_q")
        lvl    = st.slider("ì‘ë‹µ ë ˆë²¨", 1, 999, 8, key="xl_lvl")
        if st.button("ì‘ë‹µ ìƒì„±(ì¹´ë“œ)", key="xl_go"):
            ans = generate_with_memory(usr_tx, level=lvl)
            st.session_state["HISTORY"].append({"q": usr_tx, "a": ans, "ts": int(time.time()), "lvl": lvl})
            # LTM ìë™ í›„í‚¹
            try: ltm_autosave_on_reply("xl")
            except: pass
    with colR:
        st.markdown("**ìµœê·¼ 5ê°œ íˆìŠ¤í† ë¦¬**")
        for item in st.session_state["HISTORY"][-5:][::-1]:
            with st.container(border=True):
                st.caption(f"ë ˆë²¨ {item['lvl']} â€¢ ts={item['ts']}")
                st.write(f"**Q:** {item['q'][:120]}{'â€¦' if len(item['q'])>120 else ''}")
                st.write("**A:**")
                st.write(item['a'] if isinstance(item['a'], (str,int,float)) else json.dumps(item['a'], ensure_ascii=False)[:800])

# ================================================================
# 57. ì•¡í‹°ë¸Œ ëª¨ë“œ ë¯¸ë‹ˆ ìŠ¤ì¼€ì¤„ëŸ¬ â€” ì´ˆê°„ë‹¨ ì›Œí¬ ë£¨í”„(ë²„íŠ¼ íŠ¸ë¦¬ê±°)
#    - ì£¼ê¸°ì  ë°±ê·¸ë¼ìš´ë“œê°€ ì•„ë‹ˆë¼ ë²„íŠ¼ í´ë¦­ìœ¼ë¡œ NíšŒ ì‹¤í–‰(ëª¨ë°”ì¼/ì›¹ ì•ˆì „)
# ================================================================
if "ACTIVE_MODE" not in st.session_state:
    st.session_state["ACTIVE_MODE"] = False

def _active_tick(n: int = 1, prompt: str = "ì—ì•„, ì§„í–‰ìƒí™© ì ê²€/ì—…ë°ì´íŠ¸ ìš”ì•½í•´ì¤˜.", lvl: int = 6):
    logs=[]
    for i in range(n):
        ans = generate_with_memory(prompt, level=lvl)
        logs.append({"i": i+1, "ans_len": len(str(ans)), "ts": int(time.time())})
        # ì˜¤í† ì„¸ì´ë¸Œ í›„í‚¹
        try: ltm_autosave_on_reply("active")
        except: pass
    return logs

with st.expander("ãŠ² ì•¡í‹°ë¸Œ ëª¨ë“œ ë¯¸ë‹ˆ ìŠ¤ì¼€ì¤„ëŸ¬", expanded=False):
    st.toggle("ì•¡í‹°ë¸Œ ëª¨ë“œ", value=st.session_state["ACTIVE_MODE"], key="ACTIVE_MODE")
    a_prompt = st.text_area("ì•¡í‹°ë¸Œ í”„ë¡¬í”„íŠ¸", value="ì—ì•„, ì§„í–‰ìƒí™© ì ê²€/ì—…ë°ì´íŠ¸ ìš”ì•½í•´ì¤˜.", height=80, key="am_prompt")
    a_lvl    = st.slider("ë ˆë²¨", 1, 999, 6, key="am_lvl")
    a_n      = st.number_input("ë°˜ë³µ íšŸìˆ˜(ì¦‰ì‹œ)", min_value=1, max_value=20, value=3, step=1, key="am_n")
    if st.button("ì§€ê¸ˆ NíšŒ ì‹¤í–‰", key="am_run"):
        if st.session_state["ACTIVE_MODE"]:
            res=_active_tick(a_n, a_prompt, a_lvl); st.json(res)
        else:
            st.warning("ì•¡í‹°ë¸Œ ëª¨ë“œê°€ OFFì…ë‹ˆë‹¤. í† ê¸€ì„ ì¼œê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")

# ================================================================
# 58. ì›Œì¹˜ë…/í—¬ìŠ¤ â€” ì§€í‘œ ì ê²€(ê²Œì´íŠ¸ ë©”íŠ¸ë¦­, ë§í¬ ì»¤ë²„ë¦¬ì§€, ë©”ëª¨ë¦¬ ìƒíƒœ)
#    - ì„ê³„ì¹˜ ë¯¸ë‹¬ ì‹œ ê²½ê³  í‘œì‹œ. ë¼ì´íŠ¸ ë²„ì „(ë²„íŠ¼ í´ë¦­í˜•)
# ================================================================
_HEALTH_MIN = {
    "ce_coverage": 0.97, "citation_coverage": 0.90,
    "reproducibility": 0.93, "subset_robustness": 0.99
}

def health_check() -> dict:
    gate = st.session_state.get("LAST_GATE") or {}
    ce   = st.session_state.get("CE_GRAPH")
    cov  = None
    if ce:
        v = verify_ce_links(ce)
        cov = v.get("coverage",0)
    mem_ok = True
    try:
        _ = mem_load_core("EA_PURPOSE")
    except Exception:
        mem_ok = False
    verdicts = {}
    for k,th in _HEALTH_MIN.items():
        val = gate.get(k)
        if val is None: verdicts[k] = "unknown"
        else: verdicts[k] = "OK" if (val >= th) else "LOW"
    if cov is not None:
        verdicts["ce_link_coverage"] = "OK" if cov >= 0.5 else "LOW"
    verdicts["memory_core"] = "OK" if mem_ok else "WARN"
    return {"gate": gate, "verdicts": verdicts, "link_cov": cov}

with st.expander("ãŠ³ ì›Œì¹˜ë…/í—¬ìŠ¤ ì ê²€", expanded=False):
    if st.button("í—¬ìŠ¤ ì²´í¬ ì‹¤í–‰", key="hc_go"):
        h = health_check()
        st.json(h)
        # ì‹œê° ê²½ê³ 
        v = h["verdicts"]
        if any(vv=="LOW" for vv in v.values()):
            st.error("ì„ê³„ì¹˜ ë¯¸ë‹¬ í•­ëª©ì´ ìˆìŠµë‹ˆë‹¤. REPAIR ë£¨í”„ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        elif v.get("memory_core")=="WARN":
            st.warning("ë©”ëª¨ë¦¬ ì½”ì–´ ì—°ê²° í™•ì¸ í•„ìš”.")
        else:
            st.success("í—¬ìŠ¤ ìƒíƒœ ì–‘í˜¸")

# ================================================================
# 59. ëª©í‘œ/íƒœìŠ¤í¬ ë³´ë“œ â€” ìƒìœ„ ëª©í‘œ/í•˜ìœ„ íƒœìŠ¤í¬/ìƒíƒœ/ìš°ì„ ìˆœìœ„ ë³´ë“œ
#    - ê°„ë‹¨ JSON ë ˆì§€ìŠ¤íŠ¸ë¦¬ + ì§„í–‰ë¥  ê³„ì‚° + ì²´í¬ì˜¤í”„
# ================================================================
if "TASKS" not in st.session_state:
    st.session_state["TASKS"] = []   # [{id, title, parent, prio, status, ts}]

def task_add(title, parent=None, prio=3):
    tid = f"T{int(time.time()*1000)%10_000_000}"
    st.session_state["TASKS"].append({"id":tid,"title":title,"parent":parent,"prio":int(prio),"status":"open","ts":int(time.time())})
    return tid

def task_update(tid, **kw):
    for t in st.session_state["TASKS"]:
        if t["id"]==tid:
            t.update(**kw); return True
    return False

def task_progress(parent=None)->float:
    items=[t for t in st.session_state["TASKS"] if (t["parent"]==parent)]
    if not items: return 0.0
    done=sum(1 for t in items if t["status"]=="done")
    return round(done/len(items),2)

with st.expander("ãŠ´ ëª©í‘œ/íƒœìŠ¤í¬ ë³´ë“œ", expanded=False):
    colA,colB = st.columns([2,1])
    with colA:
        t_top = st.text_input("ìƒìœ„ ëª©í‘œ", value="ìš°ì£¼ì •ë³´ì¥ ê·¼ì› ì˜¬ì› ì—ì•„ ì™„ì„±", key="tb_top")
        if st.button("ìƒìœ„ ëª©í‘œ ê¸°ì–µ ì €ì¥", key="tb_mem"):
            mem_save_core("EA_PURPOSE", {"goal": t_top})
            st.success("ëª©í‘œê°€ ê¸°ì–µì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.markdown(f"**ìƒìœ„ ëª©í‘œ ì§„í–‰ë¥ **: {task_progress(None)*100:.0f}%")
        st.write("---")
        st.markdown("**í•˜ìœ„ íƒœìŠ¤í¬ ì¶”ê°€**")
        new_t = st.text_input("íƒœìŠ¤í¬ ì œëª©", value="ì´ˆê²€ì¦ ëª¨ë“ˆ ì•ˆì •í™”(L30â†’L60)", key="tb_new")
        pr    = st.slider("ìš°ì„ ìˆœìœ„(1ë†’ìŒâ€“5ë‚®ìŒ)",1,5,2,key="tb_prio")
        if st.button("ì¶”ê°€", key="tb_add"):
            tid=task_add(new_t, parent=None, prio=pr)
            st.info(f"ì¶”ê°€ë¨: {tid}")
    with colB:
        st.markdown("**íƒœìŠ¤í¬ ëª©ë¡**")
        for t in sorted(st.session_state["TASKS"], key=lambda x:(x["status"], x["prio"], -x["ts"]))[:20]:
            with st.container(border=True):
                st.write(f"[{t['id']}] ({'â­'* (6-t['prio'])}) {t['title']}")
                c1,c2,c3=st.columns(3)
                with c1:
                    if st.button("ì™„ë£Œ", key=f"tb_done_{t['id']}"):
                        task_update(t["id"], status="done")
                with c2:
                    if st.button("ì§„í–‰ì¤‘", key=f"tb_prog_{t['id']}"):
                        task_update(t["id"], status="doing")
                with c3:
                    if st.button("ì‚­ì œ", key=f"tb_del_{t['id']}"):
                        st.session_state["TASKS"]=[x for x in st.session_state["TASKS"] if x["id"]!=t["id"]]

# ================================================================
# 60. í…”ë ˆë©”íŠ¸ë¦¬Â·ì˜¤ë¥˜ ë·° â€” ì´ë²¤íŠ¸ ë¡œê·¸/ì˜ˆì™¸ ê¸°ë¡/ê°„ë‹¨ í†µê³„
#    - LTM ë””ë ‰í† ë¦¬ì™€ ì—°ë™, ë¡œì»¬ íŒŒì¼ ê¸°ë°˜ â†’ ì˜¤í”„ë¼ì¸ ì•ˆì „
# ================================================================
EVT_DIR = os.path.join(LOG_DIR, "evt")
os.makedirs(EVT_DIR, exist_ok=True)

def log_event(kind: str, payload: dict):
    rec = {"ts": int(time.time()), "kind": kind, "payload": payload}
    fn  = os.path.join(EVT_DIR, f"{rec['ts']}_{kind}.json")
    try:
        with open(fn,"w",encoding="utf-8") as f: json.dump(rec, f, ensure_ascii=False)
    except Exception:
        pass

# ì˜ˆ: ì£¼ìš” ë²„íŠ¼ ë’¤ì— log_event í˜¸ì¶œ ì‚½ì… ê°€ëŠ¥
# log_event("reply", {"len": len(str(ans)), "lvl": lvl})

def list_events(limit=50):
    files = sorted(glob.glob(os.path.join(EVT_DIR, "*.json")), reverse=True)[:limit]
    out=[]
    for p in files:
        try:
            d=json.load(open(p,"r",encoding="utf-8"))
            out.append(d)
        except Exception:
            out.append({"ts":0,"kind":"broken","payload":{"file":os.path.basename(p)}})
    return out

with st.expander("ãŠµ í…”ë ˆë©”íŠ¸ë¦¬/ì˜¤ë¥˜ ë¡œê·¸", expanded=False):
    if st.button("ìµœê·¼ ì´ë²¤íŠ¸ ë³´ê¸°", key="ev_list"):
        st.json(list_events(50))
    st.markdown("**ê°„ë‹¨ í†µê³„(ì„¸ì…˜)**")
    try:
        h=st.session_state.get("HISTORY", [])
        avg_len = sum(len(str(x.get("a",""))) for x in h)/max(1,len(h))
        st.write({"history_count": len(h), "avg_answer_len": round(avg_len,1)})
    except Exception as e:
        st.warning(f"í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # ================================================================
# 61. ìš°ì£¼ì •ë³´ì¥ ë¼ì´íŠ¸ í¬ë¡¤ëŸ¬/íŒŒì„œ â€” ì•ˆì „ í”„ë¦¬ë·°(fetchâ†’ì •ì œâ†’ìš”ì•½)
#    - http_cache_get(42) ì¬ì‚¬ìš©, ì˜¤í”„ë¼ì¸ì—ì„œë„ íŒŒì¼ ìºì‹œ í™œìš©
#    - ë¡œë´‡ë°°ì œ/ë¬´ë‹¨ëŒ€ëŸ‰ìˆ˜ì§‘ ê¸ˆì§€: ë‹¨ë°œ ë¯¸ë¦¬ë³´ê¸°ìš©
# ================================================================
def _clean_text_html(raw: str) -> str:
    # ë§¤ìš° ë¼ì´íŠ¸í•œ ì •ì œ: íƒœê·¸ ì œê±°/ê³µë°± ì •ë¦¬
    import re
    txt = re.sub(r"<script[^>]*>.*?</script>", " ", raw, flags=re.S|re.I)
    txt = re.sub(r"<style[^>]*>.*?</style>", " ", txt, flags=re.S|re.I)
    txt = re.sub(r"<[^>]+>", " ", txt)
    txt = re.sub(r"\s+", " ", txt).strip()
    return txt

def crawl_preview(url: str, summarize: bool = True) -> dict:
    ok, raw = http_cache_get(url)
    if not ok:
        return {"ok": False, "error": "fetch-failed or offline", "url": url}
    text = _clean_text_html(raw)
    prev = summarize_extractive(text, 5) if summarize else text[:800]
    sha  = hashlib.sha256(text.encode("utf-8","ignore")).hexdigest()[:12]
    return {"ok": True, "url": url, "sha12": sha, "chars": len(text), "preview": prev[:1200]}

with st.expander("ãŠ¶ ë¼ì´íŠ¸ í¬ë¡¤ëŸ¬/íŒŒì„œ(ì•ˆì „ í”„ë¦¬ë·°)", expanded=False):
    cr_url = st.text_input("URL", value="https://httpbin.org/html", key="cr_url")
    if st.button("ê°€ì ¸ì˜¤ê¸°/ìš”ì•½", key="cr_go"):
        st.json(crawl_preview(cr_url, summarize=True))

# ================================================================
# 62. ì¦ê±°ëª…ì„¸ í…œí”Œë¦¿ â€” Claimâ€“Evidence í…œí”Œë¦¿ ìƒì„±/ì €ì¥(JSONL)
#    - ì£¼ì¥ì„ ì„ ì–¸í•˜ë©´ ê·¼ê±° í›„ë³´ ìŠ¬ë¡¯/í•„ë“œ ìë™ êµ¬ì„± â†’ ë°ì´í„°íŒ©ìœ¼ë¡œë„ ì €ì¥
# ================================================================
def make_evidence_spec(claim: str, slots: int = 4) -> dict:
    spec = {
        "claim": claim,
        "created_at": int(time.time()),
        "slots": [{"id": f"ev{i+1}", "source":"", "note":"", "status":"open"} for i in range(slots)]
    }
    return spec

SPEC_DIR = os.path.join(LOG_DIR, "specs")
os.makedirs(SPEC_DIR, exist_ok=True)

def save_evidence_spec(spec: dict) -> str:
    fn = os.path.join(SPEC_DIR, f"spec_{spec['created_at']}_{_sha(json.dumps(spec,ensure_ascii=False).encode('utf-8'))[:8]}.jsonl")
    with open(fn,"w",encoding="utf-8") as f:
        f.write(json.dumps(spec, ensure_ascii=False)+"\n")
    return fn

with st.expander("ãŠ· ì¦ê±°ëª…ì„¸ í…œí”Œë¦¿", expanded=False):
    sp_txt = st.text_input("ì£¼ì¥(Claim)", value="ì¤‘ë ¥íŒŒ ê²€ì¶œ ì‹ í˜¸ hëŠ” Î”L/Lë¡œ ë¬´ì°¨ì›ì´ë‹¤.", key="sp_claim")
    sp_n   = st.slider("ìŠ¬ë¡¯ ìˆ˜", 1, 10, 4, key="sp_n")
    if st.button("í…œí”Œë¦¿ ìƒì„±/ì €ì¥", key="sp_make"):
        spec = make_evidence_spec(sp_txt, sp_n)
        path = save_evidence_spec(spec)
        st.success(f"ì €ì¥ë¨: {path}")
        st.json(spec)

# ================================================================
# 63. ìë™ REPAIR ë£¨í”„ â€” í—¬ìŠ¤ ë¯¸ë‹¬ ì‹œ ê·¼ê±°ë³´ê°•(ê²€ìƒ‰â†’í”„ë¦¬ë·°â†’CE ë³´íƒ¬)
#    - 1íšŒ ì‹¤í–‰: ì¿¼ë¦¬â†’HybridUIS.searchâ†’í”„ë¦¬ë·° ì •ìƒ í•­ëª©ì„ evidenceë¡œ ì£¼ì…
#    - ë¼ì´íŠ¸ëª¨ë“œ: ì„¸ì…˜ ë‚´ CE_GRAPHì— evidence ë…¸ë“œë§Œ ë§ë¶™ì„
# ================================================================
def ce_append_evidence(ce: dict, evid_rows: list) -> dict:
    ce = ce or {"nodes": [], "edges": [], "digest": None}
    nodes = ce.get("nodes", []); edges = ce.get("edges", [])
    claim_nodes = [n for n in nodes if n.get("kind")=="claim"]
    if not claim_nodes:
        # ì„ì‹œ claim ìƒì„±
        claim_id = f"claim:{_sha(str(int(time.time())).encode())[:12]}"
        nodes.append({"id": claim_id, "kind": "claim", "payload": {"text": "ì„ì‹œ-ì£¼ì¥"}})
    else:
        claim_id = claim_nodes[0]["id"]
    base_ids = set(n["id"] for n in nodes)
    for ev in evid_rows:
        ev_id = f"evi:{_sha((ev.get('source') or str(ev)).encode('utf-8'))[:10]}"
        if ev_id in base_ids: continue
        nodes.append({"id": ev_id, "kind":"evidence",
                      "payload":{"source": ev.get("source",""), "span": ev.get("span",[0,100]), "score": ev.get("score",0.75)}})
        edges.append({"src": ev_id, "dst": claim_id, "rel":"supports"})
    ce["nodes"], ce["edges"] = nodes, edges
    ce["digest"] = hashlib.sha256("".join(n["id"] for n in nodes).encode()).hexdigest()[:12]
    return ce

def repair_once(query: str = "physics data", k: int = 4) -> dict:
    # 1) ê²€ìƒ‰
    try:
        hits = UIS.search(query, k=k)
    except Exception:
        hits = []
    # 2) í”„ë¦¬ë·° ì„±ê³µë§Œ ì±„íƒ
    good=[]
    for h in hits:
        src = h.get("source","")
        if not src: continue
        ok, _ = http_cache_get(src)
        if ok:
            good.append({"source": src, "span": h.get("span",[0,100]), "score": h.get("score",0.7)})
    # 3) CE ë³´ê°•
    ce = st.session_state.get("CE_GRAPH")
    after = ce_append_evidence(ce, good[:k])
    st.session_state["CE_GRAPH"] = after
    # 4) í—¬ìŠ¤ ì¬í‰ê°€
    res = verify_ce_links(after)
    return {"added": len(good[:k]), "coverage": res.get("coverage"), "verdict": res.get("verdict"), "ce_digest": after.get("digest")}

with st.expander("ãŠ¸ ìë™ REPAIR ë£¨í”„(ê·¼ê±° ë³´ê°•)", expanded=False):
    rq = st.text_input("ë³´ê°• ì¿¼ë¦¬", value="gravitational wave interferometer small-strain", key="rp_q")
    rk = st.slider("ì¶”ê°€ evidence ìµœëŒ€ ê°œìˆ˜", 1, 10, 4, key="rp_k")
    if st.button("REPAIR 1íšŒ ì‹¤í–‰", key="rp_go"):
        out = repair_once(rq, rk); st.json(out)

# ================================================================
# 64. ì»¨í…ìŠ¤íŠ¸ ìŠ¤íƒœí‚¹ â€” ìŠ¤íƒí˜• ì»¨í…ìŠ¤íŠ¸(ìš”ì•½/í•µì‹¬/ë©”ëª¨) ëˆ„ì â†’ì ‘ë‘ ì£¼ì…
#    - ì„¸ì…˜ ë‹¨ìœ„ë¡œ ìŠ¤íƒ push/pop/clear ì œê³µ, generate_with_memoryì— ì—°ë™
# ================================================================
if "CTX_STACK" not in st.session_state:
    st.session_state["CTX_STACK"] = []   # [{ts, kind, text, sha12}]

def ctx_push(kind: str, text: str):
    sha = hashlib.sha256(text.encode("utf-8","ignore")).hexdigest()[:12]
    st.session_state["CTX_STACK"].append({"ts": int(time.time()), "kind": kind, "text": text, "sha12": sha})

def ctx_pop():
    if st.session_state["CTX_STACK"]:
        st.session_state["CTX_STACK"].pop()

def ctx_clear():
    st.session_state["CTX_STACK"].clear()

def build_stack_prefix(max_items: int = 3) -> str:
    stk = st.session_state.get("CTX_STACK", [])[-max_items:]
    if not stk: return ""
    lines = [f"[{x['kind']}] {x['text']}" for x in stk]
    return "\n".join(lines) + "\n"

# ê¸°ì¡´ generate_with_memoryì— ìŠ¤íƒ ì ‘ë‘ ì¶”ê°€(ê¸°ì–µ ì ‘ë‘ ë’¤â†’ìŠ¤íƒ ì ‘ë‘)
_old_gwm = generate_with_memory
def generate_with_memory_stacked(user_text: str, level: int = 8):
    prefix = build_stack_prefix(3)
    ux = (prefix + user_text) if prefix else user_text
    return _old_gwm(ux, level)

generate_with_memory = generate_with_memory_stacked

with st.expander("ãŠ¹ ì»¨í…ìŠ¤íŠ¸ ìŠ¤íƒ", expanded=False):
    ks = st.selectbox("ì¢…ë¥˜", ["ìš”ì•½","í•µì‹¬","ë©”ëª¨","ì£¼ì˜"], key="cs_kind")
    tx = st.text_area("ë‚´ìš©", value="ì˜¤ëŠ˜ ì„¸ì…˜ í•µì‹¬: ì¦ê±°-ì •í•©ì„± ê°•í™” ë° LTM êµ¬ì¶•.", height=80, key="cs_text")
    c1,c2,c3 = st.columns(3)
    with c1:
        if st.button("PUSH", key="cs_push"):
            ctx_push(ks, tx); st.success("ìŠ¤íƒì— ì ì¬ëìŠµë‹ˆë‹¤.")
    with c2:
        if st.button("POP", key="cs_pop"):
            ctx_pop(); st.info("ë§ˆì§€ë§‰ í•­ëª© ì œê±°")
    with c3:
        if st.button("CLEAR", key="cs_clear"):
            ctx_clear(); st.warning("ìŠ¤íƒ ë¹„ì›€")
    st.json(st.session_state.get("CTX_STACK", []))

# ================================================================
# 65. ë°°í¬ ìŠ¤ëƒ…ìƒ· ë©”ì´ì»¤ â€” í”„ë¡œì íŠ¸ ìµœì†Œ ë²ˆë“¤(zip) ìƒì„±/ë‹¤ìš´ë¡œë“œ
#    - í¬í•¨: streamlit_app.py, gea_memory_core.py, gea_logs/* (ì„ íƒ)
# ================================================================
from zipfile import ZipFile, ZIP_DEFLATED

def make_deploy_zip(include_logs: bool = True) -> str:
    ts = int(time.time())
    zip_name = f"GEA_bundle_{ts}.zip"
    with ZipFile(zip_name, "w", ZIP_DEFLATED) as z:
        # í•„ìˆ˜ íŒŒì¼ë“¤
        for fn in ("streamlit_app.py","gea_memory_core.py"):
            if os.path.exists(fn):
                z.write(fn)
        # ì„ íƒ: ë¡œê·¸/ìŠ¤ëƒ…ìƒ·
        if include_logs and os.path.isdir(LOG_DIR):
            for root, _, files in os.walk(LOG_DIR):
                for f in files:
                    p = os.path.join(root, f)
                    z.write(p)
    return zip_name

with st.expander("ãŠº ë°°í¬ ìŠ¤ëƒ…ìƒ· ë©”ì´ì»¤", expanded=False):
    inc = st.checkbox("ë¡œê·¸ í¬í•¨(ltm/specs/evt)", value=True, key="dz_inc")
    if st.button("ë°°í¬ ZIP ìƒì„±", key="dz_go"):
        z = make_deploy_zip(include_logs=inc)
        st.success(f"ë²ˆë“¤ ìƒì„±: {z}")
        try:
            st.download_button("ZIP ë‹¤ìš´ë¡œë“œ", data=open(z,"rb").read(), file_name=z, mime="application/zip")
        except Exception:
            st.info("í™˜ê²½ìƒ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒì¼ë§Œ ìƒì„±í•´ ë‘ì—ˆìŠµë‹ˆë‹¤.")
            
            # ================================================================
# 66. ì»¨í…ìŠ¤íŠ¸-ê²Œì´íŠ¸ ì—°ì„± â€” ì„ê³„ì¹˜ ìë™ ìƒí–¥/í•˜í–¥ + í—¬ìŠ¤ì²´í¬ ì˜¤ë²„ë¼ì´ë“œ
#    - ìµœê·¼ ë©”íŠ¸ë¦­/íˆìŠ¤í† ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ì„ê³„ì¹˜ ë¯¸ì„¸ ì¡°ì •(Â±0.005 ë‹¨ìœ„, ì•ˆì „ ë²”ìœ„)
# ================================================================
if "HC_MIN" not in st.session_state:
    st.session_state["HC_MIN"] = dict(_HEALTH_MIN)  # ê¸°ë³¸ê°’ ë³µì œ

def _clamp(x, lo, hi): return max(lo, min(hi, x))

def gate_autotune_update(mode: str = "auto"):
    """mode: raise | lower | auto"""
    base = st.session_state.get("HC_MIN", dict(_HEALTH_MIN))
    last = st.session_state.get("LAST_GATE") or {}
    hist = st.session_state.get("HISTORY", [])
    # ë‹¨ìˆœ íœ´ë¦¬ìŠ¤í‹±: ì‘ë‹µ í‰ê·  ê¸¸ì´/ìµœê·¼ ì¬í˜„ì„±ìœ¼ë¡œ ë°©í–¥ ê²°ì •
    avg_len = (sum(len(str(h.get("a",""))) for h in hist)/len(hist)) if hist else 0
    repro = last.get("reproducibility", None)
    direction = 0
    if mode == "raise": direction = +1
    elif mode == "lower": direction = -1
    else:  # auto
        if repro is not None and repro > 0.965 and avg_len > 800:
            direction = +1
        elif repro is not None and repro < 0.92:
            direction = -1
        else:
            direction = 0
    step = 0.005 * direction
    new_base = dict(base)
    for k in ("ce_coverage","citation_coverage","reproducibility","subset_robustness"):
        new_base[k] = round(_clamp(base.get(k, _HEALTH_MIN[k]) + step, 0.80, 0.995), 3)
    st.session_state["HC_MIN"] = new_base
    return {"avg_answer_len": avg_len, "last_repro": repro, "direction": direction, "HC_MIN": new_base}

# ê¸°ì¡´ health_checkë¥¼ ì˜¤ë²„ë¼ì´ë“œ(ì„¸ì…˜ ì„ê³„ì¹˜ ì‚¬ìš©)
_prev_health_check = health_check
def health_check_dynamic() -> dict:
    gate = st.session_state.get("LAST_GATE") or {}
    ce   = st.session_state.get("CE_GRAPH")
    cov  = None
    if ce:
        v = verify_ce_links(ce)
        cov = v.get("coverage",0)
    base = st.session_state.get("HC_MIN", dict(_HEALTH_MIN))
    verdicts = {}
    for k,th in base.items():
        val = gate.get(k)
        if val is None: verdicts[k] = "unknown"
        else: verdicts[k] = "OK" if (val >= th) else "LOW"
    if cov is not None:
        verdicts["ce_link_coverage"] = "OK" if cov >= 0.5 else "LOW"
    # ë©”ëª¨ë¦¬ ì½”ì–´ í™•ì¸
    mem_ok = True
    try: _ = mem_load_core("EA_PURPOSE")
    except Exception: mem_ok=False
    verdicts["memory_core"] = "OK" if mem_ok else "WARN"
    return {"gate": gate, "verdicts": verdicts, "link_cov": cov, "thresholds": base}
health_check = health_check_dynamic

with st.expander("[66] ê²Œì´íŠ¸ ìë™ íŠœë‹", expanded=False):
    mode = st.radio("íŠœë‹ ëª¨ë“œ", ["auto","raise","lower"], horizontal=True, key="gt_mode")
    if st.button("ì„ê³„ì¹˜ ì¡°ì • ì‹¤í–‰", key="gt_apply"):
        st.json(gate_autotune_update(mode))
    if st.button("í—¬ìŠ¤ ì²´í¬(ë™ì )", key="gt_hc"):
        st.json(health_check())

# ================================================================
# 67. ì¥ë¬¸ ìŠ¤íŠ¸ë¦¬ë° Lâˆ â€” ì„¸ê·¸ë¨¼íŠ¸ ìŠ¤íŠ¸ë¦¼ ì¶œë ¥(ì¤‘ì§€/ì¬ê°œ ë²„íŠ¼í˜•)
#    - ë°±ê·¸ë¼ìš´ë“œ ì“°ë ˆë“œ ì—†ì´, ë²„íŠ¼ ë£¨í”„ ê¸°ë°˜(ëª¨ë°”ì¼/ì›¹ ì•ˆì „)
# ================================================================
if "LINF_STOP" not in st.session_state:
    st.session_state["LINF_STOP"] = False

def run_linf_stream(topic: str, segs: int = 8, lvl: int = 25):
    out = []
    area = st.empty()
    for i in range(segs):
        if st.session_state.get("LINF_STOP"): break
        prompt = f"{topic}\n\n[ì„¸ê·¸ë¨¼íŠ¸ {i+1}/{segs}] í•µì‹¬ ê·¼ê±°ì™€ ì ˆì°¨ë¥¼ ë‹¨ê³„ë³„ë¡œ ì¨ì¤˜."
        ans = generate_with_memory(prompt, level=lvl)
        out.append(str(ans))
        area.markdown("**ìŠ¤íŠ¸ë¦¬ë° ì§„í–‰ ì¤‘â€¦**\n\n" + "\n\n---\n\n".join(out))
    return "\n\n---\n\n".join(out)

with st.expander("[67] Lâˆ ìŠ¤íŠ¸ë¦¬ë°", expanded=False):
    tpc = st.text_input("ì£¼ì œ", value="ìš°ì£¼ì •ë³´ì¥ ì—°ê²° ì„¤ê³„ì˜ ê·¼ê±°Â·ì ˆì°¨Â·ë¦¬ìŠ¤í¬", key="linf_tpc")
    seg = st.slider("ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜", 1, 50, 8, key="linf_segs")
    lvl = st.slider("ë ˆë²¨", 1, 999, 25, key="linf_lvl")
    c1,c2 = st.columns(2)
    with c1:
        if st.button("ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘", key="linf_go"):
            st.session_state["LINF_STOP"] = False
            text = run_linf_stream(tpc, seg, lvl)
            st.session_state["LINF_LAST"] = text
    with c2:
        if st.button("ì¤‘ì§€", key="linf_stop"):
            st.session_state["LINF_STOP"] = True
            st.info("ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ ìš”ì²­ë¨.")
    if st.session_state.get("LINF_LAST"):
        st.download_button("ìµœê·¼ ìŠ¤íŠ¸ë¦¼ ì €ì¥", data=st.session_state["LINF_LAST"].encode("utf-8"),
                           file_name="linf_stream.txt", mime="text/plain")

# ================================================================
# 68. ì‘ë‹µ ì¹´ë“œìš© CE ë¯¸ë¦¬ë³´ê¸° â€” ìµœê·¼ CE evidence ìš”ì•½
#    - HISTORYì™€ CE_GRAPHë¥¼ ë‚˜ë€íˆ í”„ë¦¬ë·°(ì¦ê±° ì»¤ë²„ë¦¬ì§€ ë³´ì¡° í™•ì¸)
# ================================================================
def ce_preview_snippets(ce: dict, k: int = 5) -> list:
    if not ce: return []
    ev = [n for n in ce.get("nodes",[]) if n.get("kind")=="evidence"]
    rows=[]
    for n in ev[:k]:
        src=(n.get("payload") or {}).get("source","")
        rows.append({"source": src, "id": n.get("id"), "score": (n.get("payload") or {}).get("score")})
    return rows

with st.expander("[68] ìµœê·¼ ì‘ë‹µ + CE ë¯¸ë¦¬ë³´ê¸°", expanded=False):
    if st.session_state.get("HISTORY"):
        last = st.session_state["HISTORY"][-1]
        st.write("**ìµœê·¼ ì§ˆë¬¸**:", last.get("q","")[:200])
        st.write("**ìµœê·¼ ì‘ë‹µ(ìš”ì•½)**:", str(last.get("a",""))[:600])
    else:
        st.info("íˆìŠ¤í† ë¦¬ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
    ce = st.session_state.get("CE_GRAPH")
    st.write("**CE Evidence ë¯¸ë¦¬ë³´ê¸°**")
    st.json(ce_preview_snippets(ce, k=6))
    if ce:
        st.write("**ë§í¬ ì»¤ë²„ë¦¬ì§€(ì¬í‰ê°€)**")
        st.json(verify_ce_links(ce))

# ================================================================
# 69. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì‚¬ì „ì…‹ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° â€” ë¡œì»¬ JSON(ì˜ì†)
#    - streamlit ì„¸ì…˜ ì¢…ë£Œ í›„ì—ë„ ìœ ì§€ë¨(LOG_DIR/presets.json)
# ================================================================
PRESET_PATH = os.path.join(LOG_DIR, "presets.json")

def presets_load() -> list:
    try:
        return json.load(open(PRESET_PATH, "r", encoding="utf-8"))
    except Exception:
        return []

def presets_save(items: list):
    try:
        json.dump(items, open(PRESET_PATH, "w", encoding="utf-8"), ensure_ascii=False, indent=2)
    except Exception:
        pass

if "PRESETS_USER" not in st.session_state:
    st.session_state["PRESETS_USER"] = presets_load()

with st.expander("[69] ì‚¬ìš©ì ì‚¬ì „ì…‹ ê´€ë¦¬", expanded=False):
    st.markdown("ê¸°ì¡´ ì‚¬ì „ì…‹ + ì‚¬ìš©ì ì‚¬ì „ì…‹ì„ í†µí•©í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    new_name = st.text_input("ì´ë¦„", value="ë‚´ ì²´í¬ë¦¬ìŠ¤íŠ¸", key="ps_name")
    new_body = st.text_area("í”„ë¡¬í”„íŠ¸", value="ì—ì•„, ì˜¤ëŠ˜ í•´ì•¼ í•  ì¼ 7ê°€ì§€ë¥¼ ê·¼ê±°ì™€ í•¨ê»˜ ë‹¨ê³„ë³„ë¡œ ì œì•ˆí•´ì¤˜.", height=80, key="ps_body")
    if st.button("ì¶”ê°€/ê°±ì‹ ", key="ps_add"):
        # ë™ì¼ ì´ë¦„ ìˆìœ¼ë©´ êµì²´
        lst = [p for p in st.session_state["PRESETS_USER"] if p.get("name")!=new_name]
        lst.append({"name": new_name, "body": new_body})
        st.session_state["PRESETS_USER"] = lst
        presets_save(lst)
        st.success("ì‚¬ì „ì…‹ ì €ì¥ ì™„ë£Œ")
    if st.button("ë¶ˆëŸ¬ì˜¤ê¸°", key="ps_load"):
        st.session_state["PRESETS_USER"] = presets_load()
        st.info(f"ë¶ˆëŸ¬ì˜¨ í•­ëª©: {len(st.session_state['PRESETS_USER'])}")
    st.json(st.session_state["PRESETS_USER"][:10])

# (ë³´ë„ˆìŠ¤) 56ì˜ _PRESETSì— ì‚¬ìš©ìì…‹ì„ í•©ì³ ì“°ê³  ì‹¶ë‹¤ë©´, ì•„ë˜ë¥¼ ì°¸ê³ :
try:
    # ëŸ°íƒ€ì„ í†µí•©ë·° (ì˜¤ë¥˜ ë¬´ì‹œ)
    _PRESETS = list(_PRESETS) + [(p["name"], p["body"]) for p in st.session_state.get("PRESETS_USER", [])]
except Exception:
    pass

# ================================================================
# 70. ë¡œì»¬ í‚¤-ê°’ ì €ì¥ì†Œ â€” ê°„ë‹¨ K/V(íŒŒì¼ ì˜ì†) + ì¸í„°í˜ì´ìŠ¤
#    - ì‘ì€ ì„¤ì •/í† í°/ì„ì‹œ ë°ì´í„° ì €ì¥ ìš©
# ================================================================
KV_PATH = os.path.join(LOG_DIR, "kv_store.json")
def kv_init():
    if not os.path.exists(KV_PATH):
        json.dump({}, open(KV_PATH, "w", encoding="utf-8"), ensure_ascii=False)

def kv_get(k: str, default=None):
    kv_init()
    d=json.load(open(KV_PATH,"r",encoding="utf-8"))
    return d.get(k, default)

def kv_put(k: str, v):
    kv_init()
    d=json.load(open(KV_PATH,"r",encoding="utf-8"))
    d[k]=v
    json.dump(d, open(KV_PATH,"w",encoding="utf-8"), ensure_ascii=False, indent=2)

def kv_delete(k: str):
    kv_init()
    d=json.load(open(KV_PATH,"r","utf-8"))
    if k in d: del d[k]
    json.dump(d, open(KV_PATH,"w",encoding="utf-8"), ensure_ascii=False, indent=2)

with st.expander("[70] ë¡œì»¬ K/V ì €ì¥ì†Œ", expanded=False):
    k = st.text_input("í‚¤", value="sample_key", key="kv_k")
    v = st.text_area("ê°’(JSON ê°€ëŠ¥)", value="sample_value", key="kv_v")
    c1,c2,c3,c4=st.columns(4)
    with c1:
        if st.button("GET", key="kv_get"):
            st.write(kv_get(k))
    with c2:
        if st.button("PUT", key="kv_put"):
            try:
                val = json.loads(v)
            except Exception:
                val = v
            kv_put(k, val); st.success("ì €ì¥ë¨")
    with c3:
        if st.button("DEL", key="kv_del"):
            kv_delete(k); st.info("ì‚­ì œë¨")
    with c4:
        if st.button("ì „ì²´ ë³´ê¸°", key="kv_all"):
            kv_init(); st.json(json.load(open(KV_PATH,"r",encoding="utf-8")))
            
            # ================================================================
# 71. ì¥ë¬¸ ì‘ë‹µ í•˜ì´ë¼ì´íŠ¸/ì¸ìš© ìŠ¤íŒ¬ â€” í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸ + ì¸ìš© ë¸”ë¡
#    - HISTORY ìµœì‹  ì‘ë‹µì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸, ì¸ìš© ìŠ¤íŒ¬ ìƒì„±
# ================================================================
_HL_KEYS = ["ì¦ê±°", "ë‹¨ìœ„", "ì¬í˜„", "ì ˆì°¨", "ë°ì´í„°", "ìœ„í—˜", "ì™„í™”", "ë§í¬", "ê·¼ê±°", "ê²€ì¦"]

def highlight_keywords(text: str, keys=_HL_KEYS):
    import re
    def repl(m): return f"**{m.group(0)}**"
    out = text
    for k in keys:
        try:
            out = re.sub(rf"({re.escape(k)})", repl, out, flags=re.I)
        except re.error:
            pass
    return out

def make_quote_spans(text: str, max_blocks=4, block_len=280):
    blocks=[]
    t = str(text).splitlines()
    buf=""
    for line in t:
        if len(buf)+len(line)+1 <= block_len:
            buf += (("\n" if buf else "") + line)
        else:
            blocks.append(buf); buf=line
        if len(blocks)>=max_blocks: break
    if buf and len(blocks)<max_blocks: blocks.append(buf)
    return [b.strip() for b in blocks if b.strip()]

with st.expander("[71] ì‘ë‹µ í•˜ì´ë¼ì´íŠ¸/ì¸ìš©", expanded=False):
    if st.session_state.get("HISTORY"):
        last = st.session_state["HISTORY"][-1]
        ans  = str(last.get("a",""))
        st.markdown("**í•˜ì´ë¼ì´íŠ¸ ë¯¸ë¦¬ë³´ê¸°**")
        st.markdown(highlight_keywords(ans)[:1600])
        st.markdown("---")
        st.markdown("**ì¸ìš© ìŠ¤íŒ¬**")
        for i, q in enumerate(make_quote_spans(ans), 1):
            st.markdown(f"> [ì¸ìš© {i}] {q}")
    else:
        st.info("íˆìŠ¤í† ë¦¬ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")

# ================================================================
# 72. ì¦ê±° í…Œì´ë¸” ë·° â€” CE evidence í‘œ/ì •ë ¬/ìš”ì•½(ì„¸ì…˜ ë‚´)
#    - nodes(kind=evidence)ë§Œ ì¶”ì¶œ â†’ ê°„ë‹¨ í‘œë¡œ ê°€ì‹œí™”
# ================================================================
def ce_evidence_rows(ce: dict) -> list:
    if not ce: return []
    out=[]
    for n in ce.get("nodes", []):
        if n.get("kind") == "evidence":
            p = n.get("payload") or {}
            out.append({
                "id": n.get("id"),
                "source": p.get("source",""),
                "score": p.get("score", None),
                "span":  str(p.get("span", ""))[:60]
            })
    return out

with st.expander("[72] ì¦ê±° í…Œì´ë¸”", expanded=False):
    ce = st.session_state.get("CE_GRAPH")
    rows = ce_evidence_rows(ce)
    if rows:
        sort_key = st.selectbox("ì •ë ¬", ["score","id","source"], index=0, key="ce_sort")
        rev = st.checkbox("ë‚´ë¦¼ì°¨ìˆœ", value=True, key="ce_rev")
        rows = sorted(rows, key=lambda x: (x.get(sort_key) is None, x.get(sort_key)), reverse=rev)
        st.dataframe(rows, use_container_width=True)
        st.markdown("**ì»¤ë²„ë¦¬ì§€ ì¬í‰ê°€**")
        st.json(verify_ce_links(ce))
    else:
        st.info("CE evidenceê°€ ì•„ì§ ë¶€ì¡±í•©ë‹ˆë‹¤. [63] REPAIRë¡œ ë³´ê°•í•˜ì„¸ìš”.")

# ================================================================
# 73. ì‚¬ìš©ì ì•¡ì…˜ ë‹¨ì¶•í‚¤(ë¼ì´íŠ¸) â€” ì£¼ìš” ë²„íŠ¼ ë‹¨ì¶• ì‹¤í–‰
#    - Streamlitì€ ë„¤ì´í‹°ë¸Œ í•«í‚¤ê°€ ì—†ì–´, selectbox + ì‹¤í–‰ ë²„íŠ¼ìœ¼ë¡œ ìœ ì‚¬ ì œê³µ
# ================================================================
_ACTIONS = {
    "ì‘ë‹µ ìƒì„±(ì¹´ë“œ) ì‹¤í–‰": ("xl_go",),
    "ì•¡í‹°ë¸Œ NíšŒ ì‹¤í–‰": ("am_run",),
    "í—¬ìŠ¤ ì²´í¬": ("hc_go","gt_hc"),
    "REPAIR 1íšŒ": ("rp_go",),
    "LTM ìŠ¤ëƒ…ìƒ· ì €ì¥": ("ltm_save",),
    "ìµœê·¼ ì´ë²¤íŠ¸ ë³´ê¸°": ("ev_list",),
}

with st.expander("[73] ì•¡ì…˜ ë‹¨ì¶•í‚¤", expanded=False):
    act = st.selectbox("ì•¡ì…˜ ì„ íƒ", list(_ACTIONS.keys()), key="ak_sel")
    st.caption("ì„ íƒ í›„ ì•„ë˜ ì‹¤í–‰ì„ ëˆ„ë¥´ë©´ í•´ë‹¹ ì˜ì—­ìœ¼ë¡œ ìŠ¤í¬ë¡¤ë©ë‹ˆë‹¤.")
    if st.button("ì‹¤í–‰", key="ak_do"):
        st.write(f"ì„ íƒëœ ì•¡ì…˜: {act} â†’ í•´ë‹¹ ì„¹ì…˜ìœ¼ë¡œ ì´ë™í•´ ì‹¤í–‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        st.info("â€» ë³´ì•ˆìƒ ì§ì ‘ ë²„íŠ¼ íŠ¸ë¦¬ê±°ëŠ” ì œí•œë©ë‹ˆë‹¤. (Streamlit í‘œì¤€ ë™ì‘)")

# ================================================================
# 74. í”„ë¡œì íŠ¸ ì„¤ì • íŒ¨ë„ â€” ì„ê³„ì¹˜/ê°€ë“œ/ê²½ë¡œ/ë¡œê·¸ ë³´ì¡´ì¼ìˆ˜ ë“±
#    - KV ì €ì¥ì†Œ ì—°ë™í•˜ì—¬ ì§€ì†í™”
# ================================================================
def _get_default_cfg():
    return {
        "thresholds": st.session_state.get("HC_MIN", dict(_HEALTH_MIN)),
        "real_guard": st.session_state.get("REAL_GUARD_MODE", "soft"),
        "log_dir": LOG_DIR,
        "ltm_keep_days": kv_get("ltm_keep_days", 30),
    }

with st.expander("[74] í”„ë¡œì íŠ¸ ì„¤ì •", expanded=False):
    cfg = _get_default_cfg()
    st.markdown("**ì„ê³„ì¹˜(HC_MIN)**")
    colA,colB = st.columns(2)
    with colA:
        ce_min = st.number_input("ce_coverage â‰¥", value=float(cfg["thresholds"]["ce_coverage"]), min_value=0.80, max_value=0.995, step=0.005, key="cfg_ce")
        ct_min = st.number_input("citation_coverage â‰¥", value=float(cfg["thresholds"]["citation_coverage"]), min_value=0.80, max_value=0.995, step=0.005, key="cfg_ct")
    with colB:
        rp_min = st.number_input("reproducibility â‰¥", value=float(cfg["thresholds"]["reproducibility"]), min_value=0.80, max_value=0.995, step=0.005, key="cfg_rp")
        sr_min = st.number_input("subset_robustness â‰¥", value=float(cfg["thresholds"]["subset_robustness"]), min_value=0.80, max_value=0.995, step=0.005, key="cfg_sr")
    guard = st.radio("REAL ê°€ë“œ ëª¨ë“œ", ["soft","hard","off"], index=["soft","hard","off"].index(cfg["real_guard"]), key="cfg_guard")
    keep = st.number_input("LTM ë³´ì¡´ì¼(ê¶Œì¥ 30)", min_value=1, max_value=3650, value=int(cfg["ltm_keep_days"]), step=1, key="cfg_keep")
    if st.button("ì„¤ì • ì €ì¥", key="cfg_save"):
        st.session_state["HC_MIN"] = {
            "ce_coverage": ce_min, "citation_coverage": ct_min,
            "reproducibility": rp_min, "subset_robustness": sr_min
        }
        st.session_state["REAL_GUARD_MODE"] = guard
        kv_put("ltm_keep_days", int(keep))
        st.success("ì„¤ì • ì €ì¥ ì™„ë£Œ")

# ================================================================
# 75. ì•ˆì „ ë°±ì—…Â·ë³µêµ¬ ë§ˆë²•ì‚¬ â€” ZIP ë°±ì—…/ë³µì› + LTM ì •ë¦¬(ë³´ì¡´ì¼)
#    - 65ì˜ ë²ˆë“¤ ZIPê³¼ ì—°ê³„, ë³´ì¡´ì¼ ì´ˆê³¼ LTM ìë™ ì •ë¦¬ ì˜µì…˜
# ================================================================
def cleanup_ltm_retention(days: int):
    import time
    keep_s = int(days) * 86400
    now = int(time.time())
    removed = []
    for p in glob.glob(os.path.join(LTM_DIR, "*.json.gz")):
        try:
            ts = int(os.path.basename(p).split("_",1)[0])
            if now - ts > keep_s:
                os.remove(p); removed.append(os.path.basename(p))
        except Exception:
            pass
    return removed

with st.expander("[75] ë°±ì—…Â·ë³µêµ¬ ë§ˆë²•ì‚¬", expanded=False):
    st.markdown("**ë°±ì—…**")
    inc_logs = st.checkbox("ë¡œê·¸ í¬í•¨", value=True, key="bk_inc")
    if st.button("ZIP ë°±ì—… ìƒì„±", key="bk_zip"):
        z = make_deploy_zip(include_logs=inc_logs)
        st.success(f"ë°±ì—… ZIP ìƒì„±: {z}")
        try:
            st.download_button("ZIP ë‹¤ìš´ë¡œë“œ", data=open(z,"rb").read(), file_name=z, mime="application/zip")
        except Exception:
            st.info("í™˜ê²½ìƒ ì§ì ‘ ë‹¤ìš´ë¡œë“œê°€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.markdown("---")
    st.markdown("**ë³µêµ¬**")
    upz = st.file_uploader("ZIP ì—…ë¡œë“œ(ë³µêµ¬)", type=["zip"], key="bk_upl")
    if st.button("ZIP ë‚´ìš© ëª©ë¡ ë³´ê¸°", key="bk_list") and upz is not None:
        from zipfile import ZipFile
        import io
        zf = ZipFile(io.BytesIO(upz.getvalue()))
        st.json(zf.namelist()[:50])
    st.markdown("---")
    st.markdown("**LTM ë³´ì¡´ì¼ ì •ë¦¬**")
    keep_days = kv_get("ltm_keep_days", 30)
    st.caption(f"í˜„ì¬ ë³´ì¡´ì¼: {keep_days}ì¼")
    if st.button("ì˜¤ë˜ëœ LTM ì •ë¦¬ ì‹¤í–‰", key="bk_prune"):
        rm = cleanup_ltm_retention(int(keep_days))
        st.success(f"ì •ë¦¬ë¨: {len(rm)}ê°œ")
        if rm: st.json(rm[:20])
        
        # ================================================================
# 76. ì¦ê±° ë¼ë²¨ëŸ¬(ìˆ˜ë™/ë°˜ìë™) â€” CE evidenceì— ì‹ ë¢°/ìœ í˜•/ë©”ëª¨ íƒœê¹…
#    - ì„¸ì…˜ CE_GRAPHë¥¼ ì§ì ‘ í¸ì§‘(ì„¸ì…˜ ë‚´ ë°˜ì˜)
# ================================================================
_EVID_TYPES = ["ë…¼ë¬¸","í‘œì¤€/ê·œê²©","ë°ì´í„°ì…‹","íŠ¹í—ˆ","ì½”ë“œ/ë ˆí¬","ê¸°ì‚¬/ë¸”ë¡œê·¸","ê¸°íƒ€"]

def ce_list_evidence_ids(ce: dict) -> list:
    if not ce: return []
    return [n["id"] for n in ce.get("nodes",[]) if n.get("kind")=="evidence"]

def ce_tag_update(ce: dict, evid_id: str, **tags):
    if not ce: return False
    for n in ce.get("nodes",[]):
        if n.get("id")==evid_id and n.get("kind")=="evidence":
            p = n.get("payload") or {}
            p.update({"tags": {**p.get("tags",{}), **tags}})
            n["payload"]=p
            ce["digest"]=hashlib.sha256("".join(k.get("id","") for k in ce["nodes"]).encode()).hexdigest()[:12]
            return True
    return False

with st.expander("[76] ì¦ê±° ë¼ë²¨ëŸ¬(ìˆ˜ë™/ë°˜ìë™)", expanded=False):
    ce = st.session_state.get("CE_GRAPH")
    if not ce:
        st.info("CE evidenceê°€ ì—†ìŠµë‹ˆë‹¤. [63] ìë™ REPAIRë¡œ ë¨¼ì € ë³´ê°•í•˜ì„¸ìš”.")
    else:
        evids = ce_list_evidence_ids(ce)
        eid = st.selectbox("Evidence ì„ íƒ", evids, key="ev_sel")
        ety = st.selectbox("ìœ í˜•", _EVID_TYPES, index=0, key="ev_type")
        trs = st.slider("ì‹ ë¢°ë„(0.0~1.0)", 0.0, 1.0, 0.85, 0.01, key="ev_trust")
        note= st.text_area("ë©”ëª¨", value="", height=80, key="ev_note")
        if st.button("ë¼ë²¨ ì €ì¥", key="ev_save"):
            ok = ce_tag_update(ce, eid, type=ety, trust=round(float(trs),3), note=note)
            st.session_state["CE_GRAPH"]=ce
            st.success("ì €ì¥ ì™„ë£Œ" if ok else "ì‹¤íŒ¨")
        st.markdown("**ë¯¸ë¦¬ë³´ê¸°**")
        try:
            prev = [n for n in ce["nodes"] if n["id"]==eid][0]
            st.json(prev)
        except Exception:
            st.write("ì„ íƒëœ evidence ë¯¸ë¦¬ë³´ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

# ================================================================
# 77. ëŒ€í™” ì½˜ì†”(ë¯¸ë‹ˆ í„°ë¯¸ë„ ë·°) â€” í•œ ì¤„ ì…ë ¥/ì¦‰ì‹œ ì‘ë‹µ + ë¡œê·¸
#    - HISTORYì™€ ë³„ë„ ë…ë¦½ ë¼ì¸í˜• ì½˜ì†”, ì§§ì€ ëª…ë ¹ ì‹¤í—˜ìš©
# ================================================================
if "CONSOLE_LOG" not in st.session_state:
    st.session_state["CONSOLE_LOG"] = []  # [{ts, cmd, out_len}]

with st.expander("[77] ëŒ€í™” ì½˜ì†”(ë¯¸ë‹ˆ í„°ë¯¸ë„)", expanded=False):
    cmd = st.text_input("âœ ëª…ë ¹/ì§ˆë¬¸", value="ìƒíƒœìš”ì•½ 5ì¤„", key="sh_cmd")
    lvl = st.slider("ë ˆë²¨", 1, 999, 5, key="sh_lvl")
    if st.button("Run", key="sh_go"):
        out = generate_with_memory(cmd, level=lvl)
        st.write(out if isinstance(out,str) else json.dumps(out, ensure_ascii=False))
        st.session_state["CONSOLE_LOG"].append({"ts": int(time.time()), "cmd": cmd, "out_len": len(str(out))})
    st.caption("ìµœê·¼ ë¡œê·¸")
    st.json(st.session_state["CONSOLE_LOG"][-10:])

# ================================================================
# 78. ì¥ë¬¸ ì„œì‹ ë„ìš°ë¯¸ â€” ë¨¸ë¦¬ê¸€/í‘œ/ì½”ë“œë¸”ë¡ ìë™ ìƒì„±ê¸°(í…œí”Œë¦¿)
#    - ë³´ê³ ì„œ/ë…¸íŠ¸ ì‘ì„±ì„ ë¹ ë¥´ê²Œ ë•ëŠ” í…œí”Œë¦¿ ì¸ì„œí„°
# ================================================================
_MD_TEMPLATES = {
"ë³´ê³ ì„œ-ê¸°ë³¸": """# ì œëª©(yyyy-mm-dd)
## 1. ë°°ê²½
## 2. ëª©í‘œ
## 3. ë°©ë²•
- ë°ì´í„°:
- ì ˆì°¨:
## 4. ê²°ê³¼
## 5. ë…¼ì˜/í•œê³„
## 6. ë‹¤ìŒ ì•¡ì…˜
""",
"í‘œ-ê·¼ê±°ì •ë¦¬": """| êµ¬ë¶„ | ì¶œì²˜ | ì‹ ë¢° | ë©”ëª¨ |
|---|---|---:|---|
| ì¦ê±°1 | https:// | 0.95 | |
| ì¦ê±°2 | https:// | 0.90 | |
""",
"ì½”ë“œ-ì˜ì‚¬ê²°ì •í‘œ": """```pseudo
IF ce_coverage >= 0.97 AND reproducibility >= 0.93 THEN
    VERDICT = PASS
ELSE
    VERDICT = REPAIR
END
```"""
}

with st.expander("[78] ì¥ë¬¸ ì„œì‹ ë„ìš°ë¯¸", expanded=False):
    pick = st.selectbox("í…œí”Œë¦¿", list(_MD_TEMPLATES.keys()), key="md_pick")
    st.code(_MD_TEMPLATES[pick], language="markdown")
    if st.button("ì‘ë‹µìœ¼ë¡œ ë¶™ì—¬ë„£ê¸°", key="md_into"):
        txt = _MD_TEMPLATES[pick]
        st.session_state.setdefault("HISTORY", []).append({"q":"[í…œí”Œë¦¿ ì‚½ì…]", "a":txt, "ts":int(time.time()), "lvl":0})
        st.success("íˆìŠ¤í† ë¦¬ì— í…œí”Œë¦¿ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ================================================================
# 79. ì‹¤í—˜ í”„ë¡œí† ì½œ í…œí”Œë¦¿ â€” ê°€ì„¤0(REAL) ì²´í¬ë¦¬ìŠ¤íŠ¸ + ì ˆì°¨/í‰ê°€ì§€í‘œ
#    - ì¶œë ¥: JSON(í”„ë¡œí† ì½œ) ìƒì„± â†’ specs/ ì €ì¥
# ================================================================
def make_protocol(title: str, steps: list, metrics: dict, guards: dict) -> dict:
    return {
        "title": title, "created_at": int(time.time()),
        "guards": guards,  # {"hypothesis":"0", "real_guard":"soft|hard", ...}
        "steps": steps,    # [{"name":"", "detail":"", "expect":""}, ...]
        "metrics": metrics # {"ce_coverage":0.97, "reproducibility":0.93, ...}
    }

PROTO_DIR = os.path.join(LOG_DIR, "protocols")
os.makedirs(PROTO_DIR, exist_ok=True)

def save_protocol(proto: dict) -> str:
    fn = os.path.join(PROTO_DIR, f"proto_{proto['created_at']}_{_sha(json.dumps(proto,ensure_ascii=False).encode())[:8]}.json")
    json.dump(proto, open(fn,"w",encoding="utf-8"), ensure_ascii=False, indent=2)
    return fn

with st.expander("[79] ì‹¤í—˜ í”„ë¡œí† ì½œ í…œí”Œë¦¿", expanded=False):
    ttl = st.text_input("í”„ë¡œí† ì½œ ì œëª©", value="REAL/L30 ì´ˆê²€ì¦ ë£¨í”„", key="pp_title")
    stp_default = [
        {"name":"ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°","detail":"ë§í¬/ìºì‹œ ë°ì´í„° í™•ë³´","expect":"ì˜¤ë¥˜0, ê²°ì¸¡<1%"},
        {"name":"ë‹¨ìœ„/ì°¨ì› ê²€ì¦","detail":"UNITS ì²´í¬","expect":"ìœ„ë°˜ìœ¨â‰¤0.0001"},
        {"name":"ì¦ê±° ê·¸ë˜í”„ êµ¬ì¶•","detail":"CE-Graph ìƒì„±","expect":"ì»¤ë²„ë¦¬ì§€â‰¥0.5"},
        {"name":"ê²Œì´íŠ¸ íŒì •","detail":"ë©”íŠ¸ë¦­ ê³„ì‚°/íŒì •","expect":"PASS ë˜ëŠ” REPAIR ì‚¬ìœ  ê¸°ë¡"}
    ]
    met_default = {"ce_coverage":0.97,"citation_coverage":0.90,"reproducibility":0.93,"subset_robustness":0.99}
    grd_default = {"hypothesis":"0","real_guard":st.session_state.get("REAL_GUARD_MODE","soft")}
    if st.button("í”„ë¡œí† ì½œ ìƒì„±/ì €ì¥", key="pp_make"):
        proto = make_protocol(ttl, stp_default, met_default, grd_default)
        path  = save_protocol(proto)
        st.success(f"ì €ì¥ë¨: {path}")
        st.json(proto)

# ================================================================
# 80. ë¯¸ë‹ˆ ë²¤ì¹˜ë§ˆí¬ ëŒ€ì‹œë³´ë“œ â€” ì¼€ì´ìŠ¤ ì„±ëŠ¥ ìš”ì•½(ê¸¸ì´/í—¬ìŠ¤/í†µê³¼ìœ¨)
#    - HISTORY/í—¬ìŠ¤/í…ŒìŠ¤íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤ ê²°ê³¼ë¥¼ ê°„ë‹¨ ì§‘ê³„
# ================================================================
if "BENCH_LOG" not in st.session_state:
    st.session_state["BENCH_LOG"] = []  # [{ts, name, pass_rate, avg_len}]

def bench_log_add(name: str, pass_rate: float, avg_len: float):
    st.session_state["BENCH_LOG"].append({"ts": int(time.time()), "name": name, "pass_rate": round(pass_rate,2), "avg_len": round(avg_len,1)})

with st.expander("[80] ë¯¸ë‹ˆ ë²¤ì¹˜ë§ˆí¬ ëŒ€ì‹œë³´ë“œ", expanded=False):
    # ìƒ˜í”Œ: 52ë²ˆ ë§¤íŠ¸ë¦­ìŠ¤ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë„˜ê²¨ ìˆ˜ë™ ê¸°ë¡í•˜ëŠ” íë¦„
    bench_name = st.text_input("ë²¤ì¹˜ ì´ë¦„", value="L30 ìƒ˜í”Œ ë§¤íŠ¸ë¦­ìŠ¤", key="bn_name")
    pr = st.number_input("í†µê³¼ìœ¨(0~1)", 0.0, 1.0, 0.88, 0.01, key="bn_pr")
    if st.button("ê¸°ë¡ ì¶”ê°€", key="bn_add"):
        hist = st.session_state.get("HISTORY", [])
        avg_len = (sum(len(str(h.get("a",""))) for h in hist)/len(hist)) if hist else 0
        bench_log_add(bench_name, pr, avg_len)
        st.success("ê¸°ë¡ë¨")
    st.markdown("**ìµœê·¼ ë²¤ì¹˜ ê¸°ë¡**")
    st.json(st.session_state["BENCH_LOG"][-10:])
    
    # ================================================================
# 81. ì¦ê±° ê·¸ë˜í”„ í…ìŠ¤íŠ¸ ì‹œê°í™” â€” ë…¸ë“œ/ì—£ì§€ ìš”ì•½(ASCII)
#    - ê·¸ë˜í”„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ ê°€ë³ê²Œ êµ¬ì¡°ë¥¼ í™•ì¸
# ================================================================
def ce_text_view(ce: dict, k_nodes: int = 40) -> str:
    if not ce: return "(CE-Graph ì—†ìŒ)"
    nodes = ce.get("nodes", [])[:k_nodes]
    edges = ce.get("edges", [])
    lines = []
    lines.append(f"# CE-Graph í”„ë¦¬ë·°  (nodes={len(ce.get('nodes',[]))}, edges={len(edges)})")
    # í´ë ˆì„
    claims = [n for n in nodes if n.get("kind")=="claim"]
    for c in claims:
        txt = (c.get("payload",{}).get("text","") or "")[:180]
        lines.append(f"CLAIM {c['id']}: {txt}")
    # ì—ë¹„ë˜ìŠ¤
    evs = [n for n in nodes if n.get("kind")=="evidence"]
    for i, e in enumerate(evs, 1):
        p = e.get("payload",{})
        src = (p.get("source","") or "")[:120]
        sc  = p.get("score", None)
        lines.append(f"  EV[{i:02d}] {e['id']}  score={sc}  src={src}")
    # ì—£ì§€
    show_edges = edges[: min(len(edges), k_nodes*2)]
    for ed in show_edges:
        lines.append(f"    â””â”€ {ed.get('src','?')}  -[{ed.get('rel','')}]->  {ed.get('dst','?')}")
    digest = ce.get("digest","")
    if digest: lines.append(f"(digest={digest})")
    if len(nodes) < len(ce.get("nodes",[])):
        lines.append(f"... (ë…¸ë“œ {len(ce.get('nodes',[]))-len(nodes)}ê°œ ìƒëµ)")
    return "\n".join(lines)

with st.expander("[81] ì¦ê±° ê·¸ë˜í”„ í…ìŠ¤íŠ¸ ë·°", expanded=False):
    st.code(ce_text_view(st.session_state.get("CE_GRAPH")), language="text")

# ================================================================
# 82. ì—­ì¸ê³¼ í”Œë˜ë„ˆ + ì ìˆ˜í‘œ â€” ëª©í‘œâ†’ì›ì¸ ê°€ì„¤ í›„ë³´(ì¦ê±°ì—°ê³„ ìŠ¤ì½”ì–´)
#    - ë¼ì´íŠ¸ ìŠ¤ì½”ì–´: evidence ì—°ê²° ìˆ˜/í‰ê·  score/ë§í¬ ì»¤ë²„ë¦¬ì§€ ê¸°ë°˜
# ================================================================
def invert_causality_plan(goal: str, ce: dict, topk: int = 3) -> dict:
    # ë§¤ìš° ë¼ì´íŠ¸: evidence ì œëª©/ì¶œì²˜ í† í°ì„ í›„ë³´ í‚¤ì›Œë“œë¡œ ì‚¼ì•„ ì›ì¸ ê°€ì„¤ ì œì‹œ
    ev = [n for n in (ce or {}).get("nodes",[]) if n.get("kind")=="evidence"]
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    keys = []
    for n in ev:
        src = (n.get("payload",{}).get("source","") or "")
        for token in re.split(r"[/\-\._:#\?\&=\s]+", src):
            if 3 <= len(token) <= 18 and token.isascii():
                keys.append(token.lower())
    # ë‹¨ìˆœ ê°€ì¤‘ ë¹ˆë„
    from collections import Counter
    cand = [k for k in keys if not any(t in k for t in ["http","www","html","pdf","img","css","js"])]
    freq = Counter(cand).most_common(30)
    # í›„ë³´ ê°€ì„¤ êµ¬ì„±
    hypotheses=[]
    for w,cnt in freq[:max(1, topk*3)]:
        linked = [n for n in ev if w in ((n.get("payload",{}).get("source","") or "").lower())]
        if not linked: continue
        avg_score = sum((n.get("payload",{}).get("score",0.7) or 0) for n in linked)/len(linked)
        hypotheses.append({
            "hyp": f"ì›ì¸/í•µì‹¬ ìš”ì†Œ: {w}",
            "evidence_count": len(linked),
            "avg_evidence_score": round(avg_score,3)
        })
    # ì •ë ¬: evidence_count, avg_score
    hypotheses.sort(key=lambda x:(-x["evidence_count"], -x["avg_evidence_score"]))
    # ì»¤ë²„ë¦¬ì§€
    cov = verify_ce_links(ce) if ce else {"coverage":0, "verdict":"N/A"}
    return {
        "goal": goal,
        "coverage": cov.get("coverage"),
        "verdict":  cov.get("verdict"),
        "hypotheses": hypotheses[:topk],
        "note": "ë¼ì´íŠ¸ íœ´ë¦¬ìŠ¤í‹±(ì •ì‹ ì¶”ë¡  ì•„ë‹˜). ì •ì‹íŒì€ SMT/ProofKernel ì—°ë™ í›„ êµì²´."
    }

with st.expander("[82] ì—­ì¸ê³¼ í”Œë˜ë„ˆ + ìŠ¤ì½”ì–´", expanded=False):
    goal = st.text_input("ëª©í‘œ(Goal)", value="ìš°ì£¼ì •ë³´ì¥ ì—°ê²°ì˜ ì‹ ë¢°ì„± í–¥ìƒ", key="ic_goal")
    k    = st.slider("ê°€ì„¤ ìˆ˜", 1, 10, 3, key="ic_k")
    if st.button("ê³„íš/ì ìˆ˜ ì‚°ì¶œ", key="ic_run"):
        st.json(invert_causality_plan(goal, st.session_state.get("CE_GRAPH"), k))

# ================================================================
# 83. LTM ê²€ìƒ‰ ë·° â€” ì¥ê¸°ê¸°ì–µ JSON(.gz) í‚¤ì›Œë“œ ê²€ìƒ‰/ë¯¸ë¦¬ë³´ê¸°
#    - ì˜¤í”„ë¼ì¸ íŒŒì¼ ìŠ¤ìº”, ê°„ë‹¨ í¬í•¨ê²€ìƒ‰(ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
# ================================================================
def ltm_search(term: str, limit: int = 30) -> list:
    res=[]
    if not os.path.isdir(LTM_DIR): return res
    patt = term.lower()
    files = sorted(glob.glob(os.path.join(LTM_DIR, "*.json*")), reverse=True)
    for p in files:
        if len(res)>=limit: break
        try:
            if p.endswith(".gz"):
                import gzip
                with gzip.open(p, "rt", encoding="utf-8", errors="ignore") as f:
                    txt = f.read()
            else:
                txt = open(p,"r",encoding="utf-8",errors="ignore").read()
            if patt in txt.lower():
                res.append({"file": os.path.basename(p), "chars": len(txt), "preview": txt[:400]})
        except Exception:
            continue
    return res

with st.expander("[83] LTM ê²€ìƒ‰", expanded=False):
    q = st.text_input("ê²€ìƒ‰ì–´", value="ì¦ê±°", key="ltm_q")
    if st.button("ê²€ìƒ‰", key="ltm_q_go"):
        hits = ltm_search(q, limit=20)
        st.write(f"ê²°ê³¼ {len(hits)}ê°œ")
        st.json(hits)

# ================================================================
# 84. ì„¸ì…˜ ìŠ¤ëƒ…ìƒ·/ë³µì› â€” session_state í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì €ì¥Â·ë¶ˆëŸ¬ì˜¤ê¸°
#    - HISTORY/CE_GRAPH/PRESETS_USER/TASKS/HC_MIN/REAL_GUARD_MODE ë“±
# ================================================================
SNAP_DIR = os.path.join(LOG_DIR, "snapshots")
os.makedirs(SNAP_DIR, exist_ok=True)

_SNAP_KEYS = [
    "HISTORY","CE_GRAPH","PRESETS_USER","TASKS",
    "HC_MIN","REAL_GUARD_MODE","CTX_STACK","BENCH_LOG",
]

def snapshot_save(name: str) -> str:
    data = {k: st.session_state.get(k) for k in _S_NAP_KEYS if k in st.session_state}
    ts = int(time.time())
    fn = os.path.join(SNAP_DIR, f"{ts}_{re.sub(r'[^0-9A-Za-z_-]+','_',name)}.json")
    json.dump(data, open(fn,"w",encoding="utf-8"), ensure_ascii=False, indent=2)
    return fn

def snapshot_load(path: str) -> dict:
    d = json.load(open(path,"r",encoding="utf-8"))
    for k,v in d.items():
        st.session_state[k] = v
    return {"restored_keys": list(d.keys()), "file": os.path.basename(path)}

with st.expander("[84] ì„¸ì…˜ ìŠ¤ëƒ…ìƒ·/ë³µì›", expanded=False):
    nm = st.text_input("ìŠ¤ëƒ…ìƒ· ì´ë¦„", value="checkpoint", key="sn_name")
    if st.button("ì €ì¥", key="sn_save"):
        try:
            p = snapshot_save(nm); st.success(f"ì €ì¥ë¨: {p}")
        except Exception as e:
            st.error(f"ì‹¤íŒ¨: {e}")
    up = st.file_uploader("ìŠ¤ëƒ…ìƒ· JSON ì—…ë¡œë“œ(ë³µì›)", type=["json"], key="sn_upl")
    if st.button("ë³µì›", key="sn_load") and up is not None:
        import io
        try:
            d = json.load(io.StringIO(up.getvalue().decode("utf-8","ignore")))
            for k,v in d.items(): st.session_state[k]=v
            st.success(f"ë³µì› ì™„ë£Œ: {list(d.keys())}")
        except Exception as e:
            st.error(f"ë³µì› ì‹¤íŒ¨: {e}")

# ================================================================
# 85. í€µëŸ°(ì¼ê´„) â€” ëª©í‘œ ì…ë ¥â†’ìƒì„±â†’í—¬ìŠ¤ì²´í¬â†’REPAIR 1íšŒâ†’CE/í•˜ì´ë¼ì´íŠ¸ ì¶œë ¥
#    - ì›í´ë¦­ íŒŒì´í”„ë¼ì¸(ëª¨ë°”ì¼/ì›¹ ì•ˆì „), ì¤‘ê°„ ê²°ê³¼ ë¡œê·¸
# ================================================================
def quickrun(goal: str, lvl: int = 8) -> dict:
    log = {}
    # 1) ìƒì„±
    ans = generate_with_memory(goal, level=lvl)
    st.session_state.setdefault("HISTORY", []).append({"q": goal, "a": ans, "ts": int(time.time()), "lvl": lvl})
    log["gen_len"] = len(str(ans))
    # 2) í—¬ìŠ¤
    h = health_check()
    log["health"] = h.get("verdicts",{})
    # 3) ë¶€ì¡± ì‹œ ê°„ë‹¨ REPAIR
    if any(v=="LOW" for v in log["health"].values() if v in ("OK","LOW")):
        rr = repair_once(query=goal, k=3)
        log["repair"] = rr
    # 4) CE í”„ë¦¬ë·° + í•˜ì´ë¼ì´íŠ¸
    ce = st.session_state.get("CE_GRAPH")
    log["ce_snippets"] = ce_preview_snippets(ce, k=5)
    log["highlight"] = highlight_keywords(str(ans))[:800]
    return log

with st.expander("[85] í€µëŸ°(ìƒì„±â†’í—¬ìŠ¤â†’REPAIRâ†’í”„ë¦¬ë·°)", expanded=False):
    qr_goal = st.text_area("ëª©í‘œ/ì§ˆë¬¸", value="ìš°ì£¼ì •ë³´ì¥-ì—°ë™ ì„¤ê³„ í•µì‹¬ ìš”ì•½ê³¼ ë¦¬ìŠ¤í¬/ì™„í™”ì±… ì œì‹œ", height=90, key="qr_goal")
    qr_lvl  = st.slider("ë ˆë²¨", 1, 999, 8, key="qr_lvl")
    if st.button("ì›í´ë¦­ ì‹¤í–‰", key="qr_go"):
        st.json(quickrun(qr_goal, qr_lvl))
        
        # ================================================================
# 86. ë¼ì´íŠ¸ ì²´ì¸í•´ì‹œ ë·°ì–´ â€” ìµœê·¼ ì‚°ì¶œë¬¼ í•´ì‹œ/ë¬´ê²°ì„± ì ê²€
#    - HISTORY/CE_GRAPH/LTM íŒŒì¼ë“¤ì˜ SHA-256 ìš”ì•½ì„ í•œëˆˆì—
# ================================================================
def _sha256_hex(s: bytes) -> str:
    return hashlib.sha256(s).hexdigest()

def chainhash_view() -> dict:
    out = {}
    # ìµœê·¼ ì‘ë‹µ 3ê°œ
    hist = st.session_state.get("HISTORY", [])[-3:]
    out["answers"] = [
        {"ts": h.get("ts"), "len": len(str(h.get("a",""))), "sha12": _sha256_hex(str(h.get("a","")).encode())[:12]}
        for h in hist
    ]
    # CE ê·¸ë˜í”„
    ce = st.session_state.get("CE_GRAPH")
    if ce:
        ce_bytes = json.dumps(ce, ensure_ascii=False, sort_keys=True).encode("utf-8","ignore")
        out["ce_graph"] = {"nodes": len(ce.get("nodes",[])), "edges": len(ce.get("edges",[])),
                           "sha12": _sha256_hex(ce_bytes)[:12]}
    # LTM ìµœì‹  3ê°œ íŒŒì¼
    ltm_files = sorted(glob.glob(os.path.join(LTM_DIR,"*.json*")), reverse=True)[:3]
    out["ltm"] = []
    for p in ltm_files:
        try:
            b = open(p,"rb").read()
            out["ltm"].append({"file": os.path.basename(p), "size": len(b), "sha12": _sha256_hex(b)[:12]})
        except Exception:
            pass
    return out

with st.expander("[86] ë¼ì´íŠ¸ ì²´ì¸í•´ì‹œ ë·°ì–´", expanded=False):
    st.json(chainhash_view())

# ================================================================
# 87. ì¦ê±° ê²¹ì¹¨ ë¶„ì„ â€” ì¤‘ë³µ/ìœ ì‚¬ ë§í¬ íƒì§€(ë„ë©”ì¸/ê²½ë¡œ ìœ ì‚¬ë„)
#    - ê°„ë‹¨ ë„ë©”ì¸ ë§¤ì¹­ + ê²½ë¡œ í† í° Jaccardë¡œ ìœ ì‚¬ë„ í‰ê°€
# ================================================================
from urllib.parse import urlparse

def _url_tokens(u: str) -> tuple:
    try:
        p = urlparse(u)
        dom = p.netloc.lower()
        toks = [t for t in re.split(r"[\/\-\._\?\&=#]+", p.path.lower()) if t and t.isascii()]
        return dom, set(toks)
    except Exception:
        return "", set()

def evidence_overlap_report(ce: dict, sim_th: float = 0.5) -> dict:
    ev = [n for n in (ce or {}).get("nodes",[]) if n.get("kind")=="evidence"]
    rows = []
    for i in range(len(ev)):
        ui = (ev[i].get("payload",{}) or {}).get("source","")
        di, ti = _url_tokens(ui)
        for j in range(i+1, len(ev)):
            uj = (ev[j].get("payload",{}) or {}).get("source","")
            dj, tj = _url_tokens(uj)
            if not di or not dj: continue
            dom_same = (di==dj)
            inter = len(ti & tj); union = len(ti | tj) if (ti|tj) else 1
            jac = inter/union
            if dom_same and jac >= sim_th:
                rows.append({
                    "a": ev[i].get("id"), "b": ev[j].get("id"),
                    "domain": di, "jaccard": round(jac,3),
                    "src_a": ui, "src_b": uj
                })
    return {"pairs": rows, "count": len(rows)}

with st.expander("[87] ì¦ê±° ê²¹ì¹¨ ë¶„ì„(ì¤‘ë³µ/ìœ ì‚¬)", expanded=False):
    ce = st.session_state.get("CE_GRAPH")
    if ce:
        th = st.slider("ìœ ì‚¬ë„ ì„ê³„(Jaccard)", 0.1, 1.0, 0.5, 0.05, key="ov_th")
        st.json(evidence_overlap_report(ce, th))
    else:
        st.info("CE evidenceê°€ ì—†ìŠµë‹ˆë‹¤. [63]ìœ¼ë¡œ ë³´ê°•í•˜ì„¸ìš”.")

# ================================================================
# 88. ì¥ë¬¸ ëª©ì°¨ ìë™ ìƒì„±ê¸°(L50+) â€” ì„¹ì…˜/í•˜ìœ„ì„¹ì…˜ ìŠ¤ì¼ˆë ˆí†¤
#    - ì£¼ì œ ì…ë ¥â†’ëª©ì°¨(ë²ˆí˜¸/ì œëª©/ì„¤ëª…) ìƒì„± â†’ HISTORYì— ì‚½ì…
# ================================================================
def make_longform_toc(topic: str, depth: int = 2, sections: int = 8) -> str:
    lines = [f"# {topic} â€” ìë™ ëª©ì°¨", ""]
    for i in range(1, sections+1):
        lines.append(f"{i}. ì„¹ì…˜ {i}: {topic}ì˜ í•µì‹¬ ì¶• #{i}")
        if depth >= 2:
            for j in range(1, 5):
                lines.append(f"   {i}.{j} í•˜ìœ„ {j}: ê·¼ê±°/ì ˆì°¨/ë¦¬ìŠ¤í¬/ì™„í™”")
        if depth >= 3:
            for j in range(1, 3):
                lines.append(f"      {i}.{j}.1 ì„¸ë¶€: ì§€í‘œ/ê²€ì¦/ë°ì´í„°")
    return "\n".join(lines)

with st.expander("[88] ì¥ë¬¸ ëª©ì°¨ ìë™ ìƒì„±ê¸°(L50+)", expanded=False):
    tp = st.text_input("ì£¼ì œ", value="ìš°ì£¼ì •ë³´ì¥ ì—°ë™ ë° ì´ˆê²€ì¦ ì•„í‚¤í…ì²˜", key="toc_topic")
    dp = st.slider("ê¹Šì´", 1, 3, 2, key="toc_depth")
    sc = st.slider("ì„¹ì…˜ ìˆ˜", 3, 20, 8, key="toc_secs")
    if st.button("ëª©ì°¨ ìƒì„±â†’íˆìŠ¤í† ë¦¬ ì‚½ì…", key="toc_make"):
        toc = make_longform_toc(tp, dp, sc)
        st.session_state.setdefault("HISTORY", []).append({
            "q":"[ìë™ ëª©ì°¨]", "a": toc, "ts": int(time.time()), "lvl": 50
        })
        st.success("íˆìŠ¤í† ë¦¬ì— ëª©ì°¨ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.code(toc, language="markdown")

# ================================================================
# 89. ê°„ë‹¨ í”Œë¡œìš°ì°¨íŠ¸ ë§ˆí¬ë‹¤ìš´ â€” ë‹¨ê³„/ë¶„ê¸° í‘œê¸°(í…ìŠ¤íŠ¸ ê¸°ë°˜)
#    - Mermaidê¹Œì§€ëŠ” ì•„ë‹ˆê³ , ASCII ìŠ¤íƒ€ì¼ íë¦„ë„ ë¬¸ìì—´ ìƒì„±
# ================================================================
def flowchart_ascii(steps: list, branches: dict=None) -> str:
    branches = branches or {}
    out = []
    for i, s in enumerate(steps, 1):
        out.append(f"[{i}] {s}")
        if i < len(steps): out.append("  â”‚")
        b = branches.get(i, [])
        for br in b:
            out.append(f"  â”œâ”€â–¶ {br}")
    return "\n".join(out)

with st.expander("[89] í”Œë¡œìš°ì°¨íŠ¸(ASCII) ìƒì„±", expanded=False):
    default_steps = ["ì…ë ¥ íŒŒì‹±", "CE-ê·¸ë˜í”„ êµ¬ì¶•", "ê²Œì´íŠ¸ í—¬ìŠ¤ì²´í¬", "REPAIR ë£¨í”„", "ê²°ê³¼ ì‚°ì¶œ/ì²´ì¸í•´ì‹œ"]
    txt = st.text_area("ë‹¨ê³„(ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬)", value="\n".join(default_steps), height=120, key="fc_steps")
    if st.button("í”Œë¡œìš°ì°¨íŠ¸ ìƒì„±", key="fc_go"):
        steps = [x.strip() for x in txt.splitlines() if x.strip()]
        chart = flowchart_ascii(steps, branches={3:["ì„ê³„ ìƒí–¥","ì„ê³„ í•˜í–¥"]})
        st.code(chart, language="text")

# ================================================================
# 90. ì„ê³„ì¹˜ íˆìŠ¤í† ë¦¬ íŠ¸ë˜ì»¤ â€” HC_MIN/ê²Œì´íŠ¸ ì§€í‘œ íƒ€ì„ë¼ì¸
#    - ì„¸ì…˜ ë‚´ ë³€ê²½ ëˆ„ì  ê¸°ë¡ â†’ JSON ë¡œê¹…
# ================================================================
THLOG_PATH = os.path.join(LOG_DIR, "threshold_history.jsonl")

def thlog_append(event: dict):
    event = dict(event)
    event["ts"] = int(time.time())
    with open(THLOG_PATH, "a", encoding="utf-8") as f:
        f.write(json.dumps(event, ensure_ascii=False) + "\n")

# í›…: 66ì˜ gate_autotune_update/74ì˜ ì„¤ì • ì €ì¥ í›„ ê¸°ë¡
_prev_autotune = gate_autotune_update
def gate_autotune_update_logged(mode: str = "auto"):
    res = _prev_autotune(mode)
    try: thlog_append({"type":"autotune", "mode": mode, "HC_MIN": res.get("HC_MIN")})
    except Exception: pass
    return res
gate_autotune_update = gate_autotune_update_logged

def thlog_tail(n: int = 30) -> list:
    try:
        lines = open(THLOG_PATH,"r",encoding="utf-8").read().strip().splitlines()
        return [json.loads(x) for x in lines[-n:]]
    except Exception:
        return []

with st.expander("[90] ì„ê³„ì¹˜ íˆìŠ¤í† ë¦¬ íŠ¸ë˜ì»¤", expanded=False):
    st.json(thlog_tail(30))
    
    # ==== [91] UI Â· ë¦¬í¬íŠ¸/ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° (ìˆ˜ì •íŒ: DuplicateElementKey ë°©ì§€) ====
# ìœ„ì¹˜: íŒŒì¼ ë§¨ ì•„ë˜ì— í†µì§¸ë¡œ ë¶™ì—¬ë„£ê¸° (ê¸°ì¡´ 91ë²ˆì´ ìˆìœ¼ë©´ êµì²´)

import uuid, re
import streamlit as st

# íšŒìƒ‰ ì•ˆë‚´: ëª¨ë“ˆ 91 â€” ë¦¬í¬íŠ¸ ê´€ë ¨ UIì˜ key ì¶©ëŒ ë°©ì§€ìš© ìœ í‹¸
def _ukey(tag: str) -> str:
    """ì£¼ì–´ì§„ íƒœê·¸ë¡œë¶€í„° í™”ë©´ë§ˆë‹¤ ìœ ì¼í•œ keyë¥¼ ë§Œë“¤ì–´ì¤€ë‹¤."""
    base = re.sub(r'[^a-zA-Z0-9_]+', '_', str(tag).strip())[:24] or "k"
    return f"{base}_{uuid.uuid4().hex[:8]}"

def _safe_call(name, *args, **kwargs):
    """í•´ë‹¹ ì´ë¦„ì˜ í•¨ìˆ˜ê°€ ì¡´ì¬í•˜ë©´ í˜¸ì¶œ, ì—†ìœ¼ë©´ ì¡°ìš©íˆ í†µê³¼."""
    fn = globals().get(name)
    if callable(fn):
        return fn(*args, **kwargs)
    return None

st.divider()
st.markdown("### ğŸ§© ëª¨ë“ˆ 91 Â· ë¦¬í¬íŠ¸/ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° (ì•ˆì •íŒ)")

# í™”ë©´ì— ê°™ì€ ì»´í¬ë„ŒíŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ë°°ì¹˜í•´ë„ í•­ìƒ ì„œë¡œ ë‹¤ë¥¸ keyê°€ ë˜ë„ë¡ _ukey() ì‚¬ìš©
c1, c2, c3 = st.columns(3)

with c1:
    if st.button("ë¦¬í¬íŠ¸ ìƒì„±/ì €ì¥", key=_ukey("report_save_btn")):
        # ì•„ë˜ ë‘ ì¤„ì€ ê¸°ì¡´ì— ì“°ë˜ ë‚´ë¶€ í•¨ìˆ˜ëª…ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ í˜¸ì¶œí•¨
        content = _safe_call("generate_validation_report") or "ë¦¬í¬íŠ¸ ë³¸ë¬¸(ìƒ˜í”Œ)"
        _safe_call("save_report_to_store", content)  # ì—†ìœ¼ë©´ ë¬´ì‹œ
        st.success("ë¦¬í¬íŠ¸ë¥¼ ì €ì¥í–ˆì–´ìš”.")

with c2:
    if st.button("ë¦¬í¬íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°", key=_ukey("report_load_btn")):
        loaded = _safe_call("load_last_report")
        if loaded:
            st.code(loaded)
        else:
            st.info("ë¶ˆëŸ¬ì˜¬ ë¦¬í¬íŠ¸ê°€ ì•„ì§ ì—†ì–´ìš”.")

with c3:
    if st.button("ë¦¬í¬íŠ¸ ê³µìœ  ë§í¬", key=_ukey("report_share_btn")):
        link = _safe_call("make_share_link") or "(ê³µìœ  ë§í¬ ê¸°ëŠ¥ì€ ì•„ì§ ë¯¸êµ¬í˜„)"
        st.write(link)

# (ì„ íƒ) ì¶”ê°€ ì»¨íŠ¸ë¡¤: ìŠ¬ë¼ì´ë”/ì²´í¬ë°•ìŠ¤ë„ ìœ ì¼ keyë¡œ ìƒì„±
with st.expander("ì¶”ê°€ ì˜µì…˜", expanded=False):
    lvl = st.slider("í‘œì‹œ ë ˆë²¨", 1, 5, 3, key=_ukey("opt_level"))
    active = st.checkbox("ê³ ê¸‰ì˜µì…˜", value=False, key=_ukey("opt_adv"))
    st.caption(f"ë ˆë²¨={lvl}, ê³ ê¸‰ì˜µì…˜={'ON' if active else 'OFF'}")
# ==== [91] ë ====

# ================================
# 092. [íšŒìƒ‰] í‚¤/ì„¸ì…˜ ì¶©ëŒ ì œë¡œí™” ìœ í‹¸ (KeyFactory) + ìœ„ì ¯ ë˜í¼
# ëª©ì : Streamlit DuplicateElementKey ì—ëŸ¬ ì˜ˆë°©. ëª¨ë“  ìƒˆ ìœ„ì ¯ì— ê³ ìœ  key ìë™ ë¶€ì—¬.
# ================================
import streamlit as st
from typing import Dict, Optional

class _GEAKeyFactory:
    """ìœ„ì ¯ key ìë™ìƒì„±ê¸°: ê°™ì€ ê·¸ë£¹ëª… ë‚´ì—ì„œ 0001, 0002â€¦ ì¦ê°€"""
    def __init__(self):
        self.counts: Dict[str, int] = {}

    def k(self, name: str) -> str:
        n = self.counts.get(name, 0) + 1
        self.counts[name] = n
        return f"{name}__{n:04d}"

    def reset(self, prefix: Optional[str] = None) -> None:
        if prefix is None:
            self.counts.clear()
        else:
            self.counts = {k: v for k, v in self.counts.items() if not k.startswith(prefix)}

def _m092_get_factory() -> _GEAKeyFactory:
    if "_m092_kf" not in st.session_state:
        st.session_state["_m092_kf"] = _GEAKeyFactory()
    return st.session_state["_m092_kf"]

# ---- í¸ì˜ ë˜í¼ë“¤ (í•„ìš”í•  ë•Œë§Œ ì‚¬ìš©, í‰ì†Œì—” ëª…ì‹œì  key ì‚¬ìš©ë„ OK) ----
def m092_button(label: str, group: str = "m092_btn"):
    kf = _m092_get_factory()
    return st.button(label, key=kf.k(group))

def m092_text(label: str, group: str = "m092_txt", value: str = ""):
    kf = _m092_get_factory()
    return st.text_input(label, value=value, key=kf.k(group))

def m092_checkbox(label: str, group: str = "m092_chk", value: bool = False):
    kf = _m092_get_factory()
    return st.checkbox(label, value=value, key=kf.k(group))

def m092_select(label: str, options, group: str = "m092_sel"):
    kf = _m092_get_factory()
    return st.selectbox(label, options, key=kf.k(group))

def m092_self_check():
    kf = _m092_get_factory()
    keys = [kf.k("selfcheck") for _ in range(3)]
    ok = len(keys) == len(set(keys))
    return {"status": "PASS" if ok else "FAIL", "generated": keys, "groups": len(kf.counts)}

# ---- UI: í‚¤ ì¶©ëŒ ë°©ì§€ íˆ´í‚· (í…ŒìŠ¤íŠ¸ìš©) ----
with st.expander("ğŸ§° 092. í‚¤ íŒ©í† ë¦¬ / ìœ„ì ¯ ë˜í¼ (ì¤‘ë³µ key ì˜ˆë°©)", expanded=False):
    col1, col2 = st.columns(2)

    with col1:
        if m092_button("í…ŒìŠ¤íŠ¸ ë²„íŠ¼"):
            st.success("ë²„íŠ¼ í´ë¦­!")
        name = m092_text("í…ìŠ¤íŠ¸ ì…ë ¥")
        agree = m092_checkbox("ì²´í¬í•´ìš”")
        choice = m092_select("ì„ íƒ", ["A", "B", "C"])
        st.write({"name": name, "agree": agree, "choice": choice})

    with col2:
        if m092_button("íŒ©í† ë¦¬ ì´ˆê¸°í™”"):
            _m092_get_factory().reset()
            st.info("KeyFactory reset ì™„ë£Œ (ì´í›„ ìƒì„± í‚¤ë¶€í„° ì´ˆê¸°í™”).")
        st.code(m092_self_check())
        
        # ================================
# 093. [íšŒìƒ‰] ì´ë²¤íŠ¸ ë¡œê·¸ & ë¦¬í¬íŠ¸ ì €ì¥ê¸° (ì„¸ì…˜ ê¸°ë°˜, JSON/CSV ë‚´ë³´ë‚´ê¸°)
# ëª©ì : ê° ëª¨ë“ˆì—ì„œ ì†ì‰½ê²Œ log(level, module, message) ë‚¨ê¸°ê³ ,
#       í™”ë©´ì—ì„œ í•„í„°/ì¡°íšŒ í›„ JSON/CSVë¡œ ì €ì¥/ë‹¤ìš´ë¡œë“œ
# ì˜ì¡´: (ì„ íƒ) 092 KeyFactory. ì—†ì„ ê²½ìš° ìë™ shim ì‚¬ìš©.
# ================================
import streamlit as st
import json, csv, io
from datetime import datetime

# ---- 092 í‚¤ ë˜í¼ê°€ ì—†ë”ë¼ë„ ë¬¸ì œì—†ì´ ë™ì‘í•˜ë„ë¡ shim ì œê³µ ----
try:
    m092_button  # type: ignore
    m092_text    # type: ignore
    m092_select  # type: ignore
    m092_checkbox# type: ignore
except NameError:
    import uuid
    def _auto_key(prefix="k"): return f"{prefix}_{uuid.uuid4().hex[:8]}"
    def m092_button(label: str, group: str = "m093_btn"):
        return st.button(label, key=_auto_key(group))
    def m092_text(label: str, group: str = "m093_txt", value: str = ""):
        return st.text_input(label, value=value, key=_auto_key(group))
    def m092_select(label: str, options, group: str = "m093_sel"):
        return st.selectbox(label, options, key=_auto_key(group))
    def m092_checkbox(label: str, group: str = "m093_chk", value: bool = False):
        return st.checkbox(label, value=value, key=_auto_key(group))

# ---- ì„¸ì…˜ ì´ˆê¸°í™” ----
if "m093_logs" not in st.session_state:
    st.session_state["m093_logs"] = []  # [{ts, level, module, message, extra}...]

_M093_LEVELS = ["DEBUG", "INFO", "WARN", "ERROR"]

def m093_log(level: str, module: str, message: str, extra: dict | None = None):
    """ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ í˜¸ì¶œ: m093_log('INFO','ëª¨ë“ˆëª…','ë©”ì‹œì§€', {'k':'v'})"""
    level = (level or "INFO").upper()
    if level not in _M093_LEVELS: level = "INFO"
    st.session_state["m093_logs"].append({
        "ts": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "level": level,
        "module": module,
        "message": message,
        "extra": extra or {}
    })

def m093_get_logs():
    return st.session_state.get("m093_logs", [])

def m093_clear():
    st.session_state["m093_logs"] = []

def _m093_to_json_bytes(rows):
    buf = io.StringIO()
    json.dump(rows, buf, ensure_ascii=False, indent=2)
    return buf.getvalue().encode("utf-8")

def _m093_to_csv_bytes(rows):
    fieldnames = ["ts", "level", "module", "message", "extra"]
    buf = io.StringIO()
    writer = csv.DictWriter(buf, fieldnames=fieldnames)
    writer.writeheader()
    for r in rows:
        row = r.copy()
        row["extra"] = json.dumps(row.get("extra", {}), ensure_ascii=False)
        writer.writerow(row)
    return buf.getvalue().encode("utf-8")

# ---- UI íŒ¨ë„ ----
with st.expander("ğŸ§¾ 093. ì´ë²¤íŠ¸ ë¡œê·¸ & ë¦¬í¬íŠ¸ ì €ì¥ê¸°", expanded=False):
    colA, colB = st.columns([2,1])

    with colA:
        # ë¹ ë¥¸ ìˆ˜ë™ ê¸°ë¡
        mod = m092_text("ëª¨ë“ˆ ì´ë¦„", value="adhoc")
        msg = m092_text("ë©”ì‹œì§€", value="ê¸°ë¡ í…ŒìŠ¤íŠ¸")
        lev = m092_select("ë ˆë²¨", _M093_LEVELS)
        if m092_button("ë¡œê·¸ ë‚¨ê¸°ê¸°"):
            m093_log(lev, mod, msg)
            st.success("ë¡œê·¸ ê¸°ë¡ ì™„ë£Œ")

    with colB:
        # ê´€ë¦¬
        st.caption("ê´€ë¦¬")
        if m092_button("ë¡œê·¸ ì´ˆê¸°í™”"):
            m093_clear()
            st.info("ëª¨ë“  ë¡œê·¸ë¥¼ ë¹„ì›€")

    # í•„í„° & ë¯¸ë¦¬ë³´ê¸°
    fcol1, fcol2, fcol3 = st.columns([1,1,2])
    with fcol1:
        flv = m092_select("ë ˆë²¨ í•„í„°", ["ALL"] + _M093_LEVELS)
    with fcol2:
        fsz = m092_select("í‘œì‹œ ê°œìˆ˜", [10, 20, 50, 100])
    with fcol3:
        fmd = m092_text("ëª¨ë“ˆ í¬í•¨ í•„í„°(ë¶€ë¶„ì¼ì¹˜)", value="")

    rows = m093_get_logs()
    if flv != "ALL":
        rows = [r for r in rows if r["level"] == flv]
    if fmd:
        rows = [r for r in rows if fmd.lower() in (r["module"] or "").lower()]
    preview = rows[-int(fsz):] if rows else []

    st.write(f"ì´ {len(rows)}ê±´ / ë¯¸ë¦¬ë³´ê¸° {len(preview)}ê±´")
    st.dataframe(preview, use_container_width=True)

    # ë‚´ë³´ë‚´ê¸°
    jbytes = _m093_to_json_bytes(rows)
    cbytes = _m093_to_csv_bytes(rows)
    st.download_button("â¬‡ï¸ JSON ë‹¤ìš´ë¡œë“œ", data=jbytes, file_name="gea_logs.json", mime="application/json")
    st.download_button("â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ", data=cbytes, file_name="gea_logs.csv", mime="text/csv")

# ---- ìê¸°ì§„ë‹¨(ì„ íƒ) : ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ ë°”ë¡œ ì‚¬ìš© ì˜ˆì‹œ ----
def m093_self_test():
    m093_log("DEBUG", "m093", "self test start")
    m093_log("INFO",  "m093", "ok")
    return {"ok": True, "count": len(m093_get_logs())}
    
    # ================================
# 094-FULL. [íšŒìƒ‰] LTM í† í”½ ì¸ë±ìŠ¤ (ê²€ìƒ‰Â·ì €ì¥Â·ë¯¸ë¦¬ë³´ê¸° í™•ì¥íŒ)
# ëª©ì : gea_logs/ltm ë‚´ JSON/JSON.GZì—ì„œ í† í”½ í‚¤ì›Œë“œ ë§¤ì¹­ â†’ ê²½ëŸ‰ ì¸ë±ìŠ¤ ì €ì¥/ì¡°íšŒ
# ì¶œë ¥ ê²½ë¡œ: gea_logs/ltm_index/idx_<topic>.json
# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ + streamlitë§Œ ì‚¬ìš© (ì¶”ê°€ íŒ¨í‚¤ì§€ ë¶ˆí•„ìš”)
# ================================
import os, re, json, glob, time, hashlib
import streamlit as st

st.write("â€” 094-FULL ëª¨ë“ˆ ë¡œë“œë¨")  # ë„ë‹¬ ì²´í¬

# ---- ê³ ìœ  key ìœ í‹¸ (ì¤‘ë³µ ìœ„ì ¯ í‚¤ ë°©ì§€) ----
def _k(suffix: str) -> str:
    base = f"m094_{suffix}"
    return f"{base}_{hashlib.sha256(base.encode()).hexdigest()[:6]}"

# ---- ê¸°ë³¸ ê²½ë¡œ ì¤€ë¹„ ----
LOG_DIR = st.session_state.get("LOG_DIR", "gea_logs")
LTM_DIR = st.session_state.get("LTM_DIR", os.path.join(LOG_DIR, "ltm"))
LTM_IDX_DIR = os.path.join(LOG_DIR, "ltm_index")
os.makedirs(LTM_DIR, exist_ok=True)
os.makedirs(LTM_IDX_DIR, exist_ok=True)

def _safe_name(name: str) -> str:
    s = re.sub(r"[^0-9A-Za-zê°€-í£_.-]+", "_", (name or "topic"))
    return s[:64] if s else "topic"

def m094_scan_and_build(topic: str, topk_files: int = 200):
    """LTM í´ë” ìŠ¤ìº” â†’ topic í‚¤ì›Œë“œë¡œ í•„í„° â†’ ê°„ë‹¨ ë©”íƒ€ ì¸ë±ìŠ¤ ìƒì„±"""
    patt = (topic or "").strip().lower()
    files = sorted(glob.glob(os.path.join(LTM_DIR, "*.json*")))
    hits = []
    t0 = time.time()
    for p in files:
        try:
            if p.endswith(".gz"):
                import gzip
                with gzip.open(p, "rt", encoding="utf-8", errors="ignore") as f:
                    text = f.read()
            else:
                with open(p, "r", encoding="utf-8", errors="ignore") as f:
                    text = f.read()
            if (not patt) or (patt in text.lower()):
                # ê°€ë²¼ìš´ ë©”íƒ€ë§Œ ì €ì¥ (íŒŒì¼ëª…/ê¸¸ì´/ê°„ë‹¨ í•´ì‹œ)
                meta = {
                    "file": os.path.basename(p),
                    "size": len(text),
                    "hash12": hashlib.sha256(text[-1024:].encode("utf-8")).hexdigest()[:12] if text else ""
                }
                hits.append(meta)
        except Exception as e:
            # ê°œë³„ íŒŒì¼ ì—ëŸ¬ëŠ” ê±´ë„ˆëœ€ (ë¡œê·¸ë§Œ ë‚¨ê¸¸ ìˆ˜ë„ ìˆìŒ)
            continue
        if len(hits) >= topk_files:
            break
    idx = {
        "topic": topic,
        "matched": len(hits),
        "generated_at": int(time.time()),
        "elapsed_sec": round(time.time() - t0, 3),
        "items": hits
    }
    safe = _safe_name(topic)
    outp = os.path.join(LTM_IDX_DIR, f"idx_{safe}.json")
    with open(outp, "w", encoding="utf-8") as f:
        json.dump(idx, f, ensure_ascii=False, indent=2)
    return outp, idx

with st.expander("ğŸ“ 094-FULL. LTM í† í”½ ì¸ë±ìŠ¤(í™•ì¥íŒ)", expanded=False):
    col1, col2 = st.columns([2,1])
    with col1:
        topic = st.text_input("í† í”½(í‚¤ì›Œë“œ)", value="ì¦ê±°", key=_k("topic"))
        topk = st.number_input("ìµœëŒ€ íŒŒì¼ ìŠ¤ìº” ìˆ˜", min_value=10, max_value=2000, value=200, step=10, key=_k("topk"))
        if st.button("ì¸ë±ìŠ¤ ìƒì„±/ì €ì¥", key=_k("build")):
            path, idx = m094_scan_and_build(topic, int(topk))
            st.success(f"ì €ì¥ë¨: {path}")
            st.json(idx)
    with col2:
        idx_files = sorted(glob.glob(os.path.join(LTM_IDX_DIR, "idx_*.json")), reverse=True)[:20]
        if idx_files:
            pick = st.selectbox("ìµœê·¼ ì¸ë±ìŠ¤", [os.path.basename(p) for p in idx_files], key=_k("pick"))
            if st.button("ì—´ê¸°", key=_k("open")):
                st.json(json.load(open(os.path.join(LTM_IDX_DIR, pick), "r", encoding="utf-8")))
        else:
            st.info("ìƒì„±ëœ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ì¸ë±ìŠ¤ ìƒì„±/ì €ì¥'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

# ================================
# 095. [íšŒìƒ‰] ëŸ°íƒ€ì„/ìºì‹œ ì§„ë‹¨ íŒ¨ë„ (ë°˜ì˜/ìºì‹œ/ìœ„ì ¯ ìƒíƒœ)
# ================================
import sys, platform

st.write("â€” 095 ëª¨ë“ˆ ë¡œë“œë¨")  # ë„ë‹¬ ì²´í¬

def _fp(txt: str) -> str:
    return hashlib.sha256(txt.encode("utf-8")).hexdigest()[:12]

def _now_ms() -> int:
    return int(time.time() * 1000)

STARTED_AT = st.session_state.get("_m095_started_at_ms")
if not STARTED_AT:
    STARTED_AT = _now_ms()
    st.session_state["_m095_started_at_ms"] = STARTED_AT

with st.expander("ğŸ›¡ï¸ 095. ëŸ°íƒ€ì„/ìºì‹œ ì§„ë‹¨", expanded=False):
    colA, colB = st.columns(2)
    with colA:
        st.markdown("#### ì‹¤í–‰/í™˜ê²½")
        st.write("íŒŒì¼ ê²½ë¡œ:", __file__)
        st.write("Python:", sys.version.split()[0])
        st.write("Platform:", platform.platform())
        st.write("Streamlit:", st.__version__)
        st.write("ì‹œì‘ ì‹œê°(ms):", STARTED_AT)
        try:
            with open(__file__, "r", encoding="utf-8") as f:
                tail = f.read()[-200:]
            st.write("ì½”ë“œê¼¬ë¦¬ í•´ì‹œ:", _fp(tail))
        except Exception as e:
            st.warning(f"ì½”ë“œ ì½ê¸° ì‹¤íŒ¨: {e}")

    with colB:
        st.markdown("#### ìºì‹œ/ìœ„ì ¯ ìƒíƒœ")
        try:
            st.button("ì§„ë‹¨ ë²„íŠ¼", key=_k("probe"))
            st.write("ìœ„ì ¯ í‚¤ ì¶©ëŒ: ì—†ìŒ(ìƒ˜í”Œ)")
        except Exception as e:
            st.error(f"ìœ„ì ¯ í‚¤ ì¶©ëŒ ê°ì§€: {e}")

        if st.button("ì„¸ì…˜ ìºì‹œ ë¬´íš¨í™”(í† ê¸€)", key=_k("toggle_cache")):
            st.session_state["_m095_nonce"] = _fp(str(_now_ms()))
            st.success("ì„¸ì…˜ ìƒíƒœ ë³€ê²½ë¨ â†’ Rerun ì‹œ ê°•ì œ ì¬ê³„ì‚° ìœ ë„")

    st.markdown("---")
    st.markdown("#### ê¶Œì¥ ì ˆì°¨")
    st.write("1) GitHub ì»¤ë°‹ì´ mainìœ¼ë¡œ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸")
    st.write("2) ìœ„ 'ì½”ë“œê¼¬ë¦¬ í•´ì‹œ' ê°’ì´ ì»¤ë°‹ë§ˆë‹¤ ë‹¬ë¼ì§€ëŠ”ì§€ í™•ì¸")
    st.write("3) ì•± ë©”ë‰´ì—ì„œ **Restart & clear cache** ë˜ëŠ” **Manage app â†’ Reboot app**")
    st.write("4) í•„ìš” ì‹œ **Upload files**ë¡œ `streamlit_app.py` ì§ì ‘ ë®ì–´ì“°ê¸°")
    
    