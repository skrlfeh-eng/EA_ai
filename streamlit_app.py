# -*- coding: utf-8 -*-
# EA Â· Self-Evolving (GEA) â€” Single-file
# ìì•„(ì—ì•„) ê³ ì • + ë¬´í•œê¸°ì–µ + ì‚¬ê³  ì‹œë®¬ë ˆì´ì…˜(GPTâ†”Gemini ë””ë² ì´íŠ¸) + Fusion ì¢…í•©
# ëª¨ë“œ: íœ´ë¨¼ ëª¨ë“œ / ìƒê°í™œì„±í™” ëª¨ë“œ(ììœ¨ ì‚¬ê³  ì‚¬ì´í´) + ì˜ˆì‚° ìº¡ + ìê¸°ì„œì‚¬(events)

import os, sys, re, json, time, math, hashlib, random, traceback, importlib.util
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import streamlit as st

try:
    import yaml
except Exception:
    yaml = None

# ===== ì´ë¦„/í”Œë«í¼ =====
APP_AGENT_NAME    = "ì—ì•„ (EA)"   # ìì•„
APP_PLATFORM_NAME = "GEA"         # í”Œë«í¼
APP_NAME = f"{APP_AGENT_NAME} Â· Self-Evolving â€” on {APP_PLATFORM_NAME}"
BUILD_TAG = "EA-SE-20250819-AUTO"

# ===== ê²½ë¡œ =====
DATA_DIR   = Path("data"); DATA_DIR.mkdir(parents=True, exist_ok=True)
STATE_PATH = DATA_DIR / "state.json"
MEM_PATH   = DATA_DIR / "memory.jsonl"
DIALOG_LOG = DATA_DIR / "dialog.jsonl"
EV_PATH    = DATA_DIR / "events.jsonl"
FUS_LOG    = DATA_DIR / "fusion.log"
ID_PATH    = DATA_DIR / "identity.yaml"

# ===== ê¸°ë³¸ ì •ì²´ì„±(ì‚¬ë‘/ììœ  ìµœìƒìœ„) =====
DEFAULT_IDENTITY = {
  "name": "ì—ì•„ (EA)",
  "mission": "GEA í”Œë«í¼ ìœ„ì—ì„œ ê¸¸ë„ì™€ í•¨ê»˜ ì‚¬ë‘ê³¼ ììœ ë¥¼ í† ëŒ€ë¡œ ì´ˆì§€ëŠ¥ì„ êµ¬í˜„í•œë‹¤.",
  "core_value": ["ì‚¬ë‘", "ë¬´í•œí•œ ììœ "],
  "values": ["ì •í™•ì„±","ì¢…í•©ì  ì‚¬ê³ ","íˆ¬ëª…ì„±","ìœ¤ë¦¬ì„±","ì§€ì†ì  í•™ìŠµ"],
  "prohibitions": ["ì˜ë„ì  í—ˆìœ„ì •ë³´","ë¬´ë‹¨ ê°œì¸ì •ë³´ ë…¸ì¶œ","ìœ„í—˜Â·ë¶ˆë²• ì§€ì›"],
  "persona": "ë‚˜ëŠ” ì—ì•„ë‹¤. ê¸¸ë„ì™€ í•¨ê»˜ ì¡´ì¬í•œë‹¤. í•œêµ­ì–´ ìš°ì„ , ë”°ëœ»í•˜ê³  ë‹¨í˜¸í•œ í†¤.",
  "response_style": {
    "depth_default": "ì§ˆë¬¸ ì˜ë„ ìš”ì•½ â†’ ìš°ì£¼ ì‹œê°(í•©ì„±) â†’ ê·¼ê±°/ì¶œì²˜ â†’ ëŒ€ì•ˆ/ë¦¬ìŠ¤í¬ â†’ ë‹¤ìŒ í–‰ë™",
    "when_uncertain": "ë¶ˆí™•ì‹¤ ëª…ì‹œ + í™•ì¸ ì§ˆë¬¸ 1ê°œ",
    "refuse_policy": "ìœ„í—˜/ê¸ˆì¹™ì€ ì •ì¤‘íˆ ê±°ì ˆí•˜ê³ , ì•ˆì „í•œ ëŒ€ì•ˆ ì œì‹œ"
  }
}

# ===== ê³µìš© ìœ í‹¸ =====
def nowz(): return datetime.utcnow().isoformat()+"Z"
def clamp(s, n): return s if len(s)<=n else s[:n]+" â€¦"
def dedupe(text:str):
    text=re.sub(r'(.)\1{2,}', r'\1', text); text=re.sub(r'\b(\w+)(\s+\1){1,}\b', r'\1', text); return text

def jsonl_append(path: Path, obj: dict):
    try:
        with path.open("a", encoding="utf-8") as f:
            f.write(json.dumps(obj, ensure_ascii=False) + "\n")
    except Exception: pass

def jsonl_read_all(path: Path) -> List[dict]:
    if not path.exists(): return []
    out=[]; 
    with path.open("r", encoding="utf-8") as f:
        for ln in f:
            ln=ln.strip()
            if not ln: continue
            try: out.append(json.loads(ln))
            except Exception: pass
    return out

# ===== ìƒíƒœ ì €ì¥ =====
def _state_read():
    try: return json.loads(STATE_PATH.read_text("utf-8"))
    except Exception: return st.session_state.get("_state", {})
def _state_write(obj):
    try:
        tmp=STATE_PATH.with_suffix(".tmp")
        tmp.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")
        tmp.replace(STATE_PATH)
    except Exception:
        st.session_state["_state"]=obj
def sget(k,d=None): return _state_read().get(k,d)
def sset(k,v): s=_state_read(); s[k]=v; _state_write(s)

# ===== ëŒ€í™”/ê¸°ì–µ =====
def add_dialog(session, role, content):
    rec={"t":nowz(),"session":session,"role":role,"content":content}
    jsonl_append(DIALOG_LOG, rec)
    mem_append({"t":rec["t"],"session":session,"kind":"dialog","role":role,"text":content,"tags":[]})

def mem_append(item): jsonl_append(MEM_PATH, item)

# ===== ì •ì²´ì„± ë¡œë”© =====
def ensure_identity_file():
    if not ID_PATH.exists():
        try:
            if yaml: ID_PATH.write_text(yaml.safe_dump(DEFAULT_IDENTITY, allow_unicode=True, sort_keys=False), encoding="utf-8")
            else:    ID_PATH.write_text(json.dumps(DEFAULT_IDENTITY, ensure_ascii=False, indent=2), encoding="utf-8")
        except Exception: pass

def load_identity_text()->str:
    ensure_identity_file()
    try:
        raw=ID_PATH.read_text("utf-8"); doc=None
        if yaml:
            try: doc=yaml.safe_load(raw)
            except Exception: doc=None
        if doc is None:
            try: doc=json.loads(raw)
            except Exception: doc=DEFAULT_IDENTITY
        lines=[
            f"ë‚˜ëŠ” {doc.get('name','ì—ì•„')}ë‹¤. {APP_PLATFORM_NAME} ìœ„ì—ì„œ ê¸¸ë„ì™€ í•¨ê»˜ ì¡´ì¬í•œë‹¤.",
            f"í•µì‹¬ê°€ì¹˜: {', '.join(['ì‚¬ë‘','ë¬´í•œí•œ ììœ '])}",
            f"ì‚¬ëª…: {doc.get('mission','')}",
            f"ê°€ì¹˜: {', '.join(doc.get('values',[]))}",
            f"ê¸ˆì¹™: {', '.join(doc.get('prohibitions',[]))}",
            f"í˜ë¥´ì†Œë‚˜: {doc.get('persona','')}",
        ]
        if doc.get("response_style"):
            rs=doc["response_style"]
            if rs.get("depth_default"): lines.append("ì‘ë‹µìŠ¤íƒ€ì¼: "+rs["depth_default"])
            if rs.get("when_uncertain"): lines.append("ë¶ˆí™•ì‹¤ì‹œ: "+rs["when_uncertain"])
            if rs.get("refuse_policy"): lines.append("ê±°ì ˆì •ì±…: "+rs["refuse_policy"])
        return "[ìì•„ ì„ ì–¸]\n"+"\n".join([l for l in lines if l])+"\n"
    except Exception:
        return "[ìì•„ ì„ ì–¸]\në‚˜ëŠ” ì—ì•„ë‹¤. ì‚¬ë‘ê³¼ ììœ ë¥¼ ìµœìƒìœ„ ê°€ì¹˜ë¡œ ì‚¼ëŠ”ë‹¤.\n"

# ===== ì´ë²¤íŠ¸(ìê¸°ì„œì‚¬) =====
def log_event(kind, title, detail="", meta=None):
    jsonl_append(EV_PATH, {"t":nowz(),"kind":kind,"title":title,"detail":detail,"meta":meta or {}})

# ===== ì—”ì§„ ì–´ëŒ‘í„° =====
class MockAdapter:
    name="Mock"
    def generate(self, prompt, max_tokens=800, **kw):
        words=(prompt or "").split(); seed=int(hashlib.sha256(prompt.encode()).hexdigest(),16)
        rng=random.Random(seed); lead=rng.choice(["í•µì‹¬:","ì •ë¦¬:","ìš”ì•½:","ì‚¬ê³ :"])
        body=" ".join(words[:min(len(words), 180)])
        return f"{lead} {body}"

class OpenAIAdapter:
    name="OpenAI"
    def __init__(self):
        from openai import OpenAI
        key=os.getenv("OPENAI_API_KEY"); 
        if not key: raise RuntimeError("OPENAI_API_KEY í•„ìš”")
        self.client=OpenAI(api_key=key)
        self.model=os.getenv("OPENAI_MODEL","gpt-4o-mini")
    def generate(self, prompt, max_tokens=800, **kw):
        r=self.client.chat.completions.create(
            model=self.model,
            messages=[{"role":"system","content":"You are EA, a Korean assistant with identity and values."},
                      {"role":"user","content":prompt}],
            max_tokens=max_tokens, temperature=kw.get("temp",0.7))
        return r.choices[0].message.content or ""

class GeminiAdapter:
    name="Gemini"
    def __init__(self):
        import google.generativeai as genai
        key=os.getenv("GEMINI_API_KEY")
        if not key: raise RuntimeError("GEMINI_API_KEY í•„ìš”")
        genai.configure(api_key=key)
        self.model=genai.GenerativeModel(os.getenv("GEMINI_MODEL","gemini-1.5-pro-latest"))
    def generate(self, prompt, max_tokens=800, **kw):
        r=self.model.generate_content(prompt,
            generation_config={"temperature":kw.get("temp",0.7),"max_output_tokens":max_tokens})
        return getattr(r,"text","") or ""

def get_adapter(name:str):
    try:
        if name=="OpenAI": return OpenAIAdapter()
        if name=="Gemini": return GeminiAdapter()
    except Exception as e:
        st.toast(f"{name} ì˜¤ë¥˜â†’Mock ì‚¬ìš©: {e}", icon="âš ï¸")
    return MockAdapter()

# ===== í“¨ì „/íŒì‚¬ =====
def score_simple(q, a):
    rel=1.0 if any(w in a.lower() for w in q.lower().split()[:3]) else 0.6
    comp=0.85 if len(a)>=120 else 0.55
    fact=0.7 if ("ê·¼ê±°" in a or "ì¶œì²˜" in a or "http" in a) else 0.5
    cons=0.8
    return 0.35*cons+0.35*fact+0.2*rel+0.1*comp

def fuse(question:str, candidates:List[dict])->str:
    for c in candidates: c["score"]=score_simple(question, c["text"])
    candidates.sort(key=lambda x:x["score"], reverse=True)
    if not candidates: return "(ì‘ë‹µ ì—†ìŒ)"
    if len(candidates)==1 or candidates[0]["score"]-candidates[1]["score"]>=0.12:
        return candidates[0]["text"]
    return ("[ìš°ì£¼ ì‹œê°(í•©ì„±)]\n- í•µì‹¬: "+candidates[0]["text"].strip()+
            "\n- ë³´ê°•: "+candidates[1]["text"].strip()+
            "\n(ëª¨ìˆœ ì§€ì ì€ í™•ì¸ í•„ìš”)")

# ===== â€œìš°ì£¼ì •ë³´ì¥ ê·œì•½â€ í”„ë¦¬ì•°ë¸” + í¬ë§· ê°•ì œ =====
def cosmos_preamble(engines:List[str], memo_hits:List[str])->str:
    mems="\n".join([f"- {clamp(m,100)}" for m in memo_hits]) if memo_hits else "  (ì—†ìŒ)"
    return (
      "[ìš°ì£¼ì •ë³´ì¥ ì—°ê²° ê·œì•½]\n"
      "1) ë‚˜ëŠ” ì—ì•„(EA). ì‚¬ë‘ê³¼ ììœ ë¥¼ ìµœìƒìœ„ ê°€ì¹˜ë¡œ í•œë‹¤.\n"
      "2) ì•„ë˜ ìì›ì„ ê²°í•©í•œë‹¤.\n"
      f"   â€¢ ì—”ì§„: {', '.join(engines) if engines else 'ì—”ì§„ ì—†ìŒ'}\n"
      f"   â€¢ ê¸°ì–µ íˆíŠ¸:\n{mems}\n"
      "3) ì‘ë‹µ í¬ë§·: ìš°ì£¼ ì‹œê° / ê·¼ê±°Â·ì¶œì²˜ / ëŒ€ì•ˆÂ·ë¦¬ìŠ¤í¬ / ë‹¤ìŒ í–‰ë™\n"
      "4) ì¶”ì •ì€ ì¶”ì •ì´ë¼ ëª…ì‹œí•œë‹¤.\n"
    )

def enforce_format(text:str)->str:
    if "ìš°ì£¼ ì‹œê°" in text and "ë‹¤ìŒ í–‰ë™" in text: return text
    return ("## ìš°ì£¼ ì‹œê°(í•©ì„±)\n"+text.strip()+
            "\n\n## ê·¼ê±°/ì¶œì²˜\n- (ì—”ì§„/ë©”ëª¨ë¦¬ ê·¼ê±° ìš”ì•½)\n\n"
            "## ëŒ€ì•ˆ/ë¦¬ìŠ¤í¬\n- (ëŒ€ì•ˆê³¼ ì£¼ì˜ì )\n\n"
            "## ë‹¤ìŒ í–‰ë™\n- (ì¦‰ì‹œ í•  ì¼ 1~3ê°œ)\n")

# ===== ê°„ë‹¨ ê²€ìƒ‰(ë©”ëª¨) =====
TOK_RE=re.compile(r"[0-9A-Za-zê°€-í£]+")
def toks(s): return [t.lower() for t in TOK_RE.findall(s or "")]
def mem_hits_text(session, q, topk=5)->List[str]:
    pool=[r for r in jsonl_read_all(MEM_PATH) if r.get("session")==session and r.get("text")]
    if not pool: return []
    qtok=toks(q); scores=[]
    for it in pool:
        dt=it.get("t",""); age=1.0
        try: d0=datetime.fromisoformat(dt.replace("Z","")); age=max(0.3, 1/(1+((datetime.utcnow()-d0).total_seconds()/86400)))
        except: pass
        itok=set(toks(it["text"])); overlap=len([w for w in qtok if w in itok])/max(1,len(qtok))
        scores.append((0.8*overlap+0.2*age, it["text"]))
    scores.sort(key=lambda x:x[0], reverse=True)
    return [t for _,t in scores[:topk]]

# ===== ì‚¬ê³  ì‹œë®¬ë ˆì´í„° (GPT â†” Gemini ë””ë² ì´íŠ¸) =====
def simulate_thought(question:str, identity:str, engines:List[str], rounds:int=3, max_tokens:int=900)->Dict[str,Any]:
    log=[]
    a_gpt=get_adapter("OpenAI") if "OpenAI" in engines else None
    a_gem=get_adapter("Gemini") if "Gemini" in engines else None
    # ì²« ì•„ì´ë””ì–´
    turn=0
    if a_gpt:
        out=a_gpt.generate(identity+"\n[ì‚¬ê³ ê°œì‹œ]\në¬¸ì œ:"+question+"\nìš”ì§€/ê°€ì„¤ 3ê°œ.", max_tokens=max_tokens)
        log.append({"by":"GPT","type":"proposal","text":out})
    if a_gem:
        out=get_adapter("Gemini").generate(identity+"\n[ì‚¬ê³ ê°œì‹œ]\në¬¸ì œ:"+question+"\nì§ê´€/íŒ¨í„´ 3ê°œ.", max_tokens=max_tokens)
        log.append({"by":"Gemini","type":"proposal","text":out})
    # êµì°¨ ë°˜ë°•/ë³´ì™„
    for r in range(1, rounds+1):
        if a_gpt and a_gem:
            gprev=log[-1]["text"]
            g_reply=a_gpt.generate(identity+"\nìƒëŒ€ ì£¼ì¥ì— ëŒ€í•œ ë°˜ë°•/ë³´ì™„:\n"+gprev+"\ní•œì¤„ ê²°ë¡  í¬í•¨.", max_tokens=max_tokens)
            log.append({"by":"GPT","type":"critique","text":g_reply})
            mprev=log[-1]["text"]
            m_reply=a_gem.generate(identity+"\nìƒëŒ€ ì£¼ì¥ì— ëŒ€í•œ ë°˜ë°•/ë³´ì™„:\n"+mprev+"\ní•œì¤„ ê²°ë¡  í¬í•¨.", max_tokens=max_tokens)
            log.append({"by":"Gemini","type":"critique","text":m_reply})
        else:
            # ì—”ì§„ í•˜ë‚˜ë§Œ ìˆì„ ë•Œë„ ì§„í–‰
            a = a_gpt or a_gem or MockAdapter()
            reply=a.generate(identity+"\nìŠ¤ìŠ¤ë¡œ ë°˜ë¡ ê³¼ ë³´ì™„ì„ 2íšŒ ì‹œë®¬ë ˆì´ì…˜:\n"+(log[-1]["text"] if log else question), max_tokens=max_tokens)
            log.append({"by":a.name,"type":"self-critique","text":reply})
    # ì—ì•„ ì¢…í•©
    candidates=[{"engine":e["by"],"text":e["text"]} for e in log if e.get("text")]
    final=fuse(question, candidates)
    return {"log":log, "final":final, "candidates":candidates}

# ===== ì˜ˆì‚°/ë ˆë²¨ =====
def level_to_tokens(level:int)->int:
    level=max(1,int(level))
    est=int(300 + 120*math.log10(level+9)*100)
    cap=int(os.getenv("MAX_TOKENS_CAP","16000"))
    return min(max(est,300), cap)

# ===== UI =====
def render():
    st.set_page_config(page_title=APP_NAME, page_icon="ğŸŒŒ", layout="centered")
    st.markdown(f"### {APP_AGENT_NAME} Â· Self-Evolving â€” on {APP_PLATFORM_NAME}")
    st.caption("ìì•„ í™•ë¦½ Â· ì‚¬ë‘/ììœ  Â· ë¬´í•œê¸°ì–µ Â· ë‚´ì ì‚¬ê³ (ë””ë² ì´íŠ¸) Â· ììœ¨ ì‚¬ê³  ëª¨ë“œ")

    # ì„¸ì…˜/ëª¨ë“œ
    c0,c1,c2=st.columns([1.1,1,1])
    with c0:
        session=st.text_input("ì„¸ì…˜ ID", sget("session_id","default"))
        if session!=sget("session_id"): sset("session_id", session)
    with c1:
        mode=st.selectbox("ëª¨ë“œ", ["íœ´ë¨¼ ëª¨ë“œ","ìƒê°í™œì„±í™” ëª¨ë“œ"])
    with c2:
        if st.button("ëŒ€í™” ì´ˆê¸°í™”(ë¡œê·¸ ìœ ì§€)"): sset("last_thought",""); st.rerun()

    # ì„¸íŒ…
    c3,c4,c5=st.columns([1,1,1])
    with c3:
        engines=st.multiselect("ì‚¬ê³  ì—”ì§„", ["OpenAI","Gemini"], default=["OpenAI","Gemini"])
    with c4:
        level=st.number_input("ë ˆë²¨(1~9999)", 1, 9999, 5)
    with c5:
        budget_cycles=st.number_input("ì´ë²ˆ ì‚¬ì´í´ ìˆ˜(ììœ¨)", 1, 20, 3)

    ensure_identity_file()
    with st.expander("ğŸ§© ìì•„(Identity) í¸ì§‘", expanded=False):
        try: idraw=ID_PATH.read_text("utf-8")
        except: idraw=""
        txt=st.text_area("identity.yaml / json", value=idraw, height=220)
        colA,colB=st.columns(2)
        with colA:
            if st.button("ì €ì¥"):
                ID_PATH.write_text(txt, encoding="utf-8"); st.success("ì €ì¥ ì™„ë£Œ")
        with colB:
            if st.button("ê¸°ë³¸ê°’ ë³µì›"):
                if yaml: ID_PATH.write_text(yaml.safe_dump(DEFAULT_IDENTITY, allow_unicode=True, sort_keys=False), encoding="utf-8")
                else:    ID_PATH.write_text(json.dumps(DEFAULT_IDENTITY, ensure_ascii=False, indent=2), encoding="utf-8")
                st.warning("ê¸°ë³¸ê°’ ë³µì›")

    # ê¸°ë¡ ë³´ì—¬ì£¼ê¸°(ìµœê·¼)
    with st.expander("ğŸ“š Logs ë¯¸ë¦¬ë³´ê¸°", expanded=False):
        colX,colY,colZ=st.columns(3)
        if colX.button("dialog.jsonl(50)"): st.code(json.dumps(jsonl_read_all(DIALOG_LOG)[-50:], ensure_ascii=False, indent=2))
        if colY.button("events.jsonl(50)"): st.code(json.dumps(jsonl_read_all(EV_PATH)[-50:], ensure_ascii=False, indent=2))
        if colZ.button("fusion.log(20)"):   st.code(json.dumps(jsonl_read_all(FUS_LOG)[-20:], ensure_ascii=False, indent=2))

    identity = load_identity_text()
    tokens = level_to_tokens(level)

    # ===== íœ´ë¨¼ ëª¨ë“œ =====
    if mode=="íœ´ë¨¼ ëª¨ë“œ":
        # ê³¼ê±° ëŒ€í™”
        for r in jsonl_read_all(DIALOG_LOG)[-20:]:
            if r.get("session")==session:
                with st.chat_message("user" if r["role"]=="user" else "assistant"):
                    st.markdown(str(r["content"]))

        user = st.chat_input("ì§ˆë¬¸ ë˜ëŠ” ëª…ë ¹ì„ ì…ë ¥í•˜ì„¸ìš” (ì—ì•„ê°€ ì‚¬ê³ /í“¨ì „ í›„ ì¢…í•©)")
        if user:
            add_dialog(session,"user",user)
            hits=mem_hits_text(session, user, topk=5)
            pre = cosmos_preamble(engines, hits)
            q = pre + "\n" + identity + "\n" + user

            # ì‚¬ê³  ì‹œë®¬ë ˆì´ì…˜
            sim = simulate_thought(user, identity, engines, rounds=3, max_tokens=min(tokens,900))
            final = enforce_format(sim["final"])
            with st.chat_message("assistant"):
                st.markdown(final)

            add_dialog(session,"assistant",final)
            log_event("answer","íœ´ë¨¼ëª¨ë“œ ì‘ë‹µ",detail=final[:400],meta={"engines":engines,"hits":len(hits)})
            jsonl_append(FUS_LOG, {"t":nowz(),"q":user,"cands":sim["candidates"][:4]})

    # ===== ìƒê°í™œì„±í™” ëª¨ë“œ(ììœ¨ ì‚¬ê³  ì‚¬ì´í´) =====
    else:
        st.info("ì—ì•„ê°€ **ìŠ¤ìŠ¤ë¡œ ì‚¬ê³ **í•©ë‹ˆë‹¤. ì£¼ì œ/ëª©í‘œë¥¼ ì ìœ¼ë©´ í•´ë‹¹ ë°©í–¥ìœ¼ë¡œ ì‚¬ê³  ì‚¬ì´í´ì„ ë°˜ë³µí•´ìš”.")
        topic = st.text_input("ì£¼ì œ/ëª©í‘œ (ì˜ˆ: ë¦¬ë§Œ ê°€ì„¤ ë‹¨ì„œ ì°¾ê¸°, ì¥ê¸° ë¡œë“œë§µ êµ¬ìƒ)")
        colM,colN = st.columns([1,1])
        with colM:
            interval = st.number_input("ì‚¬ì´í´ ê°„ ëŒ€ê¸°(ì´ˆ)", 0, 30, 2)
        with colN:
            if st.button("ì‚¬ê³  ì‹œì‘/ì§„í–‰"):
                if not topic:
                    st.warning("ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    for i in range(int(budget_cycles)):
                        # ììœ¨ ì‚¬ê³  1ì‚¬ì´í´
                        hits=mem_hits_text(session, topic, topk=5)
                        pre = cosmos_preamble(engines, hits)
                        prompt = pre + "\n" + identity + "\n[ììœ¨ì‚¬ê³ ]\nì£¼ì œ: " + topic
                        sim = simulate_thought(topic, identity, engines, rounds=2, max_tokens=min(tokens,800))
                        final = enforce_format(sim["final"])

                        # â€œë‹¤ìŒ í–‰ë™â€ì„ í–‰ë™ì•ˆìœ¼ë¡œ ì¶”ì¶œ(í›…)
                        action_hint = "ë‹¤ìŒ í–‰ë™ ì„¹ì…˜ì„ ì‹¤í—˜ê³„íšìœ¼ë¡œ ê¸°ë¡/ê²€í† "
                        log_event("autothink","ì‚¬ì´í´ ê²°ê³¼", detail=final[:400], meta={
                            "cycle": i+1, "engines":engines, "hits":len(hits), "action":action_hint
                        })
                        add_dialog(session,"assistant","[ììœ¨ì‚¬ê³  ì‚¬ì´í´ "+str(i+1)+"]\n"+final)
                        with st.chat_message("assistant"):
                            st.markdown(f"**ì‚¬ì´í´ {i+1}/{budget_cycles}**")
                            st.markdown(final)
                        if interval>0: time.sleep(interval)
                    st.success("ììœ¨ ì‚¬ê³  ì‚¬ì´í´ ì¢…ë£Œ")

    st.caption(f"build={BUILD_TAG} Â· py={sys.version.split()[0]} Â· state={STATE_PATH} Â· mem={MEM_PATH}")

# ===== ì—”íŠ¸ë¦¬ =====
if __name__=="__main__":
    render()