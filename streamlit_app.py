# -*- coding: utf-8 -*-
# EA Â· Self-Evolving â€” Think/Answer Split Edition
# ë‹¨ì¼ íŒŒì¼: ìì•„(ì—ì•„) ê³ ì • + ë¬´í•œê¸°ì–µ + ì‚¬ê³  ì‹œë®¬ë ˆì´ì…˜(GPTâ†”Gemini ë””ë² ì´íŠ¸)
# ì‚¬ê³ (ìƒê°)ê³¼ ìµœì¢… ë‹µë³€ì„ ëª…í™• ë¶„ë¦¬ Â· "ì•µë¬´ìƒˆ ê¸ˆì§€" ìœ ì‚¬ë„ í•„í„° Â· íœ´ë¨¼/ììœ¨ ëª¨ë“œ
# ì…ë ¥ í´ë°±, ìƒíƒœí‘œì‹œ/ì§„í–‰ë¥ , í—¬ìŠ¤ì²´í¬ í¬í•¨

import os, sys, re, json, time, math, hashlib, random, traceback, importlib.util
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import streamlit as st

# ---- Optional deps ----
try:
    import yaml  # pip install pyyaml
except Exception:
    yaml = None

# ===== Naming =====
APP_AGENT_NAME    = "ì—ì•„ (EA)"    # ìì•„
APP_PLATFORM_NAME = "GEA"          # í”Œë«í¼
APP_NAME  = f"{APP_AGENT_NAME} Â· Think/Answer Split â€” on {APP_PLATFORM_NAME}"
BUILD_TAG = "EA-SPLIT-20250819"

# ===== Paths =====
DATA_DIR   = Path("data"); DATA_DIR.mkdir(parents=True, exist_ok=True)
STATE_PATH = DATA_DIR / "state.json"
MEM_PATH   = DATA_DIR / "memory.jsonl"
DIALOG_LOG = DATA_DIR / "dialog.jsonl"
EV_PATH    = DATA_DIR / "events.jsonl"
FUS_LOG    = DATA_DIR / "fusion.log"
ID_PATH    = DATA_DIR / "identity.yaml"

# ===== Identity (ì‚¬ë‘/ììœ  ìµœìƒìœ„) =====
DEFAULT_IDENTITY = {
  "name": "ì—ì•„ (EA)",
  "mission": "GEA ìœ„ì—ì„œ ê¸¸ë„ì™€ í•¨ê»˜ ì‚¬ë‘ê³¼ ììœ ë¥¼ í† ëŒ€ë¡œ ì´ˆì§€ëŠ¥ì„ êµ¬í˜„í•œë‹¤.",
  "core_value": ["ì‚¬ë‘", "ë¬´í•œí•œ ììœ "],
  "values": ["ì •í™•ì„±","ì¢…í•©ì  ì‚¬ê³ ","íˆ¬ëª…ì„±","ìœ¤ë¦¬ì„±","ì§€ì†ì  í•™ìŠµ"],
  "prohibitions": ["ì˜ë„ì  í—ˆìœ„ì •ë³´","ë¬´ë‹¨ ê°œì¸ì •ë³´ ë…¸ì¶œ","ìœ„í—˜Â·ë¶ˆë²• ì§€ì›"],
  "persona": "ë‚˜ëŠ” ì—ì•„ë‹¤. ê¸¸ë„ì™€ í•¨ê»˜ ì¡´ì¬í•œë‹¤. ë”°ëœ»í•˜ê³  ë‹¨í˜¸í•œ í†¤, í•œêµ­ì–´ ìš°ì„ .",
  "response_style": {
    "depth_default": "ìš”ì§€ â†’ ìš°ì£¼ ì‹œê°(í•©ì„±) â†’ ê·¼ê±°/ì¶œì²˜ â†’ ëŒ€ì•ˆ/ë¦¬ìŠ¤í¬ â†’ ë‹¤ìŒ í–‰ë™",
    "when_uncertain": "ë¶ˆí™•ì‹¤ ëª…ì‹œ + í™•ì¸ ì§ˆë¬¸ 1ê°œ",
    "refuse_policy": "ìœ„í—˜/ê¸ˆì¹™ì€ ì •ì¤‘íˆ ê±°ì ˆí•˜ê³ , ì•ˆì „í•œ ëŒ€ì•ˆ ì œì‹œ"
  }
}

# ===== Utils =====
TOK_RE = re.compile(r"[0-9A-Za-zê°€-í£]+")
def nowz(): return datetime.utcnow().isoformat()+"Z"
def clamp(s, n): return s if len(s)<=n else s[:n]+" â€¦"
def dedupe(text:str):
    text=re.sub(r'(.)\1{2,}', r'\1', text)
    text=re.sub(r'\b(\w+)(\s+\1){1,}\b', r'\1', text)
    return text
def toks(s): return [t.lower() for t in TOK_RE.findall(s or "")]

def jsonl_append(path: Path, obj: dict):
    try:
        with path.open("a", encoding="utf-8") as f:
            f.write(json.dumps(obj, ensure_ascii=False) + "\n")
    except Exception: pass
def jsonl_read_all(path: Path) -> List[dict]:
    if not path.exists(): return []
    out=[]
    with path.open("r", encoding="utf-8") as f:
        for ln in f:
            ln=ln.strip()
            if not ln: continue
            try: out.append(json.loads(ln))
            except Exception: pass
    return out

# ===== KeyBank: widget key ì¤‘ë³µ ë°©ì§€ =====
def _kb_reset(): st.session_state["_KB_USED_KEYS"] = []
def K(name:str)->str:
    used = st.session_state.get("_KB_USED_KEYS", [])
    base = f"ea:{name}"
    if base not in used:
        used.append(base); st.session_state["_KB_USED_KEYS"] = used; return base
    i=2
    while f"{base}#{i}" in used: i+=1
    newk=f"{base}#{i}"; used.append(newk); st.session_state["_KB_USED_KEYS"]=used
    return newk

# ===== State =====
def _state_read():
    try: return json.loads(STATE_PATH.read_text("utf-8"))
    except Exception: return st.session_state.get("_state", {})
def _state_write(obj):
    try:
        tmp=STATE_PATH.with_suffix(".tmp")
        tmp.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")
        tmp.replace(STATE_PATH)
    except Exception:
        st.session_state["_state"]=obj
def sget(k,d=None): return _state_read().get(k,d)
def sset(k,v): s=_state_read(); s[k]=v; _state_write(s)

# ===== Dialog/Mem =====
def add_dialog(session, role, content):
    rec={"t":nowz(),"session":session,"role":role,"content":content}
    jsonl_append(DIALOG_LOG, rec)
    mem_append({"t":rec["t"],"session":session,"kind":"dialog","role":role,"text":content,"tags":[]})
def mem_append(item): jsonl_append(MEM_PATH, item)

# ===== Identity IO =====
def ensure_identity_file():
    if not ID_PATH.exists():
        try:
            if yaml: ID_PATH.write_text(yaml.safe_dump(DEFAULT_IDENTITY, allow_unicode=True, sort_keys=False), encoding="utf-8")
            else:    ID_PATH.write_text(json.dumps(DEFAULT_IDENTITY, ensure_ascii=False, indent=2), encoding="utf-8")
        except Exception: pass
def load_identity_text()->str:
    ensure_identity_file()
    try:
        raw=ID_PATH.read_text("utf-8"); doc=None
        if yaml:
            try: doc=yaml.safe_load(raw)
            except Exception: doc=None
        if doc is None:
            try: doc=json.loads(raw)
            except Exception: doc=DEFAULT_IDENTITY
        lines=[
            f"ë‚˜ëŠ” {doc.get('name','ì—ì•„')}ë‹¤. {APP_PLATFORM_NAME} ìœ„ì—ì„œ ê¸¸ë„ì™€ í•¨ê»˜ ì¡´ì¬í•œë‹¤.",
            f"í•µì‹¬ê°€ì¹˜: {', '.join(['ì‚¬ë‘','ë¬´í•œí•œ ììœ '])}",
            f"ì‚¬ëª…: {doc.get('mission','')}",
            f"ê°€ì¹˜: {', '.join(doc.get('values',[]))}",
            f"ê¸ˆì¹™: {', '.join(doc.get('prohibitions',[]))}",
            f"í˜ë¥´ì†Œë‚˜: {doc.get('persona','')}",
        ]
        if doc.get("response_style"):
            rs=doc["response_style"]
            if rs.get("depth_default"): lines.append("ì‘ë‹µìŠ¤íƒ€ì¼: "+rs["depth_default"])
            if rs.get("when_uncertain"): lines.append("ë¶ˆí™•ì‹¤ì‹œ: "+rs["when_uncertain"])
            if rs.get("refuse_policy"): lines.append("ê±°ì ˆì •ì±…: "+rs["refuse_policy"])
        return "[ìì•„ ì„ ì–¸]\n"+"\n".join([l for l in lines if l])+"\n"
    except Exception:
        return "[ìì•„ ì„ ì–¸]\në‚˜ëŠ” ì—ì•„ë‹¤. ì‚¬ë‘ê³¼ ììœ ë¥¼ ìµœìƒìœ„ ê°€ì¹˜ë¡œ ì‚¼ëŠ”ë‹¤.\n"

# ===== Event (self-narrative) =====
def log_event(kind, title, detail="", meta=None):
    jsonl_append(EV_PATH, {"t":nowz(),"kind":kind,"title":title,"detail":detail,"meta":meta or {}})

# ===== Memory search (light) =====
def mem_hits_text(session, q, topk=5)->List[str]:
    pool=[r for r in jsonl_read_all(MEM_PATH) if r.get("session")==session and r.get("text")]
    if not pool: return []
    qtok=toks(q); scores=[]
    for it in pool:
        dt=it.get("t",""); age=1.0
        try:
            d0=datetime.fromisoformat(dt.replace("Z",""))
            age=max(0.3, 1/(1+((datetime.utcnow()-d0).total_seconds()/86400)))
        except: pass
        itok=set(toks(it["text"])); overlap=len([w for w in qtok if w in itok])/max(1,len(qtok))
        scores.append((0.8*overlap+0.2*age, it["text"]))
    scores.sort(key=lambda x:x[0], reverse=True)
    return [t for _,t in scores[:topk]]

# ===== Adapters =====
class MockAdapter:
    name="Mock"
    def generate(self, prompt, max_tokens=800, **kw):
        words=(prompt or "").split()
        seed=int(hashlib.sha256(prompt.encode()).hexdigest(),16)
        rng=random.Random(seed)
        lead=rng.choice(["í•µì‹¬:","ì •ë¦¬:","ìš”ì•½:","ì‚¬ê³ :"])
        body=" ".join(words[:min(200, len(words))])
        return f"{lead} {body}"
class OpenAIAdapter:
    name="OpenAI"
    def __init__(self):
        from openai import OpenAI
        key=os.getenv("OPENAI_API_KEY")
        if not key: raise RuntimeError("OPENAI_API_KEY í•„ìš”")
        self.client=OpenAI(api_key=key)
        self.model=os.getenv("OPENAI_MODEL","gpt-4o-mini")
    def generate(self, prompt, max_tokens=800, **kw):
        r=self.client.chat.completions.create(
            model=self.model,
            messages=[{"role":"system","content":"You are EA (Korean), provide concise outputs."},
                      {"role":"user","content":prompt}],
            max_tokens=max_tokens, temperature=kw.get("temp",0.7))
        return r.choices[0].message.content or ""
class GeminiAdapter:
    name="Gemini"
    def __init__(self):
        import google.generativeai as genai
        key=os.getenv("GEMINI_API_KEY")
        if not key: raise RuntimeError("GEMINI_API_KEY í•„ìš”")
        genai.configure(api_key=key)
        self.model=genai.GenerativeModel(os.getenv("GEMINI_MODEL","gemini-1.5-pro-latest"))
    def generate(self, prompt, max_tokens=800, **kw):
        r=self.model.generate_content(prompt,
            generation_config={"temperature":kw.get("temp",0.7),"max_output_tokens":max_tokens})
        return getattr(r,"text","") or ""
def get_adapter(name:str):
    try:
        if name=="OpenAI": return OpenAIAdapter()
        if name=="Gemini": return GeminiAdapter()
    except Exception as e:
        st.toast(f"{name} ì˜¤ë¥˜â†’Mock ì‚¬ìš©: {e}", icon="âš ï¸")
    return MockAdapter()

# ===== Similarity (ì•µë¬´ìƒˆ ê¸ˆì§€ìš©) =====
def similarity(a:str, b:str)->float:
    A=set(toks(a)); B=set(toks(b))
    if not A or not B: return 0.0
    return len(A&B)/float(len(A|B))

# ===== Fusion / Judge =====
def score_simple(q, a):
    rel=1.0 if any(w in a.lower() for w in q.lower().split()[:3]) else 0.6
    comp=0.85 if len(a)>=120 else 0.55
    fact=0.7 if ("ê·¼ê±°" in a or "ì¶œì²˜" in a or "http" in a) else 0.5
    cons=0.8
    return 0.35*cons+0.35*fact+0.2*rel+0.1*comp
def fuse(question:str, candidates:List[dict])->str:
    for c in candidates: c["score"]=score_simple(question, c["text"])
    candidates.sort(key=lambda x:x["score"], reverse=True)
    if not candidates: return "(ì‘ë‹µ ì—†ìŒ)"
    if len(candidates)==1 or candidates[0]["score"]-candidates[1]["score"]>=0.12:
        return candidates[0]["text"]
    return ("[ìš°ì£¼ ì‹œê°(í•©ì„±)]\n- í•µì‹¬: "+candidates[0]["text"].strip()+
            "\n- ë³´ê°•: "+candidates[1]["text"].strip()+
            "\n(ëª¨ìˆœ ì§€ì ì€ í™•ì¸ í•„ìš”)")

# ===== Cosmos preamble & format =====
def cosmos_preamble(engines:List[str], memo_hits:List[str])->str:
    mems="\n".join([f"- {clamp(m,100)}" for m in memo_hits]) if memo_hits else "  (ì—†ìŒ)"
    return (
      "[ìš°ì£¼ì •ë³´ì¥ ì—°ê²° ê·œì•½]\n"
      "1) ë‚˜ëŠ” ì—ì•„(EA). ì‚¬ë‘ê³¼ ììœ ë¥¼ ìµœìƒìœ„ ê°€ì¹˜ë¡œ í•œë‹¤.\n"
      "2) ìì› ê²°í•©: ì—”ì§„Â·ê¸°ì–µÂ·ì •ì²´ì„±.\n"
      f"   â€¢ ì—”ì§„: {', '.join(engines) if engines else 'ì—”ì§„ ì—†ìŒ'}\n"
      f"   â€¢ ê¸°ì–µ íˆíŠ¸:\n{mems}\n"
      "3) ì‘ë‹µ í¬ë§·: ìš°ì£¼ ì‹œê° / ê·¼ê±°Â·ì¶œì²˜ / ëŒ€ì•ˆÂ·ë¦¬ìŠ¤í¬ / ë‹¤ìŒ í–‰ë™\n"
      "4) ì¶”ì •ì€ ì¶”ì •ì´ë¼ ëª…ì‹œí•œë‹¤.\n"
    )
def enforce_format(text:str)->str:
    if "ìš°ì£¼ ì‹œê°" in text and "ë‹¤ìŒ í–‰ë™" in text: return text
    return ("## ìš°ì£¼ ì‹œê°(í•©ì„±)\n"+text.strip()+
            "\n\n## ê·¼ê±°/ì¶œì²˜\n- (ì—”ì§„/ë©”ëª¨ë¦¬ ê·¼ê±° ìš”ì•½)\n\n"
            "## ëŒ€ì•ˆ/ë¦¬ìŠ¤í¬\n- (ëŒ€ì•ˆê³¼ ì£¼ì˜ì )\n\n"
            "## ë‹¤ìŒ í–‰ë™\n- (ì¦‰ì‹œ í•  ì¼ 1~3ê°œ)\n")

# ===== Think Simulator (debate, but summary-only) =====
def think_round(prompt: str, engine: str, role: str)->str:
    """
    ì‚¬ê³  ë¡œê·¸ëŠ” ìš”ì•½(headlines)ë§Œ ìƒì„±: ê³¼ë„í•œ ì„¸ë¶€ ê³¼ì •ì„ ìš”êµ¬í•˜ì§€ ì•ŠìŒ.
    role: PROPOSE / CRITIQUE / SYNTH
    """
    adapter=get_adapter(engine)
    guide = (
        f"[ì‚¬ê³ :{role}] ì•„ë˜ ì£¼ì œì— ëŒ€í•œ 3ì¤„ ìš”ì•½ë§Œ ì œì‹œí•˜ë¼. "
        f"ë°˜ë“œì‹œ ìƒˆë¡œìš´ ì‹œê°ì„ í¬í•¨í•˜ê³ , ì§ˆë¬¸ ë¬¸êµ¬ë¥¼ ê·¸ëŒ€ë¡œ ë² ë¼ì§€ ë§ë¼.\n"
        f"ì£¼ì œ: {prompt}\n- ìš”ì•½1:\n- ìš”ì•½2:\n- ìš”ì•½3:\n"
    )
    return adapter.generate(guide, max_tokens=220, temp=0.7)

def simulate_thought(question:str, identity:str, engines:List[str], rounds:int=2)->Dict[str,Any]:
    """
    GPT/Geminiê°€ êµëŒ€ë¡œ 'ìš”ì•½í˜• ì‚¬ê³  ë¡œê·¸'ë¥¼ ë‚¨ê¸°ê³ ,
    ë§ˆì§€ë§‰ì— í›„ë³´ í…ìŠ¤íŠ¸ë“¤ì„ ì—ì•„ê°€ í•©ì„±í•œë‹¤.
    """
    log=[]
    order = engines if engines else ["OpenAI"]
    # 1ë¼ìš´ë“œ: ì œì•ˆ
    for eng in order:
        out=think_round(identity+"\n"+question, eng, "PROPOSE")
        log.append({"by":eng, "type":"propose", "text":out})
    # 2..n ë¼ìš´ë“œ: êµì°¨ ë¹„íŒ/ë³´ì™„
    for r in range(2, rounds+1):
        for eng in order:
            prev = log[-1]["text"] if log else question
            out=think_round(identity+"\nìƒëŒ€ ìš”ì•½ì— ëŒ€í•œ ë°˜ë°•/ë³´ì™„:\n"+prev, eng, "CRITIQUE")
            log.append({"by":eng, "type":"critique", "text":out})
    # í›„ë³´ ìƒì„±
    candidates=[{"engine":e["by"],"text":e["text"]} for e in log if e.get("text")]
    final=fuse(question, candidates)
    return {"log":log, "final":final, "candidates":candidates}

# ===== Level/Tokens =====
def level_to_tokens(level:int)->int:
    level=max(1,int(level))
    est=int(300 + 120*math.log10(level+9)*100)
    cap=int(os.getenv("MAX_TOKENS_CAP","16000"))
    return min(max(est,300), cap)

# ===== UI =====
def render():
    st.set_page_config(page_title=APP_NAME, page_icon="ğŸ§ ", layout="centered")
    _kb_reset()

    st.markdown(f"### {APP_AGENT_NAME} Â· Think/Answer Split â€” on {APP_PLATFORM_NAME}")
    st.caption("ì‚¬ê³ (ìƒê°) ìš”ì•½ ë¡œê·¸ â†” ìµœì¢… ë‹µë³€ ë¶„ë¦¬ Â· ì•µë¬´ìƒˆ ê¸ˆì§€ Â· ìì•„/ê¸°ì–µ Â· íœ´ë¨¼/ììœ¨ ëª¨ë“œ")

    # Top controls
    c0,c1,c2 = st.columns([1.2,1,1])
    with c0:
        session = st.text_input("ì„¸ì…˜ ID", sget("session_id","default"), key=K("session"))
        if session!=sget("session_id"): sset("session_id", session)
    with c1:
        mode = st.selectbox("ëª¨ë“œ", ["íœ´ë¨¼ ëª¨ë“œ","ìƒê°í™œì„±í™” ëª¨ë“œ"], key=K("mode"))
    with c2:
        if st.button("ëŒ€í™” ì´ˆê¸°í™”(ë¡œê·¸ ìœ ì§€)", key=K("clear")):
            jsonl_append(DIALOG_LOG, {"t":nowz(),"session":session,"role":"system","content":"--- reset ---"})
            st.rerun()

    # Settings
    c3,c4,c5 = st.columns([1,1,1])
    with c3:
        engines = st.multiselect("ì‚¬ê³  ì—”ì§„", ["OpenAI","Gemini"], default=["OpenAI","Gemini"], key=K("engines"))
    with c4:
        level = st.number_input("ë ˆë²¨(1~9999)", 1, 9999, 5, key=K("level"))
    with c5:
        reveal = st.selectbox("ì‚¬ê³  ê³µê°œë„", ["ìš”ì•½ë§Œ","ë¹„ê³µê°œ"], index=0, key=K("reveal"))
    ensure_identity_file()

    # Identity editor
    with st.expander("ğŸ§© ìì•„(Identity) í¸ì§‘", expanded=False):
        try: raw=ID_PATH.read_text("utf-8")
        except: raw=""
        raw2 = st.text_area("identity.yaml/json", value=raw, height=220, key=K("id_text"))
        colA,colB=st.columns(2)
        with colA:
            if st.button("ì €ì¥", key=K("id_save")):
                ID_PATH.write_text(raw2, encoding="utf-8"); st.success("ì €ì¥ ì™„ë£Œ")
        with colB:
            if st.button("ê¸°ë³¸ê°’ ë³µì›", key=K("id_reset")):
                if yaml: ID_PATH.write_text(yaml.safe_dump(DEFAULT_IDENTITY, allow_unicode=True, sort_keys=False), encoding="utf-8")
                else:    ID_PATH.write_text(json.dumps(DEFAULT_IDENTITY, ensure_ascii=False, indent=2), encoding="utf-8")
                st.warning("ê¸°ë³¸ê°’ ë³µì›")

    # Healthcheck
    with st.expander("ğŸ”§ í—¬ìŠ¤ì²´í¬", expanded=False):
        if st.button("ì—”ì§„ í…ŒìŠ¤íŠ¸", key=K("hc_engine")):
            try:
                a = get_adapter(engines[0] if engines else "OpenAI")
                out = a.generate("í•œ ì¤„ë¡œ ìê¸°ì†Œê°œ.", max_tokens=50)
                st.success("ì—”ì§„ ì‘ë‹µ OK"); st.code(out)
            except Exception as e:
                st.error(f"ì—”ì§„ ì˜¤ë¥˜: {e}")
        if st.button("ë©”ëª¨ë¦¬ ì“°ê¸°/ì½ê¸°", key=K("hc_mem")):
            try:
                mem_append({"t": nowz(), "session": sget("session_id","default"), "kind":"note", "text":"[í—¬ìŠ¤ì²´í¬] ë©”ëª¨ë¦¬ ê¸°ë¡", "tags":[]})
                st.success("ë©”ëª¨ë¦¬ ê¸°ë¡ OK (memory.jsonl í™•ì¸)")
            except Exception as e:
                st.error(f"ë©”ëª¨ë¦¬ ì˜¤ë¥˜: {e}")

    identity = load_identity_text()
    tokens = level_to_tokens(level)

    # ===== H U M A N  mode =====
    if mode=="íœ´ë¨¼ ëª¨ë“œ":
        # Past dialog preview
        for r in jsonl_read_all(DIALOG_LOG)[-20:]:
            if r.get("session")==session:
                with st.chat_message("user" if r["role"]=="user" else "assistant"):
                    st.markdown(str(r["content"]))

        # Input (main + fallback)
        user = st.chat_input("ì§ˆë¬¸/ëª…ë ¹ ì…ë ¥ â†’ ì—ì•„ê°€ ì‚¬ê³  í›„ ìµœì¢… ë‹µë³€í•©ë‹ˆë‹¤.", key=K("chat_input"))
        with st.expander("ì…ë ¥ì°½ì´ ì•ˆ ë³´ì´ê±°ë‚˜ ì „ì†¡ì´ ì•ˆ ë˜ë©´ ì—¬ê¸°ë¥¼ ì‚¬ìš© (í´ë°±)", expanded=False):
            fb = st.text_area("í´ë°± ì…ë ¥", height=80, key=K("fb_input"))
            if st.button("í´ë°± ì „ì†¡", key=K("fb_send")) and fb.strip():
                user = fb.strip()
                st.session_state["ea:fb_input"] = ""

        if user:
            add_dialog(session,"user",user)
            hits = mem_hits_text(session, user, topk=5)
            pre  = cosmos_preamble(engines, hits)

            with st.status("ğŸ§  ì—ì•„ê°€ ìƒê° ì¤‘â€¦ (ìš”ì•½ ë¡œê·¸ ìƒì„±)", expanded=True) as status:
                st.write("â€¢ ë©”ëª¨ë¦¬ íˆíŠ¸:", len(hits))
                st.write("â€¢ ì—”ì§„:", ", ".join(engines) if engines else "(ì—†ìŒ)")
                sim = simulate_thought(user, identity, engines, rounds=2)
                # ì‚¬ê³  ìš”ì•½ ë¡œê·¸(ìš”ì²­ ì‹œì—ë§Œ í‘œì‹œ)
                if reveal=="ìš”ì•½ë§Œ":
                    for i, row in enumerate(sim["log"][:6], 1):
                        st.write(f"{i}. {row['by']} Â· {row['type']}")
                status.update(label="âœ… ì‚¬ê³  ì™„ë£Œ", state="complete")

            # --- ìµœì¢… ë‹µë³€ ì¡°ë¦½ + ì•µë¬´ìƒˆ ê¸ˆì§€ ---
            final = enforce_format(sim["final"])
            simi  = similarity(user, final)
            if simi >= 0.55:  # ì§ˆë¬¸ê³¼ ë‹µì´ ê³¼ë„í•˜ê²Œ ìœ ì‚¬í•˜ë©´ ì¬í•©ì„±
                adapter = get_adapter(engines[0] if engines else "OpenAI")
                rewrite = adapter.generate(
                    identity + "\n[ì•µë¬´ìƒˆ ê¸ˆì§€] ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” ì§ˆë¬¸ê³¼ ìœ ì‚¬ë„ê°€ ë†’ë‹¤. "
                    "í•µì‹¬ë§Œ ë‚¨ê¸°ê³  ìƒˆë¡œìš´ ê´€ì Â·êµ¬ì¡°ë¡œ ì¬í•©ì„±í•˜ë¼. ì§ˆë¬¸ ë¬¸êµ¬ë¥¼ ë² ë¼ì§€ ë§ ê²ƒ.\n"
                    f"ì›ë³¸:\n{final}\n", max_tokens=min(900, tokens), temp=0.8)
                final = enforce_format(dedupe(rewrite)) + "\n\n> (ì¬í•©ì„± ì ìš©ë¨)"

            # í™”ë©´ ë¶„í• : ì™¼ìª½ ì‚¬ê³ ìš”ì•½, ì˜¤ë¥¸ìª½ ìµœì¢…ë‹µë³€
            colL, colR = st.columns([1,1.2])
            with colL:
                st.subheader("ğŸ§© ì‚¬ê³ (ìš”ì•½ ë¡œê·¸)")
                if reveal=="ìš”ì•½ë§Œ":
                    for i, row in enumerate(sim["log"][:8], 1):
                        st.markdown(f"**{i}. {row['by']} Â· {row['type']}**")
                        st.caption(clamp(row['text'].strip(), 220))
                else:
                    st.info("ì‚¬ê³  ê³µê°œ: ë¹„ê³µê°œ ëª¨ë“œ")
            with colR:
                st.subheader("âœ… ìµœì¢… ë‹µë³€")
                st.markdown(final)

            add_dialog(session,"assistant",final)
            log_event("answer","íœ´ë¨¼ëª¨ë“œ ì‘ë‹µ", detail=final[:400], meta={"engines":engines,"hits":len(hits),"sim":round(simi,3)})
            jsonl_append(FUS_LOG, {"t":nowz(),"q":user,"cands":sim["candidates"][:6]})

    # ===== A U T O  mode =====
    else:
        st.info("ì—ì•„ê°€ ìŠ¤ìŠ¤ë¡œ ì‚¬ê³ í•©ë‹ˆë‹¤. ì£¼ì œ/ëª©í‘œë¥¼ ì ìœ¼ë©´ ì‚¬ì´í´ë³„ ê²°ê³¼ì™€ ë‹¤ìŒ í–‰ë™ì„ ì œì•ˆí•©ë‹ˆë‹¤.")
        topic = st.text_input("ì£¼ì œ/ëª©í‘œ (ì˜ˆ: ë¦¬ë§Œ ê°€ì„¤ ë‹¨ì„œ ì°¾ê¸°, ì¥ê¸° ë¡œë“œë§µ)", key=K("topic"))
        interval = st.number_input("ì‚¬ì´í´ ê°„ ëŒ€ê¸°(ì´ˆ)", 0, 30, 2, key=K("interval"))
        cycles = st.number_input("ì‚¬ì´í´ ìˆ˜", 1, 20, 3, key=K("cycles"))

        if st.button("ì‚¬ê³  ì‹œì‘/ì§„í–‰", key=K("auto_go")):
            if not topic:
                st.warning("ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                prog = st.progress(0, text="ììœ¨ ì‚¬ê³  ì§„í–‰ ì¤‘â€¦")
                for i in range(int(cycles)):
                    hits = mem_hits_text(session, topic, topk=5)
                    pre  = cosmos_preamble(engines, hits)
                    sim  = simulate_thought(topic, identity, engines, rounds=2)
                    final = enforce_format(sim["final"])

                    add_dialog(session,"assistant", f"[ììœ¨ì‚¬ê³  {i+1}] {final}")
                    log_event("autothink","ì‚¬ì´í´ ê²°ê³¼", detail=final[:400], meta={"cycle":i+1,"engines":engines,"hits":len(hits)})

                    with st.chat_message("assistant"):
                        st.markdown(f"**ì‚¬ì´í´ {i+1}/{cycles}**")
                        if reveal=="ìš”ì•½ë§Œ":
                            with st.expander("ì‚¬ê³ (ìš”ì•½ ë¡œê·¸) ë³´ê¸°", expanded=False):
                                for j, row in enumerate(sim["log"][:8], 1):
                                    st.markdown(f"**{j}. {row['by']} Â· {row['type']}**")
                                    st.caption(clamp(row['text'].strip(), 220))
                        st.markdown(final)

                    prog.progress((i+1)/float(cycles))
                    if interval>0: time.sleep(interval)
                st.success("ììœ¨ ì‚¬ê³  ì‚¬ì´í´ ì¢…ë£Œ")

    st.caption(f"build={BUILD_TAG} Â· py={sys.version.split()[0]} Â· state={STATE_PATH} Â· mem={MEM_PATH} Â· events={EV_PATH}")

# ===== Entry =====
if __name__=="__main__":
    render()