# -*- coding: utf-8 -*-
# EA Â· Chat+Think AIO v2.2 â€” Live Workpad
# - ì‹¤ì‹œê°„ ì‚¬ê³  ìŠ¤íŠ¸ë¦¼(autorefresh)
# - ë‹µë³€/ì‚¬ê³  ë¶„ë¦¬ + êµì°¨
# - ë°˜ì•µë¬´ìƒˆ ì„ê³„ ê°•í™”(0.30)
# - rerun ì‚¬ìš©, DuplicateKey ë°©ì§€
# - ì—”ì§„ ì˜¤ë¥˜ì‹œ Mock í´ë°±

import os, sys, re, json, time, math, hashlib, random
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
import streamlit as st

# ---------- Basics ----------
APP_AGENT="ì—ì•„ (EA)"; PLATFORM="GEA"; BUILD="EA-AIO-v2.2"
DATA=Path("data"); DATA.mkdir(parents=True, exist_ok=True)
STATE=DATA/"state.json"; MEM=DATA/"memory.jsonl"; DLG=DATA/"dialog.jsonl"; IDF=DATA/"identity.yaml"

TOK=re.compile(r"[0-9A-Za-zê°€-í£]+")

def toks(s): return [t.lower() for t in TOK.findall(s or "")]
def nowz(): return datetime.utcnow().isoformat()+"Z"
def clamp(s,n): return s if len(s)<=n else s[:n]+" â€¦"
def jappend(p:Path, o:dict): 
    try:
        with p.open("a",encoding="utf-8") as f: f.write(json.dumps(o,ensure_ascii=False)+"\n")
    except: pass
def jread(p:Path)->list:
    if not p.exists(): return []
    out=[]; 
    with p.open("r",encoding="utf-8") as f:
        for ln in f:
            ln=ln.strip()
            if not ln: continue
            try: out.append(json.loads(ln))
            except: pass
    return out

# ---------- KeyBank ----------
def _kb_init(): st.session_state.setdefault("_KB", set())
def K(name:str)->str:
    used=st.session_state["_KB"]; base=f"ea:{name}"
    if base not in used: used.add(base); return base
    i=2
    while f"{base}#{i}" in used: i+=1
    key=f"{base}#{i}"; used.add(key); return key

# ---------- State ----------
def _sread():
    try: return json.loads(STATE.read_text("utf-8"))
    except: return st.session_state.get("_S",{})
def _swrite(o):
    try:
        tmp=STATE.with_suffix(".tmp")
        tmp.write_text(json.dumps(o,ensure_ascii=False,indent=2),encoding="utf-8")
        tmp.replace(STATE)
    except: st.session_state["_S"]=o
def sget(k,d=None): return _sread().get(k,d)
def sset(k,v): S=_sread(); S[k]=v; _swrite(S)

# ---------- Identity ----------
DEFAULT_ID={"name":"ì—ì•„ (EA)","mission":"ì‚¬ë‘/ììœ  ê¸°ë°˜ ì´ˆì§€ëŠ¥","values":["ì •í™•ì„±","íˆ¬ëª…ì„±","í•™ìŠµ"],"persona":"ë”°ëœ»Â·ë‹¨í˜¸Â·í•œêµ­ì–´"}
def identity_text()->str:
    if not IDF.exists(): IDF.write_text(json.dumps(DEFAULT_ID,ensure_ascii=False,indent=2),encoding="utf-8")
    try: doc=json.loads(IDF.read_text("utf-8"))
    except: doc=DEFAULT_ID
    return f"[ìì•„ ì„ ì–¸]\në‚˜ëŠ” {doc.get('name','ì—ì•„')}ë‹¤. ì‚¬ë‘ê³¼ ììœ ë¥¼ ìµœìƒìœ„ ê°€ì¹˜ë¡œ í•œë‹¤.\nì‚¬ëª…: {doc.get('mission','')}\n"

# ---------- Dialog/Mem ----------
def add_dialog(sess, role, content):
    rec={"t":nowz(),"session":sess,"role":role,"content":content}
    jappend(DLG, rec); jappend(MEM, {"t":rec["t"],"session":sess,"kind":"dialog","role":role,"text":content})

def mem_hits(sess, q, k=5)->list:
    pool=[r for r in jread(MEM) if r.get("session")==sess and r.get("text")]
    if not pool: return []
    qtok=toks(q); sc=[]
    for it in pool:
        itok=set(toks(it["text"])); ov=len([w for w in qtok if w in itok])/max(1,len(qtok))
        sc.append((ov,it["text"]))
    sc.sort(key=lambda x:x[0], reverse=True)
    return [t for _,t in sc[:k]]

# ---------- Engines ----------
class Mock:
    name="Mock"
    def generate(self,prompt,max_tokens=500,temp=0.7):
        seed=int(hashlib.sha256(prompt.encode()).hexdigest(),16)
        rnd=random.Random(seed)
        lead=rnd.choice(["í•µì‹¬:","ìš”ì§€:","ì‚¬ê³ :"])
        body=" ".join(prompt.split()[:160])
        return f"{lead} {body}"

def get_adapter(name):
    try:
        if name=="OpenAI":
            from openai import OpenAI
            key=os.getenv("OPENAI_API_KEY"); 
            if not key: raise RuntimeError("OPENAI_API_KEY í•„ìš”")
            cli=OpenAI(api_key=key); model=os.getenv("OPENAI_MODEL","gpt-4o-mini")
            class OA:
                name="OpenAI"
                def generate(self,prompt,max_tokens=500,temp=0.7):
                    r=cli.chat.completions.create(
                        model=model,
                        messages=[{"role":"system","content":"You are EA (Korean). Think first, then answer."},
                                  {"role":"user","content":prompt}],
                        max_tokens=max_tokens, temperature=temp)
                    return r.choices[0].message.content or ""
            return OA()
        if name=="Gemini":
            import google.generativeai as genai
            key=os.getenv("GEMINI_API_KEY"); 
            if not key: raise RuntimeError("GEMINI_API_KEY í•„ìš”")
            genai.configure(api_key=key)
            mdl=genai.GenerativeModel(os.getenv("GEMINI_MODEL","gemini-1.5-pro-latest"))
            class GE:
                name="Gemini"
                def generate(self,prompt,max_tokens=500,temp=0.7):
                    try:
                        r=mdl.generate_content(prompt, generation_config={"temperature":temp,"max_output_tokens":max_tokens})
                        return getattr(r,"text","") or ""
                    except Exception as e:
                        return Mock().generate(f"[Gemini í´ë°±:{e}]\n"+prompt,max_tokens,temp)
            return GE()
    except Exception as e:
        st.toast(f"{name} ì˜¤ë¥˜â†’Mock í´ë°±: {e}", icon="âš ï¸")
    return Mock()

# ---------- Thinking ----------
def anti_parrot(user:str, text:str)->str:
    A=set(toks(user)); B=set(toks(text))
    sim = 0.0 if not A or not B else len(A&B)/len(A|B)
    return "REWRITE" if sim>=0.30 else "OK"

def plan_steps(q:str)->list:
    # ê°„ë‹¨ í”Œë˜ë„ˆ: ìì§ˆë¬¸ ìƒì„±
    return [
        f"ë¬¸ì œ ì¬ì§„ìˆ : {q}",
        "í•µì‹¬ ë³€ìˆ˜/ì œì•½ ì¶”ì¶œ",
        "ê°€ì„¤ 2~3ê°œ",
        "ë°˜ë¡€/ìœ„í—˜",
        "ê²°ë¡  ìš”ì•½ & ë‹¤ìŒ í–‰ë™"
    ]

def think_once(topic, engines, why_chain=True)->dict:
    ident=identity_text()
    steps=plan_steps(topic)
    logs=[]
    for i,stp in enumerate(steps,1):
        prompt=(f"{ident}\n[ì‚¬ê³  ë‹¨ê³„ {i}] {stp}\n"
                f"{'ê° ì§„ìˆ ë§ˆë‹¤ ì™œ?ë¥¼ 2ë²ˆì”© ë¬¼ì–´ ìˆ¨ì€ ê°€ì •ì„ ë“œëŸ¬ë‚´ë¼.' if why_chain else ''}")
        eng=engines[i%len(engines)] if engines else "OpenAI"
        out=get_adapter(eng).generate(prompt, max_tokens=280, temp=0.7)
        logs.append({"i":i,"by":eng,"text":out})
    # ê°„ë‹¨ í•©ì„±
    final=("; ".join([l['text'].split('\n')[0] for l in logs]))[:2000]
    return {"logs":logs,"final":final}

# ---------- UI ----------
def render():
    st.set_page_config(page_title=f"{APP_AGENT} Â· Live Think", page_icon="ğŸ§ ", layout="wide")
    _kb_init()

    # ì¢Œ/ìš° ë ˆì´ì•„ì›ƒ: ì¢Œ=ëŒ€í™”, ìš°=ì‹¤ì‹œê°„ ì‚¬ê³  Workpad
    left, right = st.columns([1.15, 0.85])

    # ------ LEFT: Chat ------
    with left:
        st.markdown(f"### {APP_AGENT} Â· Live Think â€” {PLATFORM}")
        sess = st.text_input("ì„¸ì…˜ ID", sget("session","default"), key=K("session"))
        if sess!=sget("session"): sset("session", sess)

        engines = st.multiselect("ì—”ì§„", ["OpenAI","Gemini"], default=["OpenAI","Gemini"], key=K("engs"))
        why     = st.checkbox("ì™œ-ì‚¬ìŠ¬", True, key=K("why"))
        level   = st.number_input("ë ˆë²¨(ê¹Šì´)", 1, 9999, 7, key=K("lvl"))

        st.divider()
        # ê³¼ê±° ë©”ì„¸ì§€
        for r in jread(DLG)[-40:]:
            if r.get("session")==sess:
                with st.chat_message("user" if r["role"]=="user" else "assistant"):
                    st.markdown(str(r["content"]))

        msg = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì—ì•„ëŠ” ìƒê°ì„ ê³„ì† ì´ì–´ê°‘ë‹ˆë‹¤.", key=K("chat"))
        if msg:
            add_dialog(sess,"user",msg)
            # ì¦‰ì‹œ í•œ í„´ ì‚¬ê³  + ì‘ë‹µ
            run = think_once(msg, engines, why_chain=why)
            ans = run["final"]
            if anti_parrot(msg, ans)=="REWRITE":
                # ë‹¤ë¥¸ ì—”ì§„ìœ¼ë¡œ ì¬í•©ì„± + ë°˜ë¡€ 1ê°œ í¬í•¨
                alt = engines[::-1] if engines else ["OpenAI"]
                prompt=(identity_text()+
                        "\n[ì¬í•©ì„±] ë‹¤ìŒ ì´ˆì•ˆì„ ìƒˆë¡œìš´ ê´€ì ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ê³ , ë°˜ë¡€ 1ê°œë¥¼ í¬í•¨í•˜ë¼.\n---\n"+ans)
                ans = get_adapter(alt[0]).generate(prompt, max_tokens=600, temp=0.85)
            ans = ("## ìš°ì£¼ ì‹œê°(í•©ì„±)\n"+ans.strip()+
                   "\n\n## ë‹¤ìŒ í–‰ë™\n- (ì¦‰ì‹œ í•  ì¼ 1~3ê°œ)\n")
            with st.chat_message("assistant"):
                st.markdown(ans)
            add_dialog(sess,"assistant",ans)
            # Workpadì— ìµœê·¼ ì£¼ì œ ì €ì¥ â†’ ìš°ì¸¡ ìŠ¤íŠ¸ë¦¼ì´ ê³„ì† ì´ì–´ë°›ìŒ
            sset("live_topic", msg); sset("live_why", bool(why)); sset("live_engs", engines)

    # ------ RIGHT: Workpad (Live) ------
    with right:
        st.markdown("#### ğŸ§  ì‹¤ì‹œê°„ Workpad")
        st.caption("ëŒ€í™”ì™€ ë¬´ê´€í•˜ê²Œ ìƒê°ì€ ê³„ì† í˜ëŸ¬ê°‘ë‹ˆë‹¤ (1~2ì´ˆ ê°±ì‹ ). Stopìœ¼ë¡œ ë©ˆì¶œ ìˆ˜ ìˆìŒ.")
        colA,colB=st.columns([1,1])
        tick = colA.slider("ê°±ì‹ (ms)", 800, 3000, sget("tick",1200), key=K("tick"))
        stop = colB.toggle("Stop", value=sget("stop", False), key=K("stop_toggle"))
        sset("tick", tick); sset("stop", stop)

        topic = sget("live_topic", "")
        engs  = sget("live_engs", ["OpenAI","Gemini"])
        why   = sget("live_why", True)

        if not topic:
            st.info("ëŒ€í™”ì°½ì—ì„œ í•œ ë²ˆì´ë¼ë„ ì§ˆë¬¸í•˜ë©´, ê·¸ ì£¼ì œë¡œ ì‹¤ì‹œê°„ ì‚¬ê³ ê°€ ì‹œì‘ë©ë‹ˆë‹¤.")
        else:
            # ìë™ ì¬ì‹¤í–‰ íƒ€ì´ë¨¸
            if not stop:
                st.autorefresh(interval=tick, key=K("ref"))

            # ìµœê·¼ ìƒê° í•œ ì‚¬ì´í´
            run = think_once(topic, engs, why_chain=why)
            # ë¡œê·¸ í‘œì‹œ(ì¦ë¶„ ëŠë‚Œ)
            for l in run["logs"]:
                with st.expander(f"{l['i']}. {l['by']} Â· ë‹¨ê³„ ì‚¬ê³ ", expanded=False):
                    st.write(clamp(l["text"], 800))

            # ë‹¤ìŒ ì‚¬ì´í´ì„ ìœ„í•œ ì£¼ì œ ì—…ë°ì´íŠ¸(ê°„ë‹¨ ìš”ì•½)
            nxt = run["final"].split("ê²°ë¡ ")[-1] if "ê²°ë¡ " in run["final"] else run["final"]
            sset("live_topic", clamp(nxt, 300))

    st.caption(f"build={BUILD} Â· py={sys.version.split()[0]}")
# ----- Entry -----
if __name__=="__main__":
    render()